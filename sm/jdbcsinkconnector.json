{
  "template_id": "JdbcSinkConnector",
  "connector_type": "SINK",
  "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
  "name": "{{.logicalClusterId}}",
  "imports": [],
  "group_order": [
    "Database Connection Security",
    "Connection",
    "Writes",
    "Data Mapping",
    "DDL Support",
    "Retries",
    "CSFLE configuration"
  ],
  "config_defs": [
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 1,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 1
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 2,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 2
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 3,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 3
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 4,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 4
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 5,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 5
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 6,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 6
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 7,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 7
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 8,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 8
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 9,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 9
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 10,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 10
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 11,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 11
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 12,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 12
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 13,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 13
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 14,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 14
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 15,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 15
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 16,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 16
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 17,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 17
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 18,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 18
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 19,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 19
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 20,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 20
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 21,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 21
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 22,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 22
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 23,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 23
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 24,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 24
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 25,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 25
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 26,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 26
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 27,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 27
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 28,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 28
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 29,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 29
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 30,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 30
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 31,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 31
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 32,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 32
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 33,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 33
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 34,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 34
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 35,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 35
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 36,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 36
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 37,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 37
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 38,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 38
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 39,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 39
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 40,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 40
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 41,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 41
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 42,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 42
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 43,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 43
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 44,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 44
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 45,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 45
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 46,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 46
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 47,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 47
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 48,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 48
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 49,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 49
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 50,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 50
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 51,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 51
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 52,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 52
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 53,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 53
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 54,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 54
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 55,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 55
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 56,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 56
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 57,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 57
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 58,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 58
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 59,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 59
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 60,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 60
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 61,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 61
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 62,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 62
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 63,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 63
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 64,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 64
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 65,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 65
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 66,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 66
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 67,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 67
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 68,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 68
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 69,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 69
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 70,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 70
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 71,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 71
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 72,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 72
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 73,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 73
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 74,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 74
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 75,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 75
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 76,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 76
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 77,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 77
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 78,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 78
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 79,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 79
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 80,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 80
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 81,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 81
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 82,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 82
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 83,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 83
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 84,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 84
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 85,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 85
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 86,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 86
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 87,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 87
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 88,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 88
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 89,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 89
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 90,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 90
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 91,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 91
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 92,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 92
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 93,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 93
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 94,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 94
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 95,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 95
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 96,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 96
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 97,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 97
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 98,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 98
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 99,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 99
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 100,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 100
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 101,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 101
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 102,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 102
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 103,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 103
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 104,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 104
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 105,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 105
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 106,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 106
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 107,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 107
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 108,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 108
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 109,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 109
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 110,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 110
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 111,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 111
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 112,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 112
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 113,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 113
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 114,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 114
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 115,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 115
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 116,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 116
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 117,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 117
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 118,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 118
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 119,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 119
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 120,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 120
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 121,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 121
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 122,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 122
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 123,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 123
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 124,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 124
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 125,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 125
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 126,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 126
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 127,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 127
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 128,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 128
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 129,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 129
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 130,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 130
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 131,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 131
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 132,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 132
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 133,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 133
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 134,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 134
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 135,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 135
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 136,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 136
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 137,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 137
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 138,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 138
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 139,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 139
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 140,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 140
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 141,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 141
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 142,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 142
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 143,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 143
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 144,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 144
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 145,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 145
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 146,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 146
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 147,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 147
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 148,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 148
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 149,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 149
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 150,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 150
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 151,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 151
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 152,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 152
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 153,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 153
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 154,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 154
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 155,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 155
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 156,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 156
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 157,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 157
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 158,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 158
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 159,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 159
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 160,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 160
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 161,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 161
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 162,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 162
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 163,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 163
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 164,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 164
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 165,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 165
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 166,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 166
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 167,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 167
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 168,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 168
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 169,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 169
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 170,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 170
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 171,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 171
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 172,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 172
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 173,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 173
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 174,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 174
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 175,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 175
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 176,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 176
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 177,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 177
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 178,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 178
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 179,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 179
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 180,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 180
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 181,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 181
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 182,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 182
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 183,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 183
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 184,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 184
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 185,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 185
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 186,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 186
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 187,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 187
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 188,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 188
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 189,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 189
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 190,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 190
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 191,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 191
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 192,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 192
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 193,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 193
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 194,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 194
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 195,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 195
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 196,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 196
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 197,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 197
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 198,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 198
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 199,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 199
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 200,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 200
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 201,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 201
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 202,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 202
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 203,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 203
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 204,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 204
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 205,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 205
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 206,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 206
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 207,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 207
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 208,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 208
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 209,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 209
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 210,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 210
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 211,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 211
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 212,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 212
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 213,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 213
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 214,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 214
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 215,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 215
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 216,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 216
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 217,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 217
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 218,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 218
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 219,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 219
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 220,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 220
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 221,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 221
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 222,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 222
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 223,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 223
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 224,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 224
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 225,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 225
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 226,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 226
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 227,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 227
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 228,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 228
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 229,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 229
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 230,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 230
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 231,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 231
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 232,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 232
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 233,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 233
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 234,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 234
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 235,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 235
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 236,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 236
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 237,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 237
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 238,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 238
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 239,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 239
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 240,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 240
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 241,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 241
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 242,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 242
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 243,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 243
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 244,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 244
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 245,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 245
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 246,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 246
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 247,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 247
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 248,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 248
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 249,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 249
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 250,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 250
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 251,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 251
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 252,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 252
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 253,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 253
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 254,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 254
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 255,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 255
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 256,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 256
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 257,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 257
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 258,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 258
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 259,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 259
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 260,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 260
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 261,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 261
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 262,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 262
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 263,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 263
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 264,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 264
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 265,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 265
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 266,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 266
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 267,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 267
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 268,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 268
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 269,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 269
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 270,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 270
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 271,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 271
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 272,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 272
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 273,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 273
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 274,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 274
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 275,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 275
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Database Connection Security",
      "order_in_group": 276,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 276
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 277,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 277
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 278,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 278
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 279,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 279
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 280,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 280
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 281,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 281
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 282,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 282
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 283,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 283
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 284,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 284
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 285,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 285
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 286,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 286
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 287,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 287
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 288,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 288
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 289,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 289
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 290,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 290
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 291,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 291
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 292,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 292
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 293,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 293
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 294,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 294
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Database Connection Security",
      "order_in_group": 295,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 295
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 296,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 296
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database Connection Security",
      "order_in_group": 297,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 297
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "connection.attempts",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Connection",
      "order_in_group": 298,
      "display_name": "connection.attempts",
      "documentation": "The maximum number of attempts to get a valid JDBC connection. The value must be a positive integer.Type: intDefault: 3Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 298
      },
      "default": "3importance: low"
    },
    {
      "name": "connection.backoff.ms",
      "type": "LONGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Connection",
      "order_in_group": 299,
      "display_name": "connection.backoff.ms",
      "documentation": "The backoff time in milliseconds between connection attempts.Type: longDefault: 10000Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 299
      },
      "default": "10000importance: low"
    },
    {
      "name": "connection.url",
      "type": "STRINGIMPORTANCE",
      "required": true,
      "importance": "HIGH",
      "group": "Connection",
      "order_in_group": 300,
      "display_name": "connection.url",
      "documentation": "JDBC connection URL.For example:jdbc:oracle:thin:@localhost:1521:orclpdb1,jdbc:mysql://localhost/db_name,jdbc:sqlserver://localhost;instance=SQLEXPRESS;databaseName=db_nameType: stringImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 300
      }
    },
    {
      "name": "connection.user",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Connection",
      "order_in_group": 301,
      "display_name": "connection.user",
      "documentation": "JDBC connection user.Type: stringDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 301
      },
      "default": "nullimportance: high"
    },
    {
      "name": "connection.password",
      "type": "PASSWORDDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Connection",
      "order_in_group": 302,
      "display_name": "connection.password",
      "documentation": "JDBC connection password.Type: passwordDefault: nullImportance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 302
      },
      "default": "nullimportance: high"
    },
    {
      "name": "jdbc.credentials.provider.class",
      "type": "CLASSDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Connection",
      "order_in_group": 303,
      "display_name": "jdbc.credentials.provider.class",
      "documentation": "Credentials provider to use for authentication to configure the database. By default, the connector usesDefaultJdbcCredentialsProvider. Configure the class with the fully qualified name of your\ncustom credentials provider class.Type: classDefault:io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProviderValid Values: Any class implementing interface:io.confluent.connect.jdbc.util.JdbcCredentialsProviderImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 303
      },
      "default": "io.confluent.connect.jdbc.util.defaultjdbccredentialsprovidervalid values: any class implementing interface:io.confluent.connect.jdbc.util.jdbccredentialsproviderimportance: low"
    },
    {
      "name": "dialect.name",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Connection",
      "order_in_group": 304,
      "display_name": "dialect.name",
      "documentation": "The name of the database dialect that should be used for this connector. By default this is empty, and the connector automatically determines the dialect based upon the JDBC connection URL. Use this if you want to override that behavior and use a specific dialect. All properly-packaged dialects in the JDBC connector plugin can be used.Type: stringDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dValid Values: [, Db2DatabaseDialect, MySqlDatabaseDialect, SybaseDatabaseDialect, GenericDatabaseDialect, OracleDatabaseDialect, SqlServerDatabaseDialect, PostgreSqlDatabaseDialect, SqliteDatabaseDialect, DerbyDatabaseDialect, SapHanaDatabaseDialect, MockDatabaseDialect, VerticaDatabaseDialect]Importance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 304
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dvalid values: [, db2databasedialect, mysqldatabasedialect, sybasedatabasedialect, genericdatabasedialect, oracledatabasedialect, sqlserverdatabasedialect, postgresqldatabasedialect, sqlitedatabasedialect, derbydatabasedialect, saphanadatabasedialect, mockdatabasedialect, verticadatabasedialect]importance: low",
      "valid_values": [
        "",
        "db2databasedialect",
        "mysqldatabasedialect",
        "sybasedatabasedialect",
        "genericdatabasedialect",
        "oracledatabasedialect",
        "sqlserverdatabasedialect",
        "postgresqldatabasedialect",
        "sqlitedatabasedialect",
        "derbydatabasedialect",
        "saphanadatabasedialect",
        "mockdatabasedialect",
        "verticadatabasedialect"
      ]
    },
    {
      "name": "insert.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Writes",
      "order_in_group": 305,
      "display_name": "insert.mode",
      "documentation": "The insertion mode to use.Type: stringDefault: insertValid Values: [insert, upsert, update]Importance: highThe supported modes are as follows:insertUse standard SQLINSERTstatements.upsertUse the appropriate upsert semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,INSERTORIGNORE. When usingupsertmode, you must add and define thepk.modeandpk.fieldsproperties in the connector configuration. For example:{\n\n     ...\n\n     \"pk.mode\": \"record_value\",\n     \"pk.fields\": \"id\"\n\n     ...\n\n }In the previous example,pk.fieldsshould contain your primary key.updateUse the appropriate update semantics for the target database if it is\nsupported by the connector\u00e2\u0080\u0093for example,UPDATE.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 305
      },
      "default": "insertvalid values: [insert, upsert, update]importance: highthe supported modes are as follows:insertuse standard sqlinsertstatements.upsertuse the appropriate upsert semantics for the target database if it is",
      "valid_values": [
        "insert",
        "upsert",
        "update"
      ]
    },
    {
      "name": "batch.size",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Writes",
      "order_in_group": 306,
      "display_name": "batch.size",
      "documentation": "Specifies how many records to attempt to batch together for insertion into the\ndestination table, when possible. Note that if you setconsumer.max.poll.recordsin the Connect worker properties to a value\nlower thanbatch.size, batch processing will be lost and the desiredbatch.sizewon\u00e2\u0080\u0099t be reached. You can also configure the connector\u00e2\u0080\u0099s\nunderlying consumer\u00e2\u0080\u0099smax.poll.recordsusingconsumer.override.max.poll.recordsin the connector configuration.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 306
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "delete.enabled",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Writes",
      "order_in_group": 307,
      "display_name": "delete.enabled",
      "documentation": "Whether to treatnullrecord values as deletes. Requirespk.modeto berecord_key.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 307
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "table.name.format",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 308,
      "display_name": "table.name.format",
      "documentation": "A format string for the destination table name, which may contain${topic}as a placeholder for the originating topic name.For example,kafka_${topic}for the topicorderswill map to the table namekafka_orders.Type: stringDefault:${topic}Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 308
      },
      "default": "${topic}importance: medium"
    },
    {
      "name": "pk.mode",
      "type": "STRINGDEFAULT",
      "required": true,
      "importance": "HIGH",
      "group": "Data Mapping",
      "order_in_group": 309,
      "display_name": "pk.mode",
      "documentation": "The primary key mode, also refer topk.fieldsdocumentation for interplay. Supported modes are:noneNo keys utilized.kafkaApache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.record_keyField(s) from the record key are used, which may be a primitive or a struct.record_valueField(s) from the record value are used, which must be a struct.Type: stringDefault: noneValid Values: [none, kafka, record_key, record_value]Importance: high",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 309
      },
      "default": "nonevalid values: [none, kafka, record_key, record_value]importance: high",
      "valid_values": [
        "none",
        "kafka",
        "record_key",
        "record_value"
      ]
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 310,
      "display_name": "none",
      "documentation": "No keys utilized.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 310
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 311,
      "display_name": "kafka",
      "documentation": "Apache Kafka\u00c2\u00ae coordinates are used as the primary key.ImportantWith some JDBC dialects, for example the Oracle and MySQL dialects,  an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector\nmaps STRING to a variable length string (for example TEXT) and not a\nfixed length string (for example VARCHAR(256)). A primary key must have\na fixed length. To avoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 311
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 312,
      "display_name": "record_key",
      "documentation": "Field(s) from the record key are used, which may be a primitive or a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 312
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 313,
      "display_name": "record_value",
      "documentation": "Field(s) from the record value are used, which must be a struct.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 313
      }
    },
    {
      "name": "pk.fields",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 314,
      "display_name": "pk.fields",
      "documentation": "A list of comma-separated primary key field names. The runtime interpretation of\nthis configuration property depends onpk.mode:ImportantIf thepk.modeis set torecord_value, everypk.fieldsvalue\nmust exist in every topic whenloading data from different topics into\ndifferent tables\u00e2\u0080\u0093that is, if multiple topics have their own primary key. If not, you must\ncreate distinct connector configurations.noneIgnored as no fields are used as primary key in this mode.kafkaMust be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.record_keyIf empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.record_valueIf empty, all fields from the value struct will be used, otherwise used to extract the desired fields.Type: listDefault: noneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 314
      },
      "default": "noneimportance: medium"
    },
    {
      "name": "none",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 315,
      "display_name": "none",
      "documentation": "Ignored as no fields are used as primary key in this mode.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 315
      }
    },
    {
      "name": "kafka",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 316,
      "display_name": "kafka",
      "documentation": "Must be a trio representing the Kafka coordinates, defaults to__connect_topic,__connect_partition,__connect_offsetif empty. Custom field names that are set in this mode will rename the default column names, but keep the Kafka coordinates as the primary keys.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 316
      }
    },
    {
      "name": "record_key",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 317,
      "display_name": "record_key",
      "documentation": "If empty, all fields from the key struct will be used, otherwise used to extract the desired fields - for primitive key only a single field name must be configured.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 317
      }
    },
    {
      "name": "record_value",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 318,
      "display_name": "record_value",
      "documentation": "If empty, all fields from the value struct will be used, otherwise used to extract the desired fields.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 318
      }
    },
    {
      "name": "fields.whitelist",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 319,
      "display_name": "fields.whitelist",
      "documentation": "List of comma-separated record value field names. If empty, all fields from the record value are utilized, otherwise used to filter to the desired fields.Note thatpk.fieldsis applied independently in the context of which field(s) form the primary key columns in the destination database, while this configuration is applicable for the other columns.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 319
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "db.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 320,
      "display_name": "db.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting time-based values. Defaults to UTC.Type: stringDefault: \u00e2\u0080\u009cUTC\u00e2\u0080\u009dValid Values: Any valid JDK time zoneImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 320
      },
      "default": "\u00e2\u0080\u009cutc\u00e2\u0080\u009dvalid values: any valid jdk time zoneimportance: medium"
    },
    {
      "name": "date.timezone",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 321,
      "display_name": "date.timezone",
      "documentation": "Name of the JDBC timezone that should be used in the connector when inserting DATE type values. Defaults to DB_TIMEZONE that uses the timezone set for db.timzeone configuration (to maintain backward compatibility). It is recommended to set this to UTC to avoid conversion for DATE type values.Type: stringDefault: \u00e2\u0080\u009cDB_TIMEZONE\u00e2\u0080\u009dValid Values: [DB_TIMEZONE, UTC]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 321
      },
      "default": "\u00e2\u0080\u009cdb_timezone\u00e2\u0080\u009dvalid values: [db_timezone, utc]importance: medium",
      "valid_values": [
        "db_timezone",
        "utc"
      ]
    },
    {
      "name": "timestamp.precision.mode",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 322,
      "display_name": "timestamp.precision.mode",
      "documentation": "Convert the timestamp with precision. If set to microseconds, the timestamp will be converted to microsecond precision. If set to nanoseconds the timestamp will be converted to nanoseconds precision.Note that the microsecond and nanosecond precision will be available based on the values supported by timestamp type in the respective databases.Type: stringDefault: \u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dValid Values: [microseconds, nanoseconds]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 322
      },
      "default": "\u00e2\u0080\u009cmicroseconds\u00e2\u0080\u009dvalid values: [microseconds, nanoseconds]importance: medium",
      "valid_values": [
        "microseconds",
        "nanoseconds"
      ]
    },
    {
      "name": "timestamp.fields.list",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Data Mapping",
      "order_in_group": 323,
      "display_name": "timestamp.fields.list",
      "documentation": "List of comma-separated record value timestamp field names that should be converted to timestamps. These fields will be converted based on the precision mode specified intimestamp.precision.mode(microseconds or nanoseconds).Note that the timestamp fields included here should be of Long or String type, and nested fields are not supported.Type: listDefault: \u00e2\u0080\u009c\u00e2\u0080\u009dImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 323
      },
      "default": "\u00e2\u0080\u009c\u00e2\u0080\u009dimportance: medium"
    },
    {
      "name": "table.types",
      "type": "LISTDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "Data Mapping",
      "order_in_group": 324,
      "display_name": "table.types",
      "documentation": "A comma-separated list of database table types to which the sink connector can\nwrite. The default value isTABLE, but any of the following\ncombinations is allowed:TableType.PARTITIONED_TABLEandTableType.VIEW. Not all databases support writing to views. If a database\nsupports writing to views, the sink connector will fail if the view definition\ndoes not match the records\u00e2\u0080\u0099 schema, regardless of the value that is set inauto.evolve.Type: listDefault:TABLEValid values:TABLE,PARTITIONEDTABLE, orVIEWImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 324
      },
      "default": "tablevalid values:table,partitionedtable, orviewimportance: low"
    },
    {
      "name": "auto.create",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "DDL Support",
      "order_in_group": 325,
      "display_name": "auto.create",
      "documentation": "Whether to automatically create the destination table based on record schema if it is found to be missing by issuingCREATE.Type: booleanDefault: falseImportance: mediumImportantDatabase performance could be adversely affected if Kafka Connect\nauto-creates a table and uses data types that are inefficient for the target\ndatabase. Confluent recommends you review the data types used in conjunction with\nyour database administrator, or pre-create the table before loading it.With some JDBC dialects\u00e2\u0080\u0093for example, the Oracle and MySQL dialects\u00e2\u0080\u0093an\nexception can occur if you setpk.modetokafkaandauto.createtotrue. The exception occurs because the connector maps STRING to a\nvariable length string (for example, TEXT) and not a fixed length string\n(for example, VARCHAR(256)). A primary key must have a fixed length. To\navoid this exception, consider the following:Do not setauto.createtotrue.Create the database table and primary key data type in advance.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 325
      },
      "default": "falseimportance: mediumimportantdatabase performance could be adversely affected if kafka connect"
    },
    {
      "name": "auto.evolve",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "DDL Support",
      "order_in_group": 326,
      "display_name": "auto.evolve",
      "documentation": "Whether to automatically add columns in the table schema when found to be missing relative to the record schema by issuingALTER.Type: booleanDefault: falseImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 326
      },
      "default": "falseimportance: medium"
    },
    {
      "name": "quote.sql.identifiers",
      "type": "STRINGDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "DDL Support",
      "order_in_group": 327,
      "display_name": "quote.sql.identifiers",
      "documentation": "When to quote table names, column names, and other identifiers in SQL statements. For backward compatibility, the default isalways.Type: stringDefault: alwaysImportance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 327
      },
      "default": "alwaysimportance: medium"
    },
    {
      "name": "mssql.use.merge.holdlock",
      "type": "BOOLEANDEFAULT",
      "required": false,
      "importance": "LOW",
      "group": "DDL Support",
      "order_in_group": 328,
      "display_name": "mssql.use.merge.holdlock",
      "documentation": "Whether to use HOLDLOCK when performing a MERGE INTOupsertstatement.\nNote that this configuration property is specific to Microsoft SQL Server\nonly.Type: booleanDefault: trueImportance: low",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 328
      },
      "default": "trueimportance: low"
    },
    {
      "name": "max.retries",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Retries",
      "order_in_group": 329,
      "display_name": "max.retries",
      "documentation": "The maximum number of times to retry on errors before failing the task.Type: intDefault: 10Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 329
      },
      "default": "10valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "retry.backoff.ms",
      "type": "INTDEFAULT",
      "required": false,
      "importance": "MEDIUM",
      "group": "Retries",
      "order_in_group": 330,
      "display_name": "retry.backoff.ms",
      "documentation": "The time in milliseconds to wait following an error before a retry attempt is made.Type: intDefault: 3000Valid Values: [0,\u00e2\u0080\u00a6]Importance: medium",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 330
      },
      "default": "3000valid values: [0,\u00e2\u0080\u00a6]importance: medium",
      "valid_values": [
        "0",
        "\u00e2\u0080\u00a6"
      ]
    },
    {
      "name": "Search by configuration property name",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 2,
      "display_name": "Search by configuration property name",
      "documentation": "Enter a string to search and filter by configuration property name.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 2
      }
    },
    {
      "name": "name",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 2,
      "display_name": "name",
      "documentation": "Globally unique name to use for this connector.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 2
      }
    },
    {
      "name": "connector.class",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 3,
      "display_name": "connector.class",
      "documentation": "Name or alias of the class for this connector. Must be a subclass of org.apache.kafka.connect.connector.Connector. If the connector is org.apache.kafka.connect.file.FileStreamSinkConnector, you can either specify this full name,  or use \u00e2\u0080\u009cFileStreamSink\u00e2\u0080\u009d or \u00e2\u0080\u009cFileStreamSinkConnector\u00e2\u0080\u009d to make the configuration a bit shorter",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 3
      }
    },
    {
      "name": "tasks.max",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 4,
      "display_name": "tasks.max",
      "documentation": "Maximum number of tasks to use for this connector.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 4
      }
    },
    {
      "name": "topics",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 5,
      "display_name": "topics",
      "documentation": "List of topics to consume, separated by commas",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 5
      }
    },
    {
      "name": "topics.regex",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 6,
      "display_name": "topics.regex",
      "documentation": "Regular expression giving topics to consume. Under the hood, the regex is compiled to ajava.util.regex.Pattern. Only one of topics or topics.regex should be specified.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 6
      }
    },
    {
      "name": "tasks.max.enforce",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 7,
      "display_name": "tasks.max.enforce",
      "documentation": "(Deprecated) Whether to enforce that the tasks.max property is respected by the connector. By default, connectors that generate too many tasks will fail, and existing sets of tasks that exceed the tasks.max property will also be failed. If this property is set to false, then connectors will be allowed to generate more than the maximum number of tasks, and existing sets of tasks that exceed the tasks.max property will be allowed to run. This property is deprecated and will be removed in an upcoming major release.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 7
      }
    },
    {
      "name": "key.converter",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 8,
      "display_name": "key.converter",
      "documentation": "Converter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the keys in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 8
      }
    },
    {
      "name": "value.converter",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 9,
      "display_name": "value.converter",
      "documentation": "Converter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the values in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 9
      }
    },
    {
      "name": "header.converter",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 10,
      "display_name": "header.converter",
      "documentation": "HeaderConverter class used to convert between Kafka Connect format and the serialized form that is written to Kafka. This controls the format of the header values in messages written to or read from Kafka, and since this is independent of connectors it allows any connector to work with any serialization format. Examples of common formats include JSON and Avro. By default, the SimpleHeaderConverter is used to serialize header values to strings and deserialize them by inferring the schemas.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 10
      }
    },
    {
      "name": "config.action.reload",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 11,
      "display_name": "config.action.reload",
      "documentation": "The action that Connect should take on the connector when changes in external configuration providers result in a change in the connector\u00e2\u0080\u0099s configuration properties. A value of \u00e2\u0080\u0098none\u00e2\u0080\u0099 indicates that Connect will do nothing. A value of \u00e2\u0080\u0098restart\u00e2\u0080\u0099 indicates that Connect should restart/reload the connector with the updated configuration properties.The restart may actually be scheduled in the future if the external configuration provider indicates that a configuration value will expire in the future.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 11
      }
    },
    {
      "name": "transforms",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 12,
      "display_name": "transforms",
      "documentation": "Aliases for the transformations to be applied to records.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 12
      }
    },
    {
      "name": "predicates",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 13,
      "display_name": "predicates",
      "documentation": "Aliases for the predicates used by transformations.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 13
      }
    },
    {
      "name": "errors.retry.timeout",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 14,
      "display_name": "errors.retry.timeout",
      "documentation": "The maximum duration in milliseconds that a failed operation will be reattempted. The default is 0, which means no retries will be attempted. Use -1 for infinite retries.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 14
      }
    },
    {
      "name": "errors.retry.delay.max.ms",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 15,
      "display_name": "errors.retry.delay.max.ms",
      "documentation": "The maximum duration in milliseconds between consecutive retry attempts. Jitter will be added to the delay once this limit is reached to prevent thundering herd issues.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 15
      }
    },
    {
      "name": "errors.tolerance",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 16,
      "display_name": "errors.tolerance",
      "documentation": "Behavior for tolerating errors during connector operation. \u00e2\u0080\u0098none\u00e2\u0080\u0099 is the default value and signals that any error will result in an immediate connector task failure; \u00e2\u0080\u0098all\u00e2\u0080\u0099 changes the behavior to skip over problematic records.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 16
      }
    },
    {
      "name": "errors.log.enable",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 17,
      "display_name": "errors.log.enable",
      "documentation": "If true, write each error and the details of the failed operation and problematic record to the Connect application log. This is \u00e2\u0080\u0098false\u00e2\u0080\u0099 by default, so that only errors that are not tolerated are reported.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 17
      }
    },
    {
      "name": "errors.log.include.messages",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 18,
      "display_name": "errors.log.include.messages",
      "documentation": "Whether to include in the log the Connect record that resulted in a failure. For sink records, the topic, partition, offset, and timestamp will be logged. For source records, the key and value (and their schemas), all headers, and the timestamp, Kafka topic, Kafka partition, source partition, and source offset will be logged. This is \u00e2\u0080\u0098false\u00e2\u0080\u0099 by default, which will prevent record keys, values, and headers from being written to log files.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 18
      }
    },
    {
      "name": "errors.deadletterqueue.topic.name",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 19,
      "display_name": "errors.deadletterqueue.topic.name",
      "documentation": "The name of the topic to be used as the dead letter queue (DLQ) for messages that result in an error when processed by this sink connector, or its transformations or converters. The topic name is blank by default, which means that no messages are to be recorded in the DLQ.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 19
      }
    },
    {
      "name": "errors.deadletterqueue.topic.replication.factor",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 20,
      "display_name": "errors.deadletterqueue.topic.replication.factor",
      "documentation": "Replication factor used to create the dead letter queue topic when it doesn\u00e2\u0080\u0099t already exist.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 20
      }
    },
    {
      "name": "errors.deadletterqueue.context.headers.enable",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Common",
      "order_in_group": 21,
      "display_name": "errors.deadletterqueue.context.headers.enable",
      "documentation": "If true, add headers containing error context to the messages written to the dead letter queue. To avoid clashing with headers from the original record, all error context header keys, all error context header keys will start with__connect.errors.",
      "validators": [],
      "sanitizers": [],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 21
      }
    }
  ]
}