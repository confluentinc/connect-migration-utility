{
  "templates": [
    {
      "template_id": "MySqlCdcSource",
      "connector_type": "SOURCE",
      "connector.class": "io.debezium.connector.mysql.MySqlConnector",
      "config_defs": [
        {
          "name": "database.hostname",
          "required": true,
          "documentation": "The address of the MySQL server."
        },
        {
          "name": "database.port",
          "required": true,
          "documentation": "Port number of the MySQL server."
        },
        {
          "name": "database.user",
          "required": true,
          "documentation": "The name of the MySQL server user that has the required authorization."
        },
        {
          "name": "database.password",
          "required": true,
          "documentation": "The password for the MySQL server user that has the required authorization."
        },
        {
          "name": "database.server.name",
          "required": true,
          "documentation": "The logical name of the MySQL server cluster. This logical name forms a namespace and is used in all Kafka topic names and Kafka Connect schema names. The logical name is also used for the namespaces of the corresponding Avro schema, if Avro data format is used. Kafka topics must (and will be) created with the prefix ``database.server.name``. Only alphanumeric characters, underscores, hyphens and dots are allowed."
        },
        {
          "name": "database.ssl.mode",
          "type": "STRING",
          "required": true,
          "default_value": "preferred",
          "importance": "LOW",
          "group": "How should we connect to your database?",
          "display_name": "SSL mode",
          "documentation": "What SSL mode should we use to connect to your database. The default `preferred` option establishes an encrypted connection if the server supports secure connections. If the server does not support secure connections, it falls back to an unencrypted connection. The `required` option establishes an encrypted connection or fails if one cannot be made for any reason.",
          "recommended_values": [
            "preferred",
            "required"
          ]
        },
        {
          "name": "database.whitelist",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "internal": true,
          "group": "Database details",
          "documentation": "Same as `database.include.list`. This property is hidden and supports backward-compatibility for existing user configurations.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "database.include.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database details",
          "display_name": "Databases included",
          "documentation": "An optional comma-separated list of strings that match database names to be monitored. Any database name not included in the list is excluded from monitoring. By default all databases are monitored. May not be used with database.exclude.list.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "database.blacklist",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "internal": true,
          "group": "Database details",
          "documentation": "Same as `database.exclude.list`. This property is hidden and supports backward-compatibility for existing user configurations.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "database.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database details",
          "display_name": "Databases excluded",
          "documentation": "An optional comma-separated list of strings that match database names to be excluded from monitoring. Any database name not included in the list is monitored. May not be used with database.include.list.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "database.connectionTimeZone",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Database details",
          "display_name": "Connection timezone",
          "documentation": "The value must be a valid ZoneId.",
          "recommender": {
            "name": "timezone"
          }
        },
        {
          "name": "table.include.list"
        },
        {
          "name": "table.exclude.list"
        },
        {
          "name": "key.converter.reference.subject.name.strategy",
          "type": "STRING",
          "importance": "HIGH",
          "group": "Output messages",
          "display_name": "Key Converter Reference Subject Name Strategy",
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for key. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "dependents": [
            "output.key.format"
          ]
        },
        {
          "name": "snapshot.mode",
          "documentation": "Specifies the criteria for running a snapshot when the connector starts. The default setting is `initial` and specifies that the connector can run a snapshot only when no offsets have been recorded for the logical server name. The `when_needed` option specifies that the connector run a snapshot upon startup whenever necessary; typically when no offsets are available, or when a previously recorded offset specifies a binlog location or GTID that is not available in the server. The `never` option specifies that the connect should never use snapshots and that when the connector starts with a logical server name, the connector should read from the beginning of the binlog. Use the `never` option with care, as it is only valid when the binlog is guaranteed to contain the entire history of the database. The `schema_only` option performs a snapshot of the schemas and not the data. This setting is useful when you do not need the topics to contain a consistent snapshot of the data but need them to have only the changes since the connector was started. The `schema_only_recovery` option  is a recovery setting for a connector that has already been capturing changes. When you restart the connector, this setting enables recovery of a corrupted or lost database history topic. You might set it periodically to \"clean up\" a database history topic that has been growing unexpectedly. Database history topics require infinite retention.",
          "recommended_values": [
            "initial",
            "when_needed",
            "never",
            "schema_only",
            "schema_only_recovery"
          ]
        },
        {
          "name": "snapshot.locking.mode",
          "type": "STRING",
          "required": false,
          "default_value": "minimal",
          "importance": "LOW",
          "group": "Database details",
          "display_name": "Snapshot locking mode",
          "documentation": "Controls how long the connector holds onto the global read lock while it is performing a snapshot. The default is `minimal`, which means the connector holds the global read lock (and thus prevents any updates) for just the initial portion of the snapshot, while the database schemas and other metadata are being read. The remaining work in a snapshot involves selecting all rows from each table. This is accomplished using a REPEATABLE READ transaction, even when the lock is no longer held and other operations are updating the database. However, in some cases it may be desirable to block all writes for the entire duration of the snapshot. In this situation, set this property to `extended`. Using a value of `none` prevents the connector from acquiring any table locks during the snapshot process. While this setting is allowed with all snapshot modes, it is safe to use if and only if no schema changes are happening while the snapshot is running.",
          "recommended_values": [
            "minimal",
            "minimal_percona",
            "extended",
            "none"
          ]
        },
        {
          "name": "column.exclude.list",
          "required": false
        },
        {
          "name": "tombstones.on.delete"
        },
        {
          "name": "database.history.skip.unparseable.ddl",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Connection details",
          "display_name": "Skip unparseable DDL",
          "documentation": "A Boolean value that specifies whether the connector should ignore malformed or unknown database statements (`true`), or stop processing so a human can fix the issue (`false`). Defaults to `false`. Consider setting this to `true` to ignore unparseable statements.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "event.deserialization.failure.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "fail",
          "importance": "MEDIUM",
          "group": "Connection details",
          "display_name": "Event deserialization failure handling mode",
          "documentation": "Specifies how the connector should react to exceptions during deserialization of binlog events.",
          "recommended_values": [
            "fail",
            "skip",
            "warn"
          ]
        },
        {
          "name": "inconsistent.schema.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "fail",
          "importance": "MEDIUM",
          "group": "Connection details",
          "display_name": "Inconsistent schema handling mode",
          "documentation": "Specifies how the connector should react to binlog events that belong to a table missing from internal schema representation.",
          "recommended_values": [
            "fail",
            "skip",
            "warn"
          ]
        },
        {
          "name": "time.precision.mode",
          "type": "STRING",
          "required": false,
          "default_value": "connect",
          "importance": "MEDIUM",
          "group": "Connector details",
          "display_name": "Time precision mode",
          "documentation": "Time, date, and timestamps can be represented with different kinds of precisions, including: 'adaptive_time_microseconds' TIME fields always use microseconds precision; 'connect' (the default) always represents time, date, and timestamp values using Kafka Connect's built-in representations for Time, Date, and Timestamp, which uses millisecond precision regardless of the database columns' precision.",
          "recommended_values": [
            "adaptive_time_microseconds",
            "connect"
          ]
        },
        {
          "name": "bigint.unsigned.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "long",
          "importance": "MEDIUM",
          "group": "Connector details",
          "display_name": "BigInt Unsigned handling mode",
          "documentation": "Specifies how BIGINT UNSIGNED columns should be represented in change events.",
          "recommended_values": [
            "precise",
            "long"
          ]
        },
        {
          "name": "enable.time.adjuster",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Connector details",
          "display_name": "Enable time adjuster",
          "documentation": "Specifies if the year value conversion is adjusted by the connector or delegated to the database.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "signal.data.collection",
          "type": "STRING",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database details",
          "display_name": "Signal data collection",
          "documentation": "Fully-qualified name of the data collection that needs to be used to send signals to the connector. Use the following format to specify the fully-qualified collection name: ``databaseName.tableName`` "
        },
        {
          "name": "database.history.store.only.captured.tables.ddl",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Connector details",
          "display_name": "Store only captured tables DDL",
          "documentation": "A Boolean value that specifies whether the connector records schema structures from all tables in a schema or database, or only from tables that are designated for capture. Defaults to `false`. \n`false` - During a database snapshot, the connector records the schema data for all non-system tables in the database, including tables that are not designated for capture. It’s best to retain the default setting. If you later decide to capture changes from tables that you did not originally designate for capture, the connector can easily begin to capture data from those tables, because their schema structure is already stored in the schema history topic. \n`true` - During a database snapshot, the connector records the table schemas only for the tables from which Debezium captures change events. If you change the default value, and you later configure the connector to capture data from other tables in the database, the connector lacks the schema information that it requires to capture change events from the tables.",
          "recommended_values": [
            "true",
            "false"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "database.history.kafka.topic",
          "value": "dbhistory.${database.server.name}.{{.logicalClusterId}}"
        },
        {
          "name": "database.history.kafka.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "database.history.consumer.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "database.history.producer.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "database.history.consumer.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "database.history.producer.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "database.history.consumer.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "database.history.producer.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "database.history.consumer.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "database.history.producer.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "database.history.consumer.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "database.history.producer.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "database.history.producer.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "database.history.producer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "database.history.producer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "database.history.consumer.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "database.history.consumer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "database.history.consumer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "connect.timeout.ms",
          "value": "5000"
        },
        {
          "name": "database.history.kafka.recovery.poll.interval.ms",
          "value": "1000"
        },
        {
          "name": "database.history.kafka.recovery.attempts",
          "value": "100000"
        },
        {
          "name": "database.server.id",
          "value": "{{.numericClusterId}}"
        },
        {
          "name": "database.ssl.mode"
        },
        {
          "name": "database.include.list"
        },
        {
          "name": "database.exclude.list"
        },
        {
          "name": "database.whitelist"
        },
        {
          "name": "database.blacklist"
        },
        {
          "name": "database.history.skip.unparseable.ddl"
        },
        {
          "name": "event.deserialization.failure.handling.mode"
        },
        {
          "name": "inconsistent.schema.handling.mode"
        },
        {
          "name": "bigint.unsigned.handling.mode"
        },
        {
          "name": "database.history.store.only.captured.tables.ddl"
        },
        {
          "name": "enable.time.adjuster"
        },
        {
          "name": "time.precision.mode"
        },
        {
          "name": "database.enabledTLSProtocols",
          "value": "TLSv1.2"
        },
        {
          "name": "snapshot.locking.mode"
        },
        {
          "name": "signal.data.collection"
        },
        {
          "name": "key.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "sr.output.key.subject.reference.naming.strategy"
          }
        }
      ]
    },
    {
      "template_id": "common-debezium-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "database.hostname",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "display_name": "Database hostname",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "database.port",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "display_name": "Database port",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "database.user",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "display_name": "Database username"
        },
        {
          "name": "database.password",
          "type": "PASSWORD",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "display_name": "Database password"
        },
        {
          "name": "database.server.name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "display_name": "Database server name",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "table.whitelist",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "internal": true,
          "group": "Database details",
          "documentation": "Same as `table.include.list`, kept as hidden for backwards-compatibility of existing user_configs",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "table.include.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database details",
          "display_name": "Tables included",
          "documentation": "An optional comma-separated list of strings that match fully-qualified table identifiers for tables to be monitored. Any table not included in this config property is excluded from monitoring. Each identifier is in the form ``schemaName.tableName``. By default the connector monitors every non-system table in each monitored schema. May not be used with \"Table excluded\".",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "table.blacklist",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "internal": true,
          "group": "Database details",
          "documentation": "Same as `table.exclude.list`, kept as hidden for backwards-compatibility of existing user_configs",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "table.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database details",
          "display_name": "Tables excluded",
          "documentation": "An optional comma-separated list of strings that match fully-qualified table identifiers for tables to be excluded from monitoring. Any table not included in this config property is monitored. Each identifier is in the form ``schemaName.tableName``. May not be used with \"Table included\".",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "snapshot.mode",
          "type": "STRING",
          "required": false,
          "default_value": "initial",
          "importance": "LOW",
          "group": "Database details",
          "display_name": "Snapshot mode"
        },
        {
          "name": "tombstones.on.delete",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "HIGH",
          "group": "Database details",
          "display_name": "Tombstones on delete",
          "documentation": "Controls whether a tombstone event should be generated after a delete event. When set to ``true``, the delete operations are represented by a delete event and a subsequent tombstone event. When set to ``false``, only a delete event is sent. Emitting the tombstone event (the default behavior) allows Kafka to completely delete all events pertaining to the given key, once the source record got deleted.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "column.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database details",
          "display_name": "Columns Excluded",
          "documentation": "Regular expressions matching columns to exclude from change events",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "poll.interval.ms",
          "type": "INT",
          "required": false,
          "default_value": "1000",
          "importance": "LOW",
          "group": "Connection details",
          "display_name": "Poll interval (ms)",
          "documentation": "Positive integer value that specifies the number of milliseconds the connector should wait during each iteration for new change events to appear. Defaults to 1000 milliseconds, or 1 second."
        },
        {
          "name": "max.batch.size",
          "type": "INT",
          "required": false,
          "default_value": "1000",
          "importance": "LOW",
          "group": "Connection details",
          "display_name": "Max batch size",
          "documentation": "Positive integer value that specifies the maximum size of each batch of events that should be processed during each iteration of this connector."
        },
        {
          "name": "event.processing.failure.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "fail",
          "importance": "LOW",
          "group": "Connection details",
          "display_name": "Event processing failure handling mode",
          "documentation": "Specifies how the connector should react to exceptions during processing of binlog events.",
          "recommended_values": [
            "fail",
            "skip",
            "warn"
          ]
        },
        {
          "name": "heartbeat.interval.ms",
          "type": "INT",
          "required": false,
          "default_value": "0",
          "importance": "LOW",
          "group": "Connection details",
          "display_name": "Heartbeat interval (ms)",
          "documentation": "Controls how frequently the connector sends heartbeat messages to a Kafka topic. The behavior of default value 0 is that the connector does not send heartbeat messages."
        },
        {
          "name": "output.data.format",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "Output messages",
          "display_name": "Output Kafka record value format",
          "documentation": "Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.",
          "recommended_values": [
            "AVRO",
            "JSON",
            "JSON_SR",
            "PROTOBUF"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "after.state.only",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "LOW",
          "group": "Output messages",
          "display_name": "After-state only",
          "documentation": "Controls whether the generated Kafka record should contain only the state after applying change events.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "provide.transaction.metadata",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Connector details",
          "display_name": "Provide transaction metadata",
          "documentation": "Stores transaction metadata information in a dedicated topic and enables the transaction metadata extraction together with event counting.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "decimal.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "precise",
          "importance": "MEDIUM",
          "group": "Connector details",
          "display_name": "Decimal handling mode",
          "documentation": "Specifies how DECIMAL and NUMERIC columns should be represented in change events, including: 'precise' (the default) uses java.math.BigDecimal to represent values, which are encoded in the change events using a binary representation and Kafka Connect's 'org.apache.kafka.connect.data.Decimal' type; 'string' uses string to represent values; 'double' represents values using Java's 'double', which may not offer the precision but will be far easier to use in consumers.",
          "recommended_values": [
            "double",
            "precise",
            "string"
          ]
        },
        {
          "name": "binary.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "bytes",
          "importance": "LOW",
          "group": "Connector details",
          "display_name": "Binary handling mode",
          "documentation": "Specifies how binary (blob, binary, etc.) columns should be represented in change events, including: 'bytes' (the default) represents binary data as byte array; 'base64' represents binary data as base64-encoded string; 'hex' represents binary data as hex-encoded (base16) string.",
          "recommended_values": [
            "bytes",
            "base64",
            "hex"
          ]
        },
        {
          "name": "time.precision.mode",
          "type": "STRING",
          "required": false,
          "default_value": "adaptive",
          "importance": "MEDIUM",
          "group": "Connector details",
          "display_name": "Time precision mode",
          "documentation": "Time, date, and timestamps can be represented with different kinds of precisions, including: 'adaptive' (the default) bases the precision of time, date, and timestamp values on the database column's precision; 'adaptive_time_microseconds' like 'adaptive' mode, but TIME fields always use microseconds precision; 'connect' always represents time, date, and timestamp values using Kafka Connect's built-in representations for Time, Date, and Timestamp, which uses millisecond precision regardless of the database columns' precision.",
          "recommended_values": [
            "adaptive",
            "adaptive_time_microseconds",
            "connect"
          ]
        },
        {
          "name": "datatype.propagate.source.type",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Database details",
          "display_name": "Propagate Source Types by Data Type",
          "documentation": "A comma-separated list of regular expressions matching the database-specific data type names that adds the data type's original type and original length as parameters to the corresponding field schemas in the emitted change records.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "cleanup.policy",
          "type": "STRING",
          "required": false,
          "default_value": "delete",
          "importance": "MEDIUM",
          "group": "Connector details",
          "display_name": "Topic cleanup policy",
          "documentation": "Set the topic cleanup policy",
          "recommended_values": [
            "compact",
            "delete"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "database.hostname"
        },
        {
          "name": "database.port"
        },
        {
          "name": "database.user"
        },
        {
          "name": "database.password"
        },
        {
          "name": "database.server.name"
        },
        {
          "name": "table.include.list"
        },
        {
          "name": "table.exclude.list"
        },
        {
          "name": "table.whitelist"
        },
        {
          "name": "table.blacklist"
        },
        {
          "name": "snapshot.mode"
        },
        {
          "name": "column.exclude.list"
        },
        {
          "name": "tombstones.on.delete"
        },
        {
          "name": "poll.interval.ms"
        },
        {
          "name": "max.batch.size"
        },
        {
          "name": "event.processing.failure.handling.mode"
        },
        {
          "name": "heartbeat.interval.ms"
        },
        {
          "name": "producer.override.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "transforms",
          "switch": {
            "after.state.only": {
              "true": "unwrap",
              "false": ""
            }
          }
        },
        {
          "name": "transforms.unwrap.type",
          "switch": {
            "after.state.only": {
              "true": "io.debezium.transforms.ExtractNewRecordState",
              "false": ""
            }
          }
        },
        {
          "name": "transforms.unwrap.drop.tombstones",
          "switch": {
            "after.state.only": {
              "true": "false",
              "false": ""
            }
          }
        },
        {
          "name": "transforms.unwrap.delete.handling.mode",
          "switch": {
            "after.state.only": {
              "true": "rewrite",
              "false": ""
            }
          }
        },
        {
          "name": "provide.transaction.metadata"
        },
        {
          "name": "decimal.handling.mode"
        },
        {
          "name": "binary.handling.mode"
        },
        {
          "name": "time.precision.mode"
        },
        {
          "name": "datatype.propagate.source.type"
        },
        {
          "name": "topic.creation.default.cleanup.policy",
          "value": "${cleanup.policy}"
        },
        {
          "name": "max.queue.size.in.bytes",
          "value": "209716100"
        },
        {
          "name": "custom.metric.tags",
          "value": "connector={{.logicalClusterId}},version=v1"
        },
        {
          "name": "connector.endpoint",
          "value": "${database.hostname}"
        }
      ]
    },
    {
      "template_id": "common",
      "global_validators": [
        {
          "name": "required",
          "priority": "HIGHEST"
        },
        {
          "name": "recommended.values",
          "priority": "HIGHER"
        }
      ],
      "abstract": true,
      "config_defs": [
        {
          "name": "connector.class",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "display_name": "Connector class"
        },
        {
          "name": "name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "display_name": "Connector name",
          "documentation": "Sets a name for your connector."
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "KAFKA_API_KEY",
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.",
          "recommended_values": [
            "SERVICE_ACCOUNT",
            "KAFKA_API_KEY"
          ]
        },
        {
          "name": "kafka.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka API Key",
          "documentation": "Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY."
        },
        {
          "name": "kafka.service.account.api.key",
          "type": "PASSWORD",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.service.account.api.secret",
          "type": "PASSWORD",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.region",
          "type": "STRING",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.endpoint",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.user.id",
          "type": "INT",
          "required": false,
          "internal": true,
          "importance": "MEDIUM"
        },
        {
          "name": "cloud.environment",
          "type": "STRING",
          "required": true,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "connector.cloud",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "kafka.dedicated",
          "type": "STRING",
          "required": true,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "valid.kafka.api.key",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "kafka.service.account.oauth.token",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "kafka.logical.cluster.id",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "connect.connector_cross_region.enable",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "connector.regional.connectivity.enabled",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "sr.internal.sa.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "sr.internal.sa.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "sr.internal.sa.validity.check",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        }
      ],
      "connector_configs": [
        {
          "name": "tasks.max"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "errors.log.enable",
          "value": "true"
        },
        {
          "name": "errors.log.include.messages",
          "value": "false"
        },
        {
          "name": "errors.retry.timeout",
          "value": "300000"
        },
        {
          "name": "errors.retry.delay.max.ms",
          "value": "30000"
        },
        {
          "name": "value.converter.ignore.modern.dialects",
          "value": "true"
        }
      ]
    },
    {
      "template_id": "common-kafka-connectivity",
      "abstract": true,
      "config_defs": [
        {
          "name": "connect.metadata_property.kafka.itsl.embed.lkc",
          "type": "STRING",
          "required": false,
          "default_value": "SKIP",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm",
          "type": "STRING",
          "required": false,
          "default_value": "UNSET",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "connect.metadata_property.kafka.itsl.bootstrap.servers",
          "type": "STRING",
          "required": false,
          "default_value": "UNSET",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "connect.fips.provider",
          "type": "STRING",
          "required": false,
          "default_value": "UNSET",
          "default_value_provider": {
            "name": "defaultvalue.fips.provider"
          },
          "importance": "HIGH",
          "internal": true
        }
      ],
      "connector_configs": [
        {
          "name": "consumer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "producer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "producer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "consumer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "admin.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "producer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "consumer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "admin.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "consumer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "admin.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        }
      ]
    },
    {
      "template_id": "common-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.service.account.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka Service Account",
          "documentation": "The Service Account that will be used to generate the API keys to communicate with Kafka Cluster."
        },
        {
          "name": "kafka.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka API Secret",
          "documentation": "Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.",
          "dependents": [
            "kafka.api.key"
          ]
        },
        {
          "name": "datapreview.schemas.enable",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "default_value": "false",
          "display_name": "Show schemas in data preview request output",
          "group": "Kafka Cluster credentials",
          "documentation": "This config key only applies to data preview requests and governs whether the data preview output has record schema with it.\nThe visibility condition is set such that it can never be true.\nSo this key does not show in create connector UI."
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "none",
          "display_name": "errors.tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "producer.override.linger.ms",
          "type": "LONG",
          "required": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "producer.override.linger.ms",
          "documentation": "The producer groups together any records that arrive in between request transmissions into a single batched request. More details can be found in the documentation: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#linger-ms."
        }
      ],
      "connector_configs": [
        {
          "name": "topic.creation.default.replication.factor",
          "value": "3"
        },
        {
          "name": "topic.creation.default.partitions",
          "value": "1"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "producer.override.max.request.size",
          "switch": {
            "kafka.dedicated": {
              "true": "20971610",
              "false": "8388698"
            }
          }
        },
        {
          "name": "topic.creation.default.max.message.bytes",
          "switch": {
            "kafka.dedicated": {
              "true": "20971520",
              "false": "8388608"
            }
          }
        },
        {
          "name": "datapreview.schemas.enable"
        },
        {
          "name": "producer.override.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "producer.override.linger.ms"
        }
      ]
    },
    {
      "template_id": "schema-registry",
      "abstract": true,
      "config_defs": [
        {
          "name": "schema.registry.url",
          "type": "STRING",
          "importance": "MEDIUM",
          "internal": true
        },
        {
          "name": "schema.context.name",
          "type": "STRING",
          "group": "Schema Config",
          "importance": "MEDIUM",
          "display_name": "Schema context",
          "documentation": "Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.",
          "default_value": "default",
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": []
    },
    {
      "template_id": "source-connector-output-data-format",
      "abstract": true,
      "config_defs": [
        {
          "name": "output.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "JSON",
          "importance": "HIGH",
          "group": "Output messages",
          "display_name": "Select output record value format",
          "alias": "data.format",
          "documentation": "Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "value.converter.schemas.enable",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "alias": "schemas.enable",
          "display_name": "value.converter.schemas.enable",
          "documentation": "Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.replace.null.with.default",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "alias": "replace.null.with.default",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.replace.null.with.default",
          "documentation": "Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.ignore.default.for.nullables",
          "alias": "ignore.default.for.nullables",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.ignore.default.for.nullables",
          "documentation": "When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters."
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "type": "BOOLEAN",
          "documentation": "Whether to scrub invalid names by replacing invalid characters with valid characters. Applicable for Avro and Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.scrub.invalid.names"
        }
      ],
      "connector_configs": [
        {
          "name": "value.converter",
          "switch": {
            "output.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "value.converter.schemas.enable"
        },
        {
          "name": "value.converter.replace.null.with.default"
        },
        {
          "name": "value.converter.schema.registry.url",
          "switch": {
            "output.data.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "switch": {
            "output.data.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "switch": {
            "output.data.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "value.converter.ignore.default.for.nullables"
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "dynamic.mapper": {
            "name": "value.converter.scrub.invalid.names.mapper"
          }
        }
      ]
    },
    {
      "template_id": "output-key-format-debezium-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "output.key.format",
          "type": "STRING",
          "required": false,
          "default_value": "JSON",
          "importance": "HIGH",
          "group": "Output messages",
          "display_name": "Output Kafka record key format",
          "alias": "key.format",
          "documentation": "Sets the output Kafka record key format. Valid entries are AVRO, JSON_SR, PROTOBUF, STRING or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON",
            "STRING"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "key.converter",
          "switch": {
            "output.key.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "STRING": "org.apache.kafka.connect.storage.StringConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "key.converter.schemas.enable",
          "switch": {
            "output.key.format": {
              "JSON": false
            }
          }
        },
        {
          "name": "key.converter.schema.registry.url",
          "switch": {
            "output.key.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "key.converter.basic.auth.credentials.source",
          "switch": {
            "output.key.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "key.converter.basic.auth.user.info",
          "switch": {
            "output.key.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        }
      ]
    },
    {
      "template_id": "super",
      "abstract": true,
      "config_defs": [
        {
          "name": "auto.restart.on.user.error",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Auto-restart policy",
          "display_name": "Enable Connector Auto-restart",
          "documentation": "Enable connector to automatically restart on user-actionable errors."
        },
        {
          "name": "value.converter.enhanced.avro.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information and Enums. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data",
          "type": "BOOLEAN",
          "documentation": "Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to generate an index suffix for unions. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums",
          "type": "BOOLEAN",
          "documentation": "Whether to represent enums as integers. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should be specified with an optional label. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls",
          "type": "BOOLEAN",
          "documentation": "Whether to generate a struct variable for null values. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should use primitive wrapper messages. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives",
          "type": "BOOLEAN",
          "documentation": "Whether a wrapper message should be interpreted as a raw primitive at root level. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties",
          "type": "BOOLEAN",
          "documentation": "Whether to allow additional properties for object schemas. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired",
          "type": "BOOLEAN",
          "documentation": "Whether to set non-required properties to be optional. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format",
          "type": "STRING",
          "recommended_values": [
            "BASE64",
            "NUMERIC"
          ],
          "documentation": "Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:\nBASE64 to serialize DECIMAL logical types as base64 encoded binary data and\nNUMERIC to serialize Connect DECIMAL logical type values in JSON/JSON_SR as a number representing the decimal value.",
          "group": "Additional Configs",
          "alias": "json.output.decimal.format",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.decimal.format",
          "default_value": "BASE64"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "type": "BOOLEAN",
          "documentation": "Specify if the Serializer should attempt to register the Schema.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.auto.register.schemas"
        },
        {
          "name": "value.converter.use.latest.version",
          "type": "BOOLEAN",
          "documentation": "Use latest version of schema in subject for serialization when auto.register.schemas is false.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.latest.version"
        },
        {
          "name": "value.converter.latest.compatibility.strict",
          "type": "BOOLEAN",
          "documentation": "Verify latest subject version is backward compatible when `use.latest.version` is `true`.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "type": "STRING",
          "default_value": "TopicNameStrategy",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "alias": "key.subject.name.strategy",
          "documentation": "How to construct the subject name for key schema registration.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "key.converter.key.subject.name.strategy"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "default_value": "TopicNameStrategy",
          "alias": "subject.name.strategy,value.subject.name.strategy",
          "documentation": "Determines how to construct the subject name under which the value schema is registered with Schema Registry.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.value.subject.name.strategy"
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.reference.subject.name.strategy"
        },
        {
          "name": "value.converter.allow.optional.map.keys",
          "type": "BOOLEAN",
          "documentation": "Allow optional string map key when converting from Connect Schema to Avro Schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions",
          "type": "BOOLEAN",
          "default_value": "false",
          "documentation": "Whether to flatten singleton unions. Applicable for Avro and JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2",
          "type": "BOOLEAN",
          "documentation": "Whether proto2 optionals are supported. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to flatten unions (oneofs). Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "header.converter",
          "documentation": "The converter class for the headers. This is used to serialize and deserialize the headers of the messages.",
          "recommended_values": [
            "org.apache.kafka.connect.storage.SimpleHeaderConverter",
            "org.apache.kafka.connect.storage.StringConverter",
            "org.apache.kafka.connect.json.JsonConverter",
            "org.apache.kafka.connect.converters.BooleanConverter",
            "org.apache.kafka.connect.converters.DoubleConverter",
            "org.apache.kafka.connect.converters.FloatConverter",
            "org.apache.kafka.connect.converters.IntegerConverter",
            "org.apache.kafka.connect.converters.LongConverter",
            "org.apache.kafka.connect.converters.ShortConverter"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "auto.restart.on.user.error"
        },
        {
          "name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "dynamic.mapper": {
            "name": "value.converter.auto.register.schemas.mapper"
          }
        },
        {
          "name": "value.converter.use.latest.version",
          "dynamic.mapper": {
            "name": "value.converter.use.latest.version.mapper"
          }
        },
        {
          "name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.reference.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter"
        }
      ]
    }
  ],
  "all_config_def_names": [
    "after.state.only",
    "bigint.unsigned.handling.mode",
    "binary.handling.mode",
    "cleanup.policy",
    "column.exclude.list",
    "connector.class",
    "database.connectionTimeZone",
    "database.exclude.list",
    "database.history.skip.unparseable.ddl",
    "database.history.store.only.captured.tables.ddl",
    "database.hostname",
    "database.include.list",
    "database.password",
    "database.port",
    "database.server.name",
    "database.ssl.mode",
    "database.user",
    "datapreview.schemas.enable",
    "datatype.propagate.source.type",
    "decimal.handling.mode",
    "enable.time.adjuster",
    "event.deserialization.failure.handling.mode",
    "event.processing.failure.handling.mode",
    "heartbeat.interval.ms",
    "inconsistent.schema.handling.mode",
    "kafka.api.key",
    "kafka.api.secret",
    "kafka.auth.mode",
    "kafka.service.account.id",
    "key.converter.reference.subject.name.strategy",
    "max.batch.size",
    "name",
    "output.data.format",
    "output.key.format",
    "poll.interval.ms",
    "provide.transaction.metadata",
    "schema.context.name",
    "signal.data.collection",
    "snapshot.locking.mode",
    "snapshot.mode",
    "table.exclude.list",
    "table.include.list",
    "tasks.max",
    "time.precision.mode",
    "tombstones.on.delete"
  ],
  "all_connector_configs": [
    {
      "name": "database.history.kafka.topic",
      "value": "dbhistory.${database.server.name}.{{.logicalClusterId}}"
    },
    {
      "name": "database.history.kafka.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "database.history.consumer.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "database.history.producer.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "database.history.producer.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "database.history.consumer.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "database.server.id",
      "value": "{{.numericClusterId}}"
    },
    {
      "name": "producer.override.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "admin.override.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "topic.creation.default.cleanup.policy",
      "value": "${cleanup.policy}"
    },
    {
      "name": "custom.metric.tags",
      "value": "connector={{.logicalClusterId}},version=v1"
    },
    {
      "name": "connector.endpoint",
      "value": "${database.hostname}"
    },
    {
      "name": "consumer.override.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "producer.override.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "admin.override.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "producer.override.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "consumer.override.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "admin.override.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "producer.override.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "admin.override.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "value.converter.schema.registry.url",
      "switch": {
        "output.data.format": {
          "AVRO": "${schema.registry.url}",
          "JSON_SR": "${schema.registry.url}",
          "PROTOBUF": "${schema.registry.url}"
        }
      }
    },
    {
      "name": "value.converter.basic.auth.user.info",
      "switch": {
        "output.data.format": {
          "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
          "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
          "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
        }
      }
    },
    {
      "name": "key.converter.schema.registry.url",
      "switch": {
        "output.key.format": {
          "AVRO": "${schema.registry.url}",
          "JSON_SR": "${schema.registry.url}",
          "PROTOBUF": "${schema.registry.url}"
        }
      }
    },
    {
      "name": "key.converter.basic.auth.user.info",
      "switch": {
        "output.key.format": {
          "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
          "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
          "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
        }
      }
    }
  ]
}