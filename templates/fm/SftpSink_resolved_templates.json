{
  "templates": [
    {
      "template_id": "SftpSink",
      "connector_type": "SINK",
      "connector.class": "io.confluent.connect.sftp.SftpSinkConnector",
      "config_defs": [
        {
          "name": "output.data.format",
          "type": "STRING",
          "importance": "HIGH",
          "group": "Output messages",
          "order_in_group": 1,
          "default_value": "${input.data.format}",
          "default_value_provider": {
            "name": "data.format.provider"
          },
          "display_name": "Output message format",
          "documentation": "Set the output message format for values. Valid entries are AVRO, JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO. Note that the output message format defaults to the value in the Input Message Format field. If either PROTOBUF or JSON_SR is selected as the input message format, you should select one explicitly.",
          "recommended_values": [
            "AVRO",
            "JSON"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "sftp.working.dir",
          "type": "STRING",
          "required": false,
          "importance": "MEDIUM",
          "group": "SFTP Details",
          "order_in_group": 6,
          "default_value": "/home/${sftp.username}",
          "display_name": "SFTP Working Directory",
          "documentation": "Path of the top level directory where the connector should write to (defaults to /home/${sftp.username})."
        },
        {
          "name": "compression.codec",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Organize my data by...",
          "order_in_group": 10,
          "display_name": "Compression Type",
          "documentation": "Compression type for files. 'deflate', 'snappy' and 'bzip2' can be used when the output format is AVRO; 'gzip' can be used when the output format is JSON.",
          "recommended_values": [
            "AVRO - deflate",
            "AVRO - snappy",
            "AVRO - bzip2",
            "JSON - gzip"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "format.class",
          "switch": {
            "output.data.format": {
              "AVRO": "io.confluent.connect.sftp.sink.format.avro.AvroFormat",
              "JSON": "io.confluent.connect.sftp.sink.format.json.JsonFormat"
            }
          }
        },
        {
          "name": "schema.cache.size",
          "value": "1000"
        },
        {
          "name": "enhanced.avro.schema.support",
          "value": "true"
        },
        {
          "name": "connect.meta.data",
          "value": "false"
        },
        {
          "name": "filename.offset.zero.pad.width",
          "value": "10"
        },
        {
          "name": "key.converter.schemas.enable",
          "value": "false"
        },
        {
          "name": "key.converter",
          "value": "org.apache.kafka.connect.converters.ByteArrayConverter"
        },
        {
          "name": "avro.codec",
          "switch": {
            "compression.codec": {
              "AVRO - deflate": "deflate",
              "AVRO - snappy": "snappy",
              "AVRO - bzip2": "bzip2"
            }
          }
        },
        {
          "name": "sftp.compression.type",
          "switch": {
            "compression.codec": {
              "JSON - gzip": "gzip"
            }
          }
        },
        {
          "name": "storage.class",
          "value": "io.confluent.connect.sftp.sink.storage.SftpSinkStorage"
        },
        {
          "name": "sftp.working.dir"
        }
      ]
    },
    {
      "template_id": "common",
      "global_validators": [
        {
          "name": "required",
          "priority": "HIGHEST"
        },
        {
          "name": "recommended.values",
          "priority": "HIGHER"
        }
      ],
      "abstract": true,
      "config_defs": [
        {
          "name": "connector.class",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 1,
          "display_name": "Connector class"
        },
        {
          "name": "name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 2,
          "display_name": "Connector name",
          "documentation": "Sets a name for your connector."
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "KAFKA_API_KEY",
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 1,
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.",
          "recommended_values": [
            "SERVICE_ACCOUNT",
            "KAFKA_API_KEY"
          ]
        },
        {
          "name": "kafka.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka API Key",
          "documentation": "Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY."
        }
      ],
      "connector_configs": [
        {
          "name": "tasks.max"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "errors.log.enable",
          "value": "true"
        },
        {
          "name": "errors.log.include.messages",
          "value": "false"
        },
        {
          "name": "errors.retry.timeout",
          "value": "300000"
        },
        {
          "name": "errors.retry.delay.max.ms",
          "value": "30000"
        },
        {
          "name": "value.converter.ignore.modern.dialects",
          "value": "true"
        }
      ]
    },
    {
      "template_id": "common-kafka-connectivity",
      "abstract": true,
      "config_defs": [],
      "connector_configs": [
        {
          "name": "consumer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "producer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "producer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "consumer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "admin.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "producer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "consumer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "admin.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "consumer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "admin.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        }
      ]
    },
    {
      "template_id": "common-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.service.account.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka Service Account",
          "documentation": "The Service Account that will be used to generate the API keys to communicate with Kafka Cluster."
        },
        {
          "name": "kafka.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 3,
          "display_name": "Kafka API Secret",
          "documentation": "Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.",
          "dependents": [
            "kafka.api.key"
          ]
        },
        {
          "name": "topics",
          "type": "LIST",
          "required": true,
          "importance": "HIGH",
          "group": "Which topics do you want to get data from?",
          "order_in_group": 1,
          "display_name": "Topic names",
          "documentation": "Identifies the topic name or a comma-separated list of topic names.",
          "dependents": [
            "kafka.api.secret"
          ],
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "max.poll.interval.ms",
          "type": "LONG",
          "required": false,
          "importance": "LOW",
          "group": "Consumer configuration",
          "order_in_group": 1,
          "display_name": "Max poll interval(ms)",
          "default_value": "300000",
          "documentation": "The maximum delay between subsequent consume requests to Kafka. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 300000 milliseconds (5 minutes)."
        },
        {
          "name": "max.poll.records",
          "type": "LONG",
          "required": false,
          "importance": "LOW",
          "group": "Consumer configuration",
          "order_in_group": 2,
          "display_name": "Max poll records",
          "default_value": "500",
          "documentation": "The maximum number of records to consume from Kafka in a single request. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 500 records."
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "all",
          "display_name": "errors.tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "errors.deadletterqueue.topic.name",
          "type": "STRING",
          "importance": "LOW",
          "group": "Which topics do you want to get data from?",
          "order_in_group": 2,
          "display_name": "Dead Letter Queue Topic Name",
          "documentation": "The name of the topic to be used as the dead letter queue (DLQ) for messages that result in an error when processed by this sink connector, or its transformations or converters. Defaults to 'dlq-${connector}' if not set. The DLQ topic will be created automatically if it does not exist. You can provide ``${connector}`` in the value to use it as a placeholder for the logical cluster ID.",
          "default_value": "dlq-${connector}"
        }
      ],
      "connector_configs": [
        {
          "name": "topics"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "errors.deadletterqueue.topic.name",
          "dynamic.mapper": {
            "name": "errors.deadletterqueue.topic.mapper"
          }
        },
        {
          "name": "errors.deadletterqueue.topic.replication.factor",
          "value": "3"
        },
        {
          "name": "errors.deadletterqueue.context.headers.enable",
          "value": "true"
        },
        {
          "name": "consumer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "consumer.override.max.poll.interval.ms",
          "value": "${max.poll.interval.ms}"
        },
        {
          "name": "consumer.override.max.poll.records",
          "value": "${max.poll.records}"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        }
      ]
    },
    {
      "template_id": "schema-registry",
      "abstract": true,
      "config_defs": [
        {
          "name": "schema.context.name",
          "type": "STRING",
          "group": "Schema Config",
          "order_in_group": 1,
          "importance": "MEDIUM",
          "display_name": "Schema context",
          "documentation": "Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.",
          "default_value": "default",
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": []
    },
    {
      "template_id": "blob-store-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "topics.dir",
          "type": "STRING",
          "required": false,
          "default_value": "topics",
          "importance": "HIGH",
          "group": "Organize my data by...",
          "order_in_group": 1,
          "display_name": "Topic directory",
          "documentation": "Top-level directory where ingested data is stored."
        },
        {
          "name": "path.format",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Organize my data by...",
          "default_value": "'year'=YYYY/'month'=MM/'day'=dd/'hour'=HH",
          "order_in_group": 2,
          "display_name": "Path format",
          "documentation": "This configuration is used to set the format of the data directories when partitioning with TimeBasedPartitioner. The format set in this configuration converts the Unix timestamp to a valid directory string. To organize files like this example, filesystem://store-name/json_logs/daily/<Topic-Name>/dt=2020-02-06/hr=09/<files>, use the properties: topics.dir=json_logs/daily, path.format='dt'=YYYY-MM-dd/'hr'=HH, and time.interval=HOURLY.",
          "dependents": [
            "timestamp.field"
          ],
          "sanitizers": [
            {
              "name": "trim.blank.string"
            }
          ]
        },
        {
          "name": "time.interval",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "Organize my data by...",
          "order_in_group": 3,
          "display_name": "Time interval",
          "documentation": "Partitioning interval of data, according to the time ingested to storage.",
          "recommended_values": [
            "DAILY",
            "HOURLY"
          ]
        },
        {
          "name": "rotate.schedule.interval.ms",
          "type": "INT",
          "default_value": "-1",
          "importance": "MEDIUM",
          "group": "Organize my data by...",
          "order_in_group": 4,
          "documentation": "Scheduled rotation uses rotate.schedule.interval.ms to close the file and upload to storage on a regular basis using the current time, rather than the record time. Setting rotate.schedule.interval.ms is nondeterministic and will invalidate exactly-once guarantees.",
          "display_name": "Maximum span of record time (in ms) before scheduled rotation"
        },
        {
          "name": "rotate.interval.ms",
          "type": "INT",
          "default_value": "${time.interval}",
          "default_value_provider": {
            "name": "rotation.config.provider"
          },
          "importance": "HIGH",
          "group": "Organize my data by...",
          "order_in_group": 5,
          "documentation": "The connectorâ€™s rotation interval specifies the maximum timespan (in milliseconds) a file can remain open and ready for additional records. In other words, when using rotate.interval.ms, the timestamp for each file starts with the timestamp of the first record inserted in the file. The connector closes and uploads a file to the blob store when the next record's timestamp does not fit into the file's rotate.interval time span from the first record's timestamp. If the connector has no more records to process, the connector may keep the file open until the connector can process another record (which can be a long time).",
          "display_name": "Maximum span of record time (in ms) before rotation"
        },
        {
          "name": "flush.size",
          "type": "INT",
          "required": false,
          "default_value": "1000",
          "importance": "HIGH",
          "group": "Organize my data by...",
          "order_in_group": 6,
          "display_name": "Flush size",
          "documentation": "Number of records written to storage before invoking file commits."
        },
        {
          "name": "timestamp.field",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Organize my data by...",
          "default_value": "",
          "order_in_group": 7,
          "display_name": "Timestamp field name",
          "documentation": "Sets the field that contains the timestamp used for the TimeBasedPartitioner",
          "dependents": [
            "path.format"
          ]
        },
        {
          "name": "timezone",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Organize my data by...",
          "default_value": "UTC",
          "order_in_group": 8,
          "display_name": "Timezone",
          "documentation": "Sets the timezone used by the TimeBasedPartitioner.",
          "recommender": {
            "name": "timezone"
          }
        },
        {
          "name": "locale",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Organize my data by...",
          "default_value": "en",
          "order_in_group": 9,
          "display_name": "Locale",
          "documentation": "Sets the locale to use with TimeBasedPartitioner.",
          "recommender": {
            "name": "locale"
          }
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        }
      ],
      "connector_configs": [
        {
          "name": "partition.duration.ms",
          "switch": {
            "time.interval": {
              "DAILY": "86400000",
              "HOURLY": "3600000"
            }
          }
        },
        {
          "name": "flush.size"
        },
        {
          "name": "topics.dir"
        },
        {
          "name": "path.format"
        },
        {
          "name": "partitioner.class",
          "value": "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
        },
        {
          "name": "locale"
        },
        {
          "name": "timezone"
        },
        {
          "name": "timestamp.extractor",
          "switch": {
            "timestamp.field": {
              "": "Record",
              "DEFAULT": "RecordField"
            }
          }
        },
        {
          "name": "timestamp.field",
          "switch": {
            "timestamp.field": {
              "": "timestamp",
              "DEFAULT": "${timestamp.field}"
            }
          }
        },
        {
          "name": "rotate.interval.ms"
        },
        {
          "name": "rotate.schedule.interval.ms"
        }
      ]
    },
    {
      "template_id": "input-data-format",
      "abstract": true,
      "config_defs": [
        {
          "name": "input.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "JSON",
          "importance": "HIGH",
          "alias": "data.format",
          "group": "Input messages",
          "order_in_group": 1,
          "display_name": "Input Kafka record value format",
          "documentation": "Sets the input Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, JSON or BYTES. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON",
            "BYTES"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "value.converter.schemas.enable",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "alias": "schemas.enable",
          "display_name": "value.converter.schemas.enable",
          "documentation": "Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.replace.null.with.default",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "alias": "replace.null.with.default",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.replace.null.with.default",
          "documentation": "Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.ignore.default.for.nullables",
          "alias": "ignore.default.for.nullables",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.ignore.default.for.nullables",
          "documentation": "When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters."
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "type": "BOOLEAN",
          "documentation": "Whether to scrub invalid names by replacing invalid characters with valid characters. Applicable for Avro and Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.scrub.invalid.names"
        }
      ],
      "connector_configs": [
        {
          "name": "value.converter",
          "switch": {
            "input.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "BYTES": "org.apache.kafka.connect.converters.ByteArrayConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "value.converter.schemas.enable"
        },
        {
          "name": "value.converter.replace.null.with.default"
        },
        {
          "name": "value.converter.schema.registry.url",
          "switch": {
            "input.data.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "switch": {
            "input.data.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "switch": {
            "input.data.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "value.converter.ignore.default.for.nullables"
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "dynamic.mapper": {
            "name": "value.converter.scrub.invalid.names.mapper"
          }
        }
      ]
    },
    {
      "template_id": "sftp-common",
      "abstract": true,
      "config_defs": [
        {
          "name": "sftp.host",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "SFTP Details",
          "order_in_group": 1,
          "display_name": "SFTP Host",
          "documentation": "Host address of the SFTP server."
        },
        {
          "name": "sftp.port",
          "type": "INT",
          "required": false,
          "importance": "MEDIUM",
          "group": "SFTP Details",
          "order_in_group": 2,
          "default_value": 22,
          "display_name": "SFTP Port",
          "documentation": "Port number of the SFTP server."
        },
        {
          "name": "sftp.username",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "SFTP Details",
          "order_in_group": 3,
          "display_name": "Username",
          "documentation": "Username for the SFTP connection."
        },
        {
          "name": "sftp.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "SFTP Details",
          "order_in_group": 4,
          "display_name": "Password",
          "documentation": "Password for the SFTP connection (not required if using TLS)."
        },
        {
          "name": "tls.pemfile",
          "type": "PASSWORD",
          "required": "false",
          "importance": "HIGH",
          "group": "SFTP Details",
          "order_in_group": 5,
          "display_name": "PEM File",
          "documentation": "PEM file to be used for authentication via TLS."
        },
        {
          "name": "tls.passphrase",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "SFTP Details",
          "order_in_group": 6,
          "display_name": "TLS passphrase",
          "documentation": "Passphrase that will be used to decrypt the private key if the given private key is encrypted."
        }
      ],
      "connector_configs": [
        {
          "name": "sftp.host"
        },
        {
          "name": "sftp.port"
        },
        {
          "name": "sftp.username"
        },
        {
          "name": "sftp.password"
        },
        {
          "name": "tls.passphrase"
        },
        {
          "name": "tls.pemfile"
        },
        {
          "name": "connector.endpoint",
          "value": "${sftp.host}"
        }
      ]
    },
    {
      "template_id": "super",
      "abstract": true,
      "config_defs": [
        {
          "name": "auto.restart.on.user.error",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Auto-restart policy",
          "order_in_group": 1,
          "display_name": "Enable Connector Auto-restart",
          "documentation": "Enable connector to automatically restart on user-actionable errors."
        },
        {
          "name": "value.converter.enhanced.avro.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information and Enums. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data",
          "type": "BOOLEAN",
          "documentation": "Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to generate an index suffix for unions. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums",
          "type": "BOOLEAN",
          "documentation": "Whether to represent enums as integers. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should be specified with an optional label. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls",
          "type": "BOOLEAN",
          "documentation": "Whether to generate a struct variable for null values. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should use primitive wrapper messages. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives",
          "type": "BOOLEAN",
          "documentation": "Whether a wrapper message should be interpreted as a raw primitive at root level. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties",
          "type": "BOOLEAN",
          "documentation": "Whether to allow additional properties for object schemas. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired",
          "type": "BOOLEAN",
          "documentation": "Whether to set non-required properties to be optional. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format",
          "type": "STRING",
          "recommended_values": [
            "BASE64",
            "NUMERIC"
          ],
          "documentation": "Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:\nBASE64 to serialize DECIMAL logical types as base64 encoded binary data and\nNUMERIC to serialize Connect DECIMAL logical type values in JSON/JSON_SR as a number representing the decimal value.",
          "group": "Additional Configs",
          "alias": "json.output.decimal.format",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.decimal.format",
          "default_value": "BASE64"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "type": "BOOLEAN",
          "documentation": "Specify if the Serializer should attempt to register the Schema.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.auto.register.schemas"
        },
        {
          "name": "value.converter.use.latest.version",
          "type": "BOOLEAN",
          "documentation": "Use latest version of schema in subject for serialization when auto.register.schemas is false.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.latest.version"
        },
        {
          "name": "value.converter.latest.compatibility.strict",
          "type": "BOOLEAN",
          "documentation": "Verify latest subject version is backward compatible when `use.latest.version` is `true`.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "type": "STRING",
          "default_value": "TopicNameStrategy",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "alias": "key.subject.name.strategy",
          "documentation": "How to construct the subject name for key schema registration.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "key.converter.key.subject.name.strategy"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "default_value": "TopicNameStrategy",
          "alias": "subject.name.strategy,value.subject.name.strategy",
          "documentation": "Determines how to construct the subject name under which the value schema is registered with Schema Registry.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.value.subject.name.strategy"
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.reference.subject.name.strategy"
        },
        {
          "name": "value.converter.allow.optional.map.keys",
          "type": "BOOLEAN",
          "documentation": "Allow optional string map key when converting from Connect Schema to Avro Schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions",
          "type": "BOOLEAN",
          "default_value": "false",
          "documentation": "Whether to flatten singleton unions. Applicable for Avro and JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2",
          "type": "BOOLEAN",
          "documentation": "Whether proto2 optionals are supported. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to flatten unions (oneofs). Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "header.converter",
          "documentation": "The converter class for the headers. This is used to serialize and deserialize the headers of the messages.",
          "recommended_values": [
            "org.apache.kafka.connect.converters.BooleanConverter",
            "org.apache.kafka.connect.converters.ByteArrayConverter",
            "org.apache.kafka.connect.converters.DoubleConverter",
            "org.apache.kafka.connect.converters.FloatConverter",
            "org.apache.kafka.connect.converters.IntegerConverter",
            "org.apache.kafka.connect.converters.LongConverter",
            "org.apache.kafka.connect.converters.ShortConverter",
            "org.apache.kafka.connect.json.JsonConverter",
            "org.apache.kafka.connect.storage.SimpleHeaderConverter",
            "org.apache.kafka.connect.storage.StringConverter"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "auto.restart.on.user.error"
        },
        {
          "name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "dynamic.mapper": {
            "name": "value.converter.auto.register.schemas.mapper"
          }
        },
        {
          "name": "value.converter.use.latest.version",
          "dynamic.mapper": {
            "name": "value.converter.use.latest.version.mapper"
          }
        },
        {
          "name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.reference.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter"
        },
        {
          "name": "key.converter.use.apache.http.client"
        },
        {
          "name": "value.converter.use.apache.http.client"
        }
      ]
    },
    {
      "template_id": "super-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "consumer.override.auto.offset.reset",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "consumer.override.auto.offset.reset",
          "documentation": "Defines the behavior of the consumer when there is no committed position (which occurs when the group is first initialized) or when an offset is out of range. You can choose either to reset the position to the â€œearliestâ€ offset (the default) or the â€œlatestâ€ offset. You can also select â€œnoneâ€ if you would rather set the initial offset yourself and you are willing to handle out of range errors manually. More details: https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#auto-offset-reset",
          "recommended_values": [
            "earliest",
            "latest",
            "none"
          ]
        },
        {
          "name": "consumer.override.isolation.level",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "consumer.override.isolation.level",
          "documentation": "Controls how to read messages written transactionally. If set to read_committed, consumer.poll() will only return transactional messages which have been committed. If set to read_uncommitted (the default), consumer.poll() will return all messages, even transactional messages which have been aborted. Non-transactional messages will be returned unconditionally in either mode.  More details: https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#isolation-level",
          "recommended_values": [
            "read_committed",
            "read_uncommitted"
          ]
        },
        {
          "name": "topics.regex",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Which topics do you want to get data from?",
          "display_name": "Topics Regex",
          "documentation": "A regular expression that matches the names of the topics to consume from. This is useful when you want to consume from multiple topics that match a certain pattern without having to list them all individually."
        }
      ],
      "connector_configs": [
        {
          "name": "consumer.override.auto.offset.reset"
        },
        {
          "name": "consumer.override.isolation.level"
        },
        {
          "name": "topics.regex"
        }
      ]
    }
  ]
}