{
  "templates": [
    {
      "template_id": "MySqlCdcSourceV2",
      "connector_type": "SOURCE",
      "connector.class": "io.debezium.connector.v2.mysql.MySqlConnectorV2",
      "config_defs": [
        {
          "name": "authentication.method",
          "type": "STRING",
          "required": false,
          "default_value": "Password",
          "importance": "HIGH",
          "group": "Authentication method",
          "order_in_group": 1,
          "display_name": "Authentication method",
          "documentation": "Select how you want to authenticate with the database. Valid options are ``IAM Roles`` and ``Password``.",
          "recommended_values": [
            "IAM Roles",
            "Password"
          ]
        },
        {
          "name": "secret.manager.enabled",
          "group": "Authentication method",
          "order_in_group": 2
        },
        {
          "name": "secret.manager"
        },
        {
          "name": "secret.manager.managed.configs",
          "recommended_values": [
            "database.hostname",
            "database.port",
            "database.user",
            "database.password"
          ]
        },
        {
          "name": "secret.manager.provider.integration.id"
        },
        {
          "name": "provider.integration.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Authentication method",
          "order_in_group": 2,
          "display_name": "Provider Integration",
          "documentation": "Select an existing integration that has access to your resource."
        },
        {
          "name": "database.hostname",
          "required": true,
          "documentation": "IP address or hostname of the MySQL database server."
        },
        {
          "name": "database.port",
          "required": true,
          "documentation": "Port number of the MySQL database server."
        },
        {
          "name": "database.user",
          "required": true,
          "documentation": "The name of the MySQL database user that has the required authorization."
        },
        {
          "name": "database.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "display_name": "Database password",
          "documentation": "Password for the MySQL database user that has the required authorization"
        },
        {
          "name": "database.aws.region",
          "type": "STRING",
          "required": false,
          "documentation": "The AWS region of the MySQL database server for RDS/Aurora.",
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "display_name": "Database AWS region"
        },
        {
          "name": "database.ssl.mode",
          "type": "STRING",
          "required": false,
          "default_value": "preferred",
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "order_in_group": 5,
          "display_name": "SSL mode",
          "documentation": "Whether to use an encrypted connection to the MySQL server. Possible settings are: `disabled`, `preferred`, `required`, `verify_ca`, and `verify_identity`. \n`disabled` specifies the use of an unencrypted connection. \n`preferred` establishes an encrypted connection if the server supports secure connections. If the server does not support secure connections, falls back to an unencrypted connection. \n`required` establishes an encrypted connection or fails if one cannot be made for any reason. \n`verify_ca` The connector behaves as when you set the `required` option, but it also verifies the server TLS certificate against the configured Certificate Authority (CA) certificates. If the server TLS certificate does not match any valid CA certificates, the connector fails. \n`verify_identity` The connector behaves as when you set the `verify_ca` option, but it also verifies that the server certificate matches the host of the remote connection.",
          "recommended_values": [
            "preferred",
            "disabled",
            "required",
            "verify_ca",
            "verify_identity"
          ]
        },
        {
          "name": "database.ssl.keystore",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "How should we connect to your database?",
          "order_in_group": 6,
          "display_name": "SSL Keystore",
          "documentation": "Path to the SSL keystore file for MySQL connection. Only needed when SSL certificate verification is required (verify_ca or verify_identity modes)."
        },
        {
          "name": "database.ssl.keystore.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "How should we connect to your database?",
          "order_in_group": 7,
          "display_name": "SSL Keystore Password",
          "documentation": "Password for the SSL keystore file for MySQL connection. Only needed when SSL certificate verification is required and the keystore is password-protected."
        },
        {
          "name": "database.ssl.truststore",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "How should we connect to your database?",
          "order_in_group": 8,
          "display_name": "SSL Truststore",
          "documentation": "Path to the SSL truststore file for MySQL connection. Only needed when SSL certificate verification is required (verify_ca or verify_identity modes)."
        },
        {
          "name": "database.ssl.truststore.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "How should we connect to your database?",
          "order_in_group": 9,
          "display_name": "SSL Truststore Password",
          "documentation": "Password for the SSL truststore file for MySQL connection. Only needed when SSL certificate verification is required and the truststore is password-protected."
        },
        {
          "name": "topic.prefix",
          "required": true,
          "documentation": "Topic prefix that provides a namespace (logical server name) for the particular MySQL database server or cluster in which Debezium is capturing changes. The prefix should be unique across all other connectors, since it is used as a topic name prefix for all Kafka topics that receive records from this connector. Only alphanumeric characters, hyphens, dots and underscores must be used. The connector automatically creates Kafka topics using the naming convention: `<topic.prefix>.<databaseName>.<tableName>`."
        },
        {
          "name": "schema.history.internal.kafka.topic",
          "type": "STRING",
          "required": false,
          "default_value": "dbhistory.${topic.prefix}.{{.logicalClusterId}}",
          "importance": "HIGH",
          "group": "How should we name your topic(s)?",
          "order_in_group": 2,
          "display_name": "Database schema history topic name",
          "documentation": "The name of the topic for the database schema history. A new topic with provided name is created, if it doesn't already exist. If the topic already exists, ensure that it has a single partition, infinite retention period and is not in use by any other connector. If no value is provided, the name defaults to ``dbhistory.<topic-prefix>.<lcc-id>``.",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "signal.data.collection",
          "type": "STRING",
          "required": false,
          "importance": "MEDIUM",
          "group": "Database config",
          "order_in_group": 1,
          "display_name": "Signal data collection",
          "documentation": "Fully-qualified name of the data collection that needs to be used to send signals to the connector. Use the following format to specify the fully-qualified collection name: `databaseName.tableName` "
        },
        {
          "name": "read.only",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "MEDIUM",
          "group": "Additional Configs",
          "display_name": "Read only",
          "documentation": "Controls whether the connector writes watermarks to the signal data collection to track incremental snapshot progress. Set the value to ``true`` to enable the connector to use an incremental snapshot watermarking strategy that does not require writing to the signal data collection (useful for read-only database connections)."
        },
        {
          "name": "snapshot.mode",
          "documentation": "Specifies the criteria for running a snapshot when the connector starts. Possible settings are: `initial`, `initial_only`, `when_needed`, `never`, `schema_only`(deprecated), `no_data`, `schema_only_recovery`(deprecated), `recovery`. \n`initial` - the connector runs a snapshot only when no offsets have been recorded for the logical server name. \n`initial_only` - the connector runs a snapshot only when no offsets have been recorded for the logical server name and then stops; i.e. it will not read change events from the binlog. \n`when_needed` - the connector runs a snapshot upon startup whenever it deems it necessary. That is, when no offsets are available, or when a previously recorded offset specifies a binlog location or GTID that is not available in the server. \n`never` - the connector never uses snapshots. Upon first startup with a logical server name, the connector reads from the beginning of the binlog. Configure this behavior with care. It is valid only when the binlog is guaranteed to contain the entire history of the database. \n`schema_only` - Deprecated, use no_data instead. \n`no_data` - the connector runs a snapshot of the schemas and not the data. This setting is useful when you do not need the topics to contain a consistent snapshot of the data but need them to have only the changes since the connector was started. \n`schema_only_recovery` - Deprecated, use recovery instead. \n`recovery` - recovery setting for a connector that has already been capturing changes. When you restart the connector, this setting enables recovery of a corrupted or lost database schema history topic. You might set it periodically to \"clean up\" a database schema history topic that has been growing unexpectedly. Database schema history topics require infinite retention.",
          "recommended_values": [
            "initial",
            "initial_only",
            "when_needed",
            "never",
            "schema_only",
            "no_data",
            "schema_only_recovery",
            "recovery"
          ]
        },
        {
          "name": "snapshot.locking.mode",
          "type": "STRING",
          "required": false,
          "default_value": "minimal",
          "importance": "LOW",
          "group": "Connector config",
          "order_in_group": 2,
          "display_name": "Snapshot locking mode",
          "documentation": "Controls whether and how long the connector holds the global MySQL read lock, which prevents any updates to the database, while the connector is performing a snapshot. Possible settings are: `minimal`, `minimal_percona`, `extended`, and `none`. \n`minimal` - the connector holds the global read lock for just the initial portion of the snapshot, while the database schemas and other metadata are being read. The remaining work in a snapshot involves selecting all rows from each table. This is accomplished using a REPEATABLE READ transaction, even when the lock is no longer held and other MySQL clients are updating the database. \n`minimal_percona` - similar to `minimal` mode except the connector uses a (Percona-specific) backup lock. This mode does not flush tables to disk, is not blocked by long-running reads, and is available only in Percona Server. \n`extended` - blocks all writes for the duration of the snapshot. Use this setting if there are clients that are submitting operations that MySQL excludes from REPEATABLE READ semantics. \n`none` - prevents the connector from acquiring any table locks during the snapshot. While this setting is allowed with all snapshot modes, it is safe to use if and only if no schema changes are happening while the snapshot is running. For tables defined with MyISAM engine, the tables would still be locked despite this property being set as MyISAM acquires a table lock. This behavior is unlike InnoDB engine, which acquires row level locks.",
          "recommended_values": [
            "minimal",
            "minimal_percona",
            "extended",
            "none"
          ]
        },
        {
          "name": "database.include.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 3,
          "display_name": "Databases included",
          "documentation": "An optional, comma-separated list of regular expressions that match the names of the databases for which to capture changes. The connector does not capture changes in any database whose name is not in this list. By default, the connector captures changes in all databases.\nTo match the name of a database, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire name string of the database; it does not match substrings that might be present in a database name.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "database.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 4,
          "display_name": "Exclude Databases",
          "documentation": "A comma-separated list of regular expressions that match the names of databases from which you do not want the connector to capture changes. The connector captures changes in any database that is not named in the ``database.exclude.list``",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "table.include.list",
          "order_in_group": 5,
          "documentation": "An optional, comma-separated list of regular expressions that match fully-qualified table identifiers for tables whose changes you want to capture. When this property is set, the connector captures changes only from the specified tables. Each identifier is of the form `database.tableName`. By default, the connector captures changes in every non-system table in each schema whose changes are being captured. \nTo match the name of a table, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire identifier for the table; it does not match substrings that might be present in a table name. \nIf you include this property in the configuration, do not also set the ``table.exclude.list`` property."
        },
        {
          "name": "table.exclude.list",
          "order_in_group": 6,
          "documentation": "An optional, comma-separated list of regular expressions that match fully-qualified table identifiers for tables whose changes you do not want to capture. Each identifier is of the form `database.tableName`. When this property is set, the connector captures changes from every table that you do not specify. \nTo match the name of a table, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire identifier for the table; it does not match substrings that might be present in a table name. \nIf you include this property in the configuration, do not set the ``table.include.list`` property."
        },
        {
          "name": "column.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 7,
          "display_name": "Columns excluded",
          "documentation": "An optional, comma-separated list of regular expressions that match the fully-qualified names of columns to exclude from change event record values. Fully-qualified names for columns are of the form ``databaseName.tableName.columnName``. \nTo match the name of a column, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire name string of the column; it does not match substrings that might be present in a column name.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "inconsistent.schema.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "fail",
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 10,
          "display_name": "Inconsistent schema handling mode",
          "documentation": "Specifies how the connector should react to binlog events that belong to a table missing from internal schema representation. Possible settings are: `fail`, `skip`, and `warn`. \n`fail` - throws an exception that indicates the problematic event and its binlog offset, and causes the connector to stop. \n`skip` - passes over the problematic event and does not log anything. \n`warn` - logs the problematic event and its binlog offset and skips the event.",
          "recommended_values": [
            "fail",
            "skip",
            "warn"
          ]
        },
        {
          "name": "driver.connectionTimeZone",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Connector config",
          "order_in_group": 13,
          "display_name": "Connection time zone",
          "documentation": "Specifies how the server's session time zone is determined. This property can take one of three values: LOCAL, SERVER, or a user-defined time zone."
        },
        {
          "name": "connect.timeout.ms",
          "type": "LONG",
          "required": false,
          "default_value": "30000",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Connection Timeout (ms)",
          "documentation": "Maximum time to wait after trying to connect to the database before timing out, given in milliseconds. Defaults to 30 seconds (30,000 ms)."
        },
        {
          "name": "event.converting.failure.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "warn",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Event converting failure handling mode",
          "documentation": "Specify how failures during converting of event should be handled, including: 'fail' throw an exception that the column of event conversion is failed with unmatched schema type, causing the connector to be stopped. it could need schema recovery to covert successfully; 'warn' (the default) the value of column of event that conversion failed will be null and be logged with warn level; 'skip' the value of column of event that conversion failed will be null and be logged with debug level.",
          "recommended_values": [
            "warn",
            "fail",
            "skip"
          ]
        },
        {
          "name": "message.key.columns",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Columns primary key mapping",
          "documentation": "A semicolon-separated list of expressions that match fully-qualified tables and column(s) to be used as message key. Each expression must match the pattern '<fully-qualified table name>:<key columns>', where the fully qualified table name could be defined as ``<databaseName>.<tableName>`` and the key columns are a comma-separated list of columns representing the custom key. For any table without an explicit key configuration the table's primary key column(s) will be used as message key. Example: ``inventory.customers:pk1,pk2;(.*).purchaseorders:pk3,pk4``"
        },
        {
          "name": "column.include.list",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Include Columns",
          "documentation": "A comma-separated list of regular expressions that match the fully-qualified names of columns that should be included in change event record values. Fully-qualified names for columns are of the form databaseName.tableName.columnName. Do not set ``column.exclude.list`` if you set this property.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "skip.messages.without.change",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Enable skipping messages without change",
          "documentation": "Enable to skip publishing messages when there is no change in included columns. This would essentially filter messages to be sent when there is no change in columns included as per ``column.include.list`` or ``column.exclude.list``. Set the value to ``true`` to prevent the connector from capturing records when no changes are present in the included columns."
        },
        {
          "name": "snapshot.include.collection.list",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Snapshot mode include data collection",
          "documentation": "A comma-separated list of regular expressions that match the fully-qualified names (<databaseName>.<tableName>) of the tables to include in a snapshot. If not explicitly set, the connector defaults to snapshotting all tables listed in table.include.list. The specified items must be named in the connector’s table.include.list property. This property takes effect only if the connector’s snapshot.mode property is set to a value other than never.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "snapshot.tables.order.by.row.count",
          "type": "STRING",
          "required": false,
          "default_value": "disabled",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Initial snapshot tables order by row count",
          "documentation": "Controls the order in which tables are processed in the initial snapshot. A 'descending' value will order the tables by row count descending. A 'ascending' value will order the tables by row count ascending. A value of 'disabled' (the default) will disable ordering by row count.",
          "recommended_values": [
            "ascending",
            "descending",
            "disabled"
          ]
        },
        {
          "name": "bigint.unsigned.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "long",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "BigInt Unsigned Handling",
          "documentation": "Specify how BIGINT UNSIGNED columns should be represented in change events, including: 'precise' uses java.math.BigDecimal to represent values, which are encoded in the change events using a binary representation and Kafka Connect's 'org.apache.kafka.connect.data.Decimal' type; 'long' (the default) represents values using Java's 'long', which may not offer the precision but will be far easier to use in consumers.",
          "recommended_values": [
            "precise",
            "long"
          ]
        },
        {
          "name": "gtid.source.excludes",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Exclude GTID sources",
          "documentation": "A comma-separated list of regular expressions that match source domain IDs in the GTID set that the connector uses to find the binlog position on the MySQL server. When this property is set, the connector uses only the GTID ranges that have source UUIDs that do not match any of the specified exclude patterns."
        },
        {
          "name": "gtid.source.includes",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Include GTID sources",
          "documentation": "A comma-separated list of regular expressions that match source domain IDs in the GTID set used that the connector uses to find the binlog position on the MySQL server. When this property is set, the connector uses only the GTID ranges that have source UUIDs that match one of the specified include patterns."
        },
        {
          "name": "include.query",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Include original SQL query with in change events",
          "documentation": "Determines whether the connector should include the original SQL query that generated the change event. Note: This option requires MySQL be configured with the ``binlog_rows_query_log_events`` option set to ``ON``. Query will not be present for events generated from snapshot. WARNING: Enabling this option may expose tables or fields explicitly excluded or masked by including the original SQL statement in the change event. For this reason the default value is ``false``."
        },
        {
          "name": "include.schema.changes",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Include database schema changes",
          "documentation": "Whether the connector should publish changes in the database schema to a Kafka topic with the same name as the database server ID. Each schema change will be recorded using a key that contains the database name and whose value include logical description of the new schema and optionally the DDL statement(s). The default is ``false``. This is independent of how the connector internally records database schema history."
        },
        {
          "name": "enable.time.adjuster",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Enable Time Adjuster",
          "documentation": "MySQL allows user to insert year value as either 2-digit or 4-digit. In case of two digit the value is automatically mapped into 1970 - 2069. The values ``false`` - delegates the implicit conversion to the database. ``true`` - (the default) Debezium makes the conversion"
        },
        {
          "name": "incremental.snapshot.allow.schema.changes",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Allow schema changes during incremental snapshot if supported.",
          "documentation": "Detect schema change during an incremental snapshot and re-select a current chunk to avoid locking DDLs. Note that changes to a primary key are not supported and can cause incorrect results if performed during an incremental snapshot. Another limitation is that if a schema change affects only columns' default values, then the change won't be detected until the DDL is processed from the binlog stream. This doesn't affect the snapshot events' values, but the schema of snapshot events may have outdated defaults."
        },
        {
          "name": "table.ignore.builtin",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Ignore system databases",
          "documentation": "A Boolean value that specifies whether built-in system tables should be ignored. This applies regardless of the table include and exclude lists."
        },
        {
          "name": "use.nongraceful.disconnect",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Use non-graceful disconnect",
          "documentation": "Whether to use `socket.setSoLinger(true, 0)` when BinaryLogClient keepalive thread triggers a disconnect for a stale connection."
        },
        {
          "name": "schema.history.internal.skip.unparseable.ddl",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Connector config",
          "order_in_group": 11,
          "display_name": "Skip unparseable DDL",
          "documentation": "A Boolean value that specifies whether the connector should ignore malformed or unknown database statements (`true`), or stop processing so a human can fix the issue (`false`). Defaults to `false`. Consider setting this to `true` to ignore unparseable statements.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "schema.history.internal.store.only.captured.tables.ddl",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Connector config",
          "order_in_group": 12,
          "display_name": "Store only captured tables DDL",
          "documentation": "A Boolean value that specifies whether the connector records schema structures from all tables in a schema or database, or only from tables that are designated for capture. Defaults to `false`. \n`false` - During a database snapshot, the connector records the schema data for all non-system tables in the database, including tables that are not designated for capture. It’s best to retain the default setting. If you later decide to capture changes from tables that you did not originally designate for capture, the connector can easily begin to capture data from those tables, because their schema structure is already stored in the schema history topic. \n`true` - During a database snapshot, the connector records the table schemas only for the tables from which Debezium captures change events. If you change the default value, and you later configure the connector to capture data from other tables in the database, the connector lacks the schema information that it requires to capture change events from the tables.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "schema.history.internal.kafka.recovery.poll.interval.ms",
          "type": "LONG",
          "required": false,
          "default_value": "100",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Poll interval during database schema history recovery (ms)",
          "documentation": "An integer value that specifies the maximum number of milliseconds the connector should wait during startup/recovery while polling for persisted data. The default is 100ms."
        },
        {
          "name": "schema.history.internal.store.only.captured.databases.ddl",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Store only DDL that modifies tables of databases that are captured based on include/exclude lists",
          "documentation": "Controls what DDL will Debezium store in database schema history. By default (false) Debezium will store all incoming DDL statements. If set to true, then only DDL that manipulates a table from captured schema/database will be stored."
        },
        {
          "name": "schema.history.internal.kafka.query.timeout.ms",
          "type": "LONG",
          "required": false,
          "default_value": "3000",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Kafka admin client query timeout (ms)",
          "documentation": "The number of milliseconds to wait while fetching cluster information using Kafka admin client."
        },
        {
          "name": "schema.history.internal.kafka.create.timeout.ms",
          "type": "LONG",
          "required": false,
          "default_value": "30000",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Kafka admin client create timeout (ms)",
          "documentation": "The number of milliseconds to wait while create kafka history topic using Kafka admin client."
        },
        {
          "name": "time.precision.mode",
          "default_value": "adaptive_time_microseconds",
          "documentation": "Time, date, and timestamps can be represented with different kinds of precisions: \n`adaptive_time_microseconds` captures the date, datetime and timestamp values exactly as in the database using either millisecond, microsecond, or nanosecond precision values based on the database column’s type. An exception is `TIME` type fields, which are always captured as microseconds. \n`connect` always represents time and timestamp values by using Kafka Connect’s built-in representations for `Time`, `Date`, and `Timestamp`, which use millisecond precision regardless of the database columns' precision.",
          "recommended_values": [
            "adaptive_time_microseconds",
            "connect"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "jdbc.creds.provider.class.name",
          "switch": {
            "authentication.method": {
              "IAM Roles": "io.confluent.credentialproviders.aws.AwsChainedAssumeRoleRdsCredsProvider",
              "DEFAULT": "io.confluent.credentialproviders.DefaultJdbcCredentialsProvider"
            }
          }
        },
        {
          "name": "bigint.unsigned.handling.mode"
        },
        {
          "name": "database.aws.region"
        },
        {
          "name": "jdbc.creds.provider.user",
          "value": "${database.user}"
        },
        {
          "name": "jdbc.creds.provider.password",
          "value": "${database.password}"
        },
        {
          "name": "jdbc.creds.provider.hostname",
          "value": "${database.hostname}"
        },
        {
          "name": "jdbc.creds.provider.port",
          "value": "${database.port}"
        },
        {
          "name": "jdbc.creds.provider.aws.rds.region",
          "value": "${database.aws.region}"
        },
        {
          "name": "schema.history.internal.kafka.topic"
        },
        {
          "name": "schema.history.internal.kafka.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "schema.history.internal.consumer.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "schema.history.internal.producer.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "schema.history.internal.consumer.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "schema.history.internal.producer.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "schema.history.internal.consumer.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "schema.history.internal.producer.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "schema.history.internal.consumer.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "schema.history.internal.producer.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "schema.history.internal.consumer.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "schema.history.internal.producer.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "schema.history.internal.producer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "schema.history.internal.producer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "schema.history.internal.consumer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "schema.history.internal.consumer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "connect.timeout.ms"
        },
        {
          "name": "schema.history.internal.kafka.recovery.poll.interval.ms"
        },
        {
          "name": "schema.history.internal.kafka.recovery.attempts",
          "value": "100000"
        },
        {
          "name": "column.include.list"
        },
        {
          "name": "column.exclude.list"
        },
        {
          "name": "database.server.id",
          "value": "{{.numericClusterId}}"
        },
        {
          "name": "database.ssl.mode"
        },
        {
          "name": "database.ssl.keystore"
        },
        {
          "name": "database.ssl.keystore.password"
        },
        {
          "name": "database.ssl.truststore"
        },
        {
          "name": "database.ssl.truststore.password"
        },
        {
          "name": "database.include.list"
        },
        {
          "name": "database.exclude.list"
        },
        {
          "name": "enable.time.adjuster"
        },
        {
          "name": "gtid.source.excludes"
        },
        {
          "name": "gtid.source.includes"
        },
        {
          "name": "include.query"
        },
        {
          "name": "include.schema.changes"
        },
        {
          "name": "event.converting.failure.handling.mode"
        },
        {
          "name": "inconsistent.schema.handling.mode"
        },
        {
          "name": "incremental.snapshot.allow.schema.changes"
        },
        {
          "name": "message.key.columns"
        },
        {
          "name": "schema.history.internal.skip.unparseable.ddl"
        },
        {
          "name": "schema.history.internal.store.only.captured.databases.ddl"
        },
        {
          "name": "schema.history.internal.store.only.captured.tables.ddl"
        },
        {
          "name": "schema.history.internal.kafka.query.timeout.ms"
        },
        {
          "name": "schema.history.internal.kafka.create.timeout.ms"
        },
        {
          "name": "skip.messages.without.change"
        },
        {
          "name": "snapshot.include.collection.list"
        },
        {
          "name": "time.precision.mode"
        },
        {
          "name": "table.ignore.builtin"
        },
        {
          "name": "driver.enabledTLSProtocols",
          "value": "TLSv1.2"
        },
        {
          "name": "driver.connectionTimeZone"
        },
        {
          "name": "snapshot.locking.mode"
        },
        {
          "name": "snapshot.tables.order.by.row.count"
        },
        {
          "name": "signal.data.collection"
        },
        {
          "name": "read.only"
        },
        {
          "name": "use.nongraceful.disconnect"
        }
      ]
    },
    {
      "template_id": "common-debezium-source-v2",
      "abstract": true,
      "config_defs": [
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "database.hostname",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "order_in_group": 1,
          "display_name": "Database hostname",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "database.port",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "order_in_group": 2,
          "display_name": "Database port",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "database.user",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "order_in_group": 3,
          "display_name": "Database username"
        },
        {
          "name": "database.password",
          "type": "PASSWORD",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your database?",
          "order_in_group": 4,
          "display_name": "Database password"
        },
        {
          "name": "after.state.only",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Output messages",
          "order_in_group": 4,
          "display_name": "After-state only",
          "documentation": "Controls whether the generated Kafka record should contain only the state of the row after the event occurred.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "tombstones.on.delete",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Output messages",
          "order_in_group": 5,
          "display_name": "Tombstones on delete",
          "documentation": "Controls whether a tombstone event should be generated after a delete event. \n`true` - a delete operation is represented by a delete event and a subsequent tombstone event. \nfalse - only a delete event is emitted. \nAfter a source record is deleted, emitting the tombstone event (the default behavior) allows Kafka to completely delete all events that pertain to the key of the deleted row in case log compaction is enabled for the topic.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "topic.prefix",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we name your topic(s)?",
          "order_in_group": 1,
          "display_name": "Topic prefix",
          "documentation": "Defines the prefix to be applied to the topic name to which the connector pushes the Kafka records.",
          "sanitizers": [
            {
              "name": "trim"
            }
          ]
        },
        {
          "name": "snapshot.mode",
          "type": "STRING",
          "required": false,
          "default_value": "initial",
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 1,
          "display_name": "Snapshot mode"
        },
        {
          "name": "incremental.snapshot.chunk.size",
          "type": "INT",
          "required": false,
          "default_value": "1024",
          "importance": "MEDIUM",
          "group": "Additional Configs",
          "display_name": "Incremental snapshot chunk size",
          "documentation": "The maximum number of rows that the connector fetches and reads into memory during an incremental snapshot chunk. Increasing the chunk size improves efficiency by running fewer, larger snapshot queries. However, larger chunk sizes also require more memory to buffer the snapshot data. Adjust the chunk size to a value that provides the best performance in your environment."
        },
        {
          "name": "table.include.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 4,
          "display_name": "Tables included",
          "documentation": "An optional, comma-separated list of regular expressions that match fully-qualified table identifiers for tables whose changes you want to capture. When this property is set, the connector captures changes only from the specified tables. Each identifier is of the form `schemaName.tableName`. By default, the connector captures changes in every non-system table in each schema whose changes are being captured. \nTo match the name of a table, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire identifier for the table; it does not match substrings that might be present in a table name. \nIf you include this property in the configuration, do not also set the ``table.exclude.list`` property.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "table.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 5,
          "display_name": "Tables excluded",
          "documentation": "An optional, comma-separated list of regular expressions that match fully-qualified table identifiers for tables whose changes you do not want to capture. Each identifier is of the form `schemaName.tableName`. When this property is set, the connector captures changes from every table that you do not specify. \nTo match the name of a table, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire identifier for the table; it does not match substrings that might be present in a table name. \nIf you include this property in the configuration, do not set the ``table.include.list`` property.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "event.processing.failure.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "fail",
          "importance": "LOW",
          "group": "Connector config",
          "order_in_group": 6,
          "display_name": "Event processing failure handling mode",
          "documentation": "Specifies how the connector should react to exceptions during processing of events. Possible settings are: `fail`, `skip`, and `warn`. \n`fail` propagates the exception, indicates the offset of the problematic event, and causes the connector to stop. \n`warn` logs the offset of the problematic event, skips that event, and continues processing. \n`skip` skips the problematic event and continues processing.",
          "recommended_values": [
            "fail",
            "skip",
            "warn"
          ]
        },
        {
          "name": "schema.name.adjustment.mode",
          "type": "STRING",
          "required": false,
          "default_value": "none",
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 7,
          "display_name": "Schema name adjustment mode",
          "documentation": "Specifies how schema names should be adjusted for compatibility with the message converter used by the connector. Possible settings are: `none`, `avro`, and `avro_unicode`. \n`none` does not apply any adjustment. \n`avro` replaces the characters that cannot be used in the Avro type name with underscore. \n`avro_unicode` replaces the underscore or characters that cannot be used in the Avro type name with corresponding unicode like _uxxxx. Note: _ is an escape sequence like backslash in Java.",
          "recommended_values": [
            "none",
            "avro",
            "avro_unicode"
          ]
        },
        {
          "name": "field.name.adjustment.mode",
          "type": "STRING",
          "required": false,
          "default_value": "none",
          "importance": "MEDIUM",
          "group": "Connector config",
          "order_in_group": 8,
          "display_name": "Field name adjustment mode",
          "documentation": "Specifies how field names should be adjusted for compatibility with the message converter used by the connector. Possible settings are: `none`, `avro`, and `avro_unicode`. \n`none` does not apply any adjustment. \n`avro` replaces the characters that cannot be used in the Avro type name with underscore. \n`avro_unicode` replaces the underscore or characters that cannot be used in the Avro type name with corresponding unicode like _uxxxx. Note: _ is an escape sequence like backslash in Java.",
          "recommended_values": [
            "none",
            "avro",
            "avro_unicode"
          ]
        },
        {
          "name": "heartbeat.interval.ms",
          "type": "INT",
          "required": false,
          "default_value": "0",
          "importance": "LOW",
          "group": "Connector config",
          "order_in_group": 9,
          "display_name": "Heartbeat interval (ms)",
          "documentation": "Controls how frequently the connector sends heartbeat messages to a Kafka topic. The behavior of default value 0 is that the connector does not send heartbeat messages. Heartbeat messages are useful for monitoring whether the connector is receiving change events from the database. Heartbeat messages might help decrease the number of change events that need to be re-sent when a connector restarts. To send heartbeat messages, set this property to a positive integer, which indicates the number of milliseconds between heartbeat messages."
        },
        {
          "name": "column.propagate.source.type",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Propagate source types by columns",
          "documentation": "A comma-separated list of regular expressions matching fully-qualified names of columns that adds the column’s original type and original length as parameters to the corresponding field schemas in the emitted change records. When this property is set, the connector adds the following fields to the schema of event records with prefix ``__debezium.source.column``. These parameters propagate a column’s original type name and length (for variable-width types), respectively. Include '.*' to match all column types.'",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "snapshot.lock.timeout.ms",
          "type": "LONG",
          "required": false,
          "default_value": "10000",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Snapshot lock timeout (ms)",
          "documentation": "The maximum number of millis to wait for table locks at the beginning of a snapshot. If locks cannot be acquired in this time frame, the snapshot will be aborted. Defaults to 10 seconds."
        },
        {
          "name": "max.batch.size",
          "type": "INT",
          "required": false,
          "default_value": "2048",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Change event batch size",
          "documentation": "Maximum size of each batch of events that the connector processes. Defaults to 2048 with the allowed range is from 1 to 5000."
        },
        {
          "name": "poll.interval.ms",
          "type": "LONG",
          "required": false,
          "default_value": "500",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Poll interval (ms)",
          "documentation": "Time to wait for new change events to appear after receiving no events, given in milliseconds. Defaults to 500 ms."
        },
        {
          "name": "snapshot.delay.ms",
          "type": "LONG",
          "required": false,
          "default_value": "0",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Snapshot delay (milliseconds)",
          "documentation": "An interval in milliseconds that the connector should wait before performing a snapshot when the connector starts. Defaults to 0 ms."
        },
        {
          "name": "streaming.delay.ms",
          "type": "LONG",
          "required": false,
          "default_value": "60000",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Streaming delay (milliseconds)",
          "documentation": "A delay period after the snapshot is completed and the streaming begins, given in milliseconds. This delay helps prevent re-snapshotting in case the connector fails during the transition to streaming. Defaults to 60000 ms."
        },
        {
          "name": "skipped.operations",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "t",
          "display_name": "Skipped Operations",
          "documentation": "The comma-separated list of operations to skip during streaming, defined as: 'c' for inserts/create; 'u' for updates; 'd' for deletes, 't' for truncates, and 'none' to indicate nothing skipped. By default, only truncate operations will be skipped.",
          "recommended_values": [
            "c",
            "u",
            "d",
            "t",
            "none"
          ]
        },
        {
          "name": "provide.transaction.metadata",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Store transaction metadata information in a dedicated topic",
          "documentation": "Determines whether the connector generates events with transaction boundaries and enriches change event envelopes with transaction metadata."
        },
        {
          "name": "notification.enabled.channels",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Enabled notification channels names",
          "documentation": "List of notification channels names that are enabled. The following channels are available: ``log`` and ``sink``. When ``sink`` is enabled, the connector sends notifications to a topic specified by the ``notification.sink.topic.name`` property.",
          "recommended_values": [
            "log",
            "sink"
          ]
        },
        {
          "name": "notification.sink.topic.name",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Notification topic name",
          "documentation": "The name of the topic for the notifications. This is required in case ``sink`` is in the list of enabled channels."
        },
        {
          "name": "binary.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "bytes",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Binary handling mode",
          "documentation": "Specify how binary (blob, binary, etc.) columns should be represented in change events, including: 'bytes' represents binary data as byte array (default); 'base64' represents binary data as base64-encoded string; 'base64-url-safe' represents binary data as base64-url-safe-encoded string; 'hex' represents binary data as hex-encoded (base16) string",
          "recommended_values": [
            "bytes",
            "base64",
            "base64-url-safe",
            "hex"
          ]
        },
        {
          "name": "topic.heartbeat.prefix",
          "type": "STRING",
          "required": false,
          "default_value": "__debezium-heartbeat-{{.logicalClusterId}}",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Prefix name of heartbeat topic",
          "documentation": "Specifies the prefix of the heartbeat topic to which the connector sends heartbeat messages. The topic name has this pattern: ``<topic.heartbeat.prefix>.<topic.prefix>``. Defaults to ``__debezium-heartbeat-{{.logicalClusterId}}``."
        },
        {
          "name": "topic.transaction",
          "type": "STRING",
          "required": false,
          "default_value": "{{.logicalClusterId}}.transaction",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Transaction topic name",
          "documentation": "Controls the name of the topic to which the connector sends transaction metadata messages. The final transaction topic name has this pattern: ``<topic.prefix>.<topic.transaction>``. Defaults to ``{{.logicalClusterId}}.transaction``."
        },
        {
          "name": "incremental.snapshot.watermarking.strategy",
          "type": "STRING",
          "required": false,
          "default_value": "INSERT_INSERT",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Incremental snapshot watermarking strategy",
          "documentation": "Specify the strategy used for watermarking during an incremental snapshot: 'INSERT_INSERT' both open and close signal is written into signal data collection (default); 'INSERT_DELETE' only open signal is written on signal data collection, the close will delete the relative open signal.",
          "recommended_values": [
            "INSERT_INSERT",
            "INSERT_DELETE"
          ]
        },
        {
          "name": "key.converter.reference.subject.name.strategy",
          "type": "STRING",
          "importance": "HIGH",
          "group": "Schema Config",
          "order_in_group": 2,
          "display_name": "Key converter reference subject name strategy",
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for key. Valid entries are `DefaultReferenceSubjectNameStrategy` or `QualifiedReferenceSubjectNameStrategy`. Note that the subject reference name strategy can be selected only for `PROTOBUF` format with the default strategy being `DefaultReferenceSubjectNameStrategy`.",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "dependents": [
            "output.key.format"
          ]
        },
        {
          "name": "signal.kafka.topic",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Signal topic name",
          "documentation": "The name of the Kafka topic that the connector monitors for ad hoc signals. Note that you can currently send signal messages to this topic via the Confluent CLI."
        },
        {
          "name": "signal.enabled.channels",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Enabled channels names",
          "documentation": "A comma-separated list of channel names that are enabled for the connector. If not set, the connector enables only the ``source`` channel by default. Supported values are: \n``source`` (default): Signals are read from a signaling table in the source database. \n``kafka``: Signals are consumed from a Kafka topic.",
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "decimal.handling.mode",
          "type": "STRING",
          "required": false,
          "default_value": "precise",
          "importance": "MEDIUM",
          "group": "How should we handle data types?",
          "order_in_group": 1,
          "display_name": "Decimal handling mode",
          "documentation": "Specifies how the connector should handle values for `DECIMAL` and `NUMERIC` columns. Possible settings are: `precise`, `double`, and `string`. \n`precise` represents values by using `java.math.BigDecimal` to represent values in binary form in change events. `double` represents values by using double values, which might result in a loss of precision but which is easier to use. `string` encodes values as formatted strings, which are easy to consume but semantic information about the real type is lost.",
          "recommended_values": [
            "double",
            "precise",
            "string"
          ]
        },
        {
          "name": "time.precision.mode",
          "type": "STRING",
          "required": false,
          "default_value": "adaptive",
          "importance": "MEDIUM",
          "group": "How should we handle data types?",
          "order_in_group": 2,
          "display_name": "Time precision mode",
          "documentation": "Time, date, and timestamps can be represented with different kinds of precisions: \n`adaptive` captures the time and timestamp values exactly as in the database using either millisecond, microsecond, or nanosecond precision values based on the database column’s type. \n`adaptive_time_microseconds` captures the date, datetime and timestamp values exactly as in the database using either millisecond, microsecond, or nanosecond precision values based on the database column’s type. An exception is `TIME` type fields, which are always captured as microseconds. \n`connect` always represents time and timestamp values by using Kafka Connect’s built-in representations for `Time`, `Date`, and `Timestamp`, which use millisecond precision regardless of the database columns' precision.",
          "recommended_values": [
            "adaptive",
            "adaptive_time_microseconds",
            "connect"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "database.hostname"
        },
        {
          "name": "database.port"
        },
        {
          "name": "database.user"
        },
        {
          "name": "database.password"
        },
        {
          "name": "topic.prefix"
        },
        {
          "name": "table.include.list"
        },
        {
          "name": "table.exclude.list"
        },
        {
          "name": "snapshot.mode"
        },
        {
          "name": "incremental.snapshot.chunk.size"
        },
        {
          "name": "tombstones.on.delete"
        },
        {
          "name": "event.processing.failure.handling.mode"
        },
        {
          "name": "key.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "sr.output.key.subject.reference.naming.strategy"
          }
        },
        {
          "name": "schema.name.adjustment.mode"
        },
        {
          "name": "field.name.adjustment.mode"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "transforms",
          "switch": {
            "after.state.only": {
              "true": "unwrap",
              "false": ""
            }
          }
        },
        {
          "name": "transforms.unwrap.type",
          "switch": {
            "after.state.only": {
              "true": "io.debezium.transforms.ExtractNewRecordState",
              "false": ""
            }
          }
        },
        {
          "name": "transforms.unwrap.drop.tombstones",
          "switch": {
            "after.state.only": {
              "true": "false",
              "false": ""
            }
          }
        },
        {
          "name": "transforms.unwrap.delete.handling.mode",
          "switch": {
            "after.state.only": {
              "true": "rewrite",
              "false": ""
            }
          }
        },
        {
          "name": "heartbeat.interval.ms"
        },
        {
          "name": "provide.transaction.metadata"
        },
        {
          "name": "column.propagate.source.type"
        },
        {
          "name": "snapshot.lock.timeout.ms"
        },
        {
          "name": "max.batch.size"
        },
        {
          "name": "poll.interval.ms"
        },
        {
          "name": "snapshot.delay.ms"
        },
        {
          "name": "streaming.delay.ms"
        },
        {
          "name": "skipped.operations"
        },
        {
          "name": "notification.enabled.channels"
        },
        {
          "name": "notification.sink.topic.name"
        },
        {
          "name": "binary.handling.mode"
        },
        {
          "name": "incremental.snapshot.watermarking.strategy"
        },
        {
          "name": "signal.enabled.channels"
        },
        {
          "name": "signal.kafka.topic"
        },
        {
          "name": "signal.kafka.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "signal.consumer.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "signal.consumer.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "signal.consumer.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "signal.consumer.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "signal.consumer.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "signal.consumer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "signal.consumer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "decimal.handling.mode"
        },
        {
          "name": "time.precision.mode"
        },
        {
          "name": "max.queue.size.in.bytes",
          "value": "209716100"
        },
        {
          "name": "custom.metric.tags",
          "value": "connector={{.logicalClusterId}},version=v2"
        },
        {
          "name": "topic.transaction"
        },
        {
          "name": "topic.heartbeat.prefix"
        },
        {
          "name": "errors.max.retries",
          "value": "3"
        },
        {
          "name": "connector.endpoint",
          "value": "${database.hostname}"
        },
        {
          "name": "connector.thread.name.pattern",
          "value": "${connector.name}-${task.id}-${debezium}-${connector.class.simple}-${topic.prefix}-${functionality}"
        },
        {
          "name": "guardrail.collections.max",
          "value": "100"
        },
        {
          "name": "guardrail.collections.limit.action",
          "value": "warn"
        }
      ]
    },
    {
      "template_id": "common",
      "global_validators": [
        {
          "name": "required",
          "priority": "HIGHEST"
        },
        {
          "name": "recommended.values",
          "priority": "HIGHER"
        }
      ],
      "abstract": true,
      "config_defs": [
        {
          "name": "connector.class",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 1,
          "display_name": "Connector class"
        },
        {
          "name": "name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 2,
          "display_name": "Connector name",
          "documentation": "Sets a name for your connector."
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "${connect.regional.connector}",
          "default_value_provider": {
            "name": "kafka.auth.mode.provider"
          },
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 1,
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode, whenever possible.",
          "recommender": {
            "name": "kafka.auth.mode"
          }
        },
        {
          "name": "kafka.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka API Key",
          "documentation": "Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY."
        }
      ],
      "connector_configs": [
        {
          "name": "tasks.max"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "errors.log.enable",
          "value": "true"
        },
        {
          "name": "errors.log.include.messages",
          "value": "false"
        },
        {
          "name": "errors.retry.timeout",
          "value": "300000"
        },
        {
          "name": "errors.retry.delay.max.ms",
          "value": "30000"
        },
        {
          "name": "value.converter.ignore.modern.dialects",
          "value": "true"
        }
      ]
    },
    {
      "template_id": "common-kafka-connectivity",
      "abstract": true,
      "config_defs": [],
      "connector_configs": [
        {
          "name": "consumer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "producer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "producer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "consumer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "admin.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "producer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "consumer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "admin.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "consumer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "admin.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        }
      ]
    },
    {
      "template_id": "common-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.service.account.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka Service Account",
          "documentation": "The Service Account that will be used to generate the API keys to communicate with Kafka Cluster."
        },
        {
          "name": "kafka.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 3,
          "display_name": "Kafka API Secret",
          "documentation": "Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.",
          "dependents": [
            "kafka.api.key"
          ]
        },
        {
          "name": "datapreview.schemas.enable",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "default_value": "false",
          "display_name": "Show schemas in data preview request output",
          "group": "Kafka Cluster credentials",
          "order_in_group": 4,
          "documentation": "This config key only applies to data preview requests and governs whether the data preview output has record schema with it.\nThe visibility condition is set such that it can never be true.\nSo this key does not show in create connector UI."
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "none",
          "display_name": "Errors Tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "producer.override.linger.ms",
          "type": "LONG",
          "required": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Producer Override Linger Ms",
          "documentation": "The producer groups together any records that arrive in between request transmissions into a single batched request. More details can be found in the documentation: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#linger-ms."
        }
      ],
      "connector_configs": [
        {
          "name": "topic.creation.default.replication.factor",
          "value": "3"
        },
        {
          "name": "topic.creation.default.partitions",
          "value": "1"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "producer.override.max.request.size",
          "switch": {
            "kafka.dedicated": {
              "true": "20971610",
              "false": "8388698"
            }
          }
        },
        {
          "name": "topic.creation.default.max.message.bytes",
          "switch": {
            "kafka.dedicated": {
              "true": "20971520",
              "false": "8388608"
            }
          }
        },
        {
          "name": "datapreview.schemas.enable"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "producer.override.linger.ms"
        },
        {
          "name": "consumer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.override.sasl.mechanism",
          "value": "PLAIN"
        }
      ]
    },
    {
      "template_id": "aws-authentication",
      "abstract": true,
      "config_defs": [
        {
          "name": "authentication.method",
          "type": "STRING",
          "required": false,
          "default_value": "Access Keys",
          "importance": "HIGH",
          "group": "AWS credentials",
          "order_in_group": 1,
          "display_name": "Authentication method",
          "documentation": "Select how you want to authenticate with AWS.",
          "recommended_values": [
            "IAM Roles",
            "Access Keys"
          ],
          "conditional_metadata_provider": [
            {
              "name": "metadata.conditional.visible",
              "arguments": {
                "config": "provider.integration.visible",
                "values": "false"
              }
            }
          ]
        },
        {
          "name": "provider.integration.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "AWS credentials",
          "order_in_group": 2,
          "display_name": "Provider Integration",
          "documentation": "Select an existing integration that has access to your resource. In case you need to integrate a new IAM role, use provider integration"
        }
      ],
      "connector_configs": [
        {
          "name": "authentication.method"
        },
        {
          "name": "provider.integration.id"
        },
        {
          "name": "customer.aws.iam.role.arn"
        },
        {
          "name": "external.id"
        },
        {
          "name": "middleware.external.id"
        },
        {
          "name": "confluent.aws.iam.role.arn"
        },
        {
          "name": "aws.iam.assume.role.session.name"
        },
        {
          "name": "provider.integration.max.retries"
        },
        {
          "name": "connect.aws.iam.role.validation.disable"
        }
      ]
    },
    {
      "template_id": "secret-manager",
      "abstract": true,
      "config_defs": [
        {
          "name": "secret.manager.enabled",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "HIGH",
          "display_name": "Use secret manager",
          "documentation": "Fetch sensitive configuration values from a secret manager.",
          "conditional_metadata_provider": [
            {
              "name": "metadata.conditional.visible",
              "arguments": {
                "config": "connect.metadata_property.secret.manager.configs.visible",
                "values": "false"
              }
            }
          ]
        },
        {
          "name": "secret.manager",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Secret manager configuration",
          "order_in_group": 1,
          "display_name": "Secret manager",
          "documentation": "Select the secret manager to use for retrieving sensitive data.",
          "recommender": {
            "name": "secret.manager.types"
          }
        },
        {
          "name": "secret.manager.managed.configs",
          "type": "LIST",
          "required": false,
          "importance": "HIGH",
          "group": "Secret manager configuration",
          "order_in_group": 2,
          "display_name": "Configurations from Secret manager",
          "documentation": "Select the configurations to fetch their values from the secret manager."
        },
        {
          "name": "secret.manager.provider.integration.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Secret manager configuration",
          "order_in_group": 3,
          "display_name": "Provider Integration",
          "documentation": "Select an existing provider integration that has access to your secret manager."
        }
      ],
      "connector_configs": [
        {
          "name": "secret.manager.enabled"
        },
        {
          "name": "secret.manager"
        },
        {
          "name": "secret.manager.managed.configs"
        },
        {
          "name": "secret.manager.provider.integration.id"
        }
      ]
    },
    {
      "template_id": "schema-registry",
      "abstract": true,
      "config_defs": [
        {
          "name": "schema.context.name",
          "type": "STRING",
          "group": "Schema Config",
          "order_in_group": 1,
          "importance": "MEDIUM",
          "display_name": "Schema context",
          "documentation": "Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.",
          "default_value": "default",
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": []
    },
    {
      "template_id": "source-connector-output-data-format",
      "abstract": true,
      "config_defs": [
        {
          "name": "output.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "JSON",
          "importance": "HIGH",
          "group": "Output messages",
          "order_in_group": 1,
          "display_name": "Select output record value format",
          "alias": "data.format",
          "documentation": "Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "value.converter.schemas.enable",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "alias": "schemas.enable",
          "display_name": "Value Converter Schemas Enable",
          "documentation": "Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.replace.null.with.default",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "alias": "replace.null.with.default",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Value Converter Replace Null With Default",
          "documentation": "Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.ignore.default.for.nullables",
          "alias": "ignore.default.for.nullables",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Value Converter Ignore Default For Nullables",
          "documentation": "When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters."
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "type": "BOOLEAN",
          "documentation": "Whether to scrub invalid names by replacing invalid characters with valid characters. Applicable for Avro and Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Scrub Invalid Names"
        }
      ],
      "connector_configs": [
        {
          "name": "value.converter",
          "switch": {
            "output.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "value.converter.schemas.enable"
        },
        {
          "name": "value.converter.replace.null.with.default"
        },
        {
          "name": "value.converter.schema.registry.url",
          "switch": {
            "output.data.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "switch": {
            "output.data.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "switch": {
            "output.data.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "value.converter.ignore.default.for.nullables"
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "dynamic.mapper": {
            "name": "value.converter.scrub.invalid.names.mapper"
          }
        }
      ]
    },
    {
      "template_id": "output-key-format-debezium-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "output.key.format",
          "type": "STRING",
          "required": false,
          "default_value": "JSON",
          "importance": "HIGH",
          "group": "Output messages",
          "order_in_group": 2,
          "display_name": "Output Kafka record key format",
          "alias": "key.format",
          "documentation": "Sets the output Kafka record key format. Valid entries are AVRO, JSON_SR, PROTOBUF, STRING or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON",
            "STRING"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "key.converter",
          "switch": {
            "output.key.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "STRING": "org.apache.kafka.connect.storage.StringConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "key.converter.schemas.enable",
          "switch": {
            "output.key.format": {
              "JSON": false
            }
          }
        },
        {
          "name": "key.converter.schema.registry.url",
          "switch": {
            "output.key.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "key.converter.basic.auth.credentials.source",
          "switch": {
            "output.key.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "key.converter.basic.auth.user.info",
          "switch": {
            "output.key.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        }
      ]
    },
    {
      "template_id": "csfle-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "csfle.enabled",
          "type": "BOOLEAN",
          "default_value": "false",
          "importance": "HIGH",
          "group": "CSFLE",
          "order_in_group": 1,
          "docs_hidden": true,
          "display_name": "Enable Client-Side Field Level Encryption",
          "documentation": "Determines whether the connector honours CSFLE rules or not",
          "conditional_metadata_provider": [
            {
              "name": "metadata.conditional.visible",
              "arguments": {
                "config": "csfle.configs.visible",
                "values": "false"
              }
            }
          ]
        },
        {
          "name": "sr.service.account.id",
          "type": "STRING",
          "importance": "HIGH",
          "group": "CSFLE",
          "order_in_group": 2,
          "docs_hidden": true,
          "display_name": "Schema Registry Service Account",
          "documentation": "Select the service account that has appropriate permissions to schemas and encryption keys in the Schema Registry."
        }
      ],
      "connector_configs": [
        {
          "name": "csfle.enabled"
        },
        {
          "name": "value.converter.rule.executors._ENCRYPT_.disabled",
          "switch": {
            "csfle.enabled": {
              "true": "false",
              "false": "true"
            }
          }
        },
        {
          "name": "value.converter.rule.executors._ENCRYPT_.onFailure",
          "switch": {
            "csfle.enabled": {
              "true": "ERROR"
            }
          }
        },
        {
          "name": "value.converter.latest.cache.ttl.sec",
          "switch": {
            "csfle.enabled": {
              "true": "300"
            }
          }
        },
        {
          "name": "key.converter.rule.executors._ENCRYPT_.disabled",
          "switch": {
            "csfle.enabled": {
              "true": "false",
              "false": "true"
            }
          }
        },
        {
          "name": "key.converter.rule.executors._ENCRYPT_.onFailure",
          "switch": {
            "csfle.enabled": {
              "true": "ERROR"
            }
          }
        },
        {
          "name": "key.converter.auto.register.schemas",
          "switch": {
            "csfle.enabled": {
              "true": "false"
            }
          }
        },
        {
          "name": "key.converter.use.latest.version",
          "switch": {
            "csfle.enabled": {
              "true": "true"
            }
          }
        },
        {
          "name": "key.converter.latest.cache.ttl.sec",
          "switch": {
            "csfle.enabled": {
              "true": "300"
            }
          }
        }
      ]
    },
    {
      "template_id": "super",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "${connect.regional.connector}",
          "default_value_provider": {
            "name": "kafka.auth.mode.provider"
          },
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 1,
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode, whenever possible.",
          "recommender": {
            "name": "kafka.auth.mode"
          }
        },
        {
          "name": "auto.restart.on.user.error",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Auto-restart policy",
          "order_in_group": 1,
          "display_name": "Enable Connector Auto-restart",
          "documentation": "Enable connector to automatically restart on user-actionable errors."
        },
        {
          "name": "value.converter.enhanced.avro.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information and Enums. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Enhanced Avro Schema Support"
        },
        {
          "name": "value.converter.connect.meta.data",
          "type": "BOOLEAN",
          "documentation": "Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Connect Meta Data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Enhanced Protobuf Schema Support"
        },
        {
          "name": "value.converter.generate.index.for.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to generate an index suffix for unions. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Generate Index For Unions"
        },
        {
          "name": "value.converter.int.for.enums",
          "type": "BOOLEAN",
          "documentation": "Whether to represent enums as integers. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Int For Enums"
        },
        {
          "name": "value.converter.optional.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should be specified with an optional label. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Optional For Nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls",
          "type": "BOOLEAN",
          "documentation": "Whether to generate a struct variable for null values. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Generate Struct For Nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should use primitive wrapper messages. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Wrapper For Nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives",
          "type": "BOOLEAN",
          "documentation": "Whether a wrapper message should be interpreted as a raw primitive at root level. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Wrapper For Raw Primitives"
        },
        {
          "name": "value.converter.object.additional.properties",
          "type": "BOOLEAN",
          "documentation": "Whether to allow additional properties for object schemas. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Object Additional Properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired",
          "type": "BOOLEAN",
          "documentation": "Whether to set non-required properties to be optional. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Use Optional For Nonrequired"
        },
        {
          "name": "value.converter.decimal.format",
          "type": "STRING",
          "recommended_values": [
            "BASE64",
            "NUMERIC"
          ],
          "documentation": "Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:\nBASE64 to serialize DECIMAL logical types as base64 encoded binary data and\nNUMERIC to serialize Connect DECIMAL logical type values in JSON/JSON_SR as a number representing the decimal value.",
          "group": "Additional Configs",
          "alias": "json.output.decimal.format",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Decimal Format",
          "default_value": "BASE64"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "type": "BOOLEAN",
          "documentation": "Specify if the Serializer should attempt to register the Schema.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Auto Register Schemas"
        },
        {
          "name": "value.converter.use.latest.version",
          "type": "BOOLEAN",
          "documentation": "Use latest version of schema in subject for serialization when auto.register.schemas is false.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Use Latest Version"
        },
        {
          "name": "value.converter.latest.compatibility.strict",
          "type": "BOOLEAN",
          "documentation": "Verify latest subject version is backward compatible when `use.latest.version` is `true`.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Latest Compatibility Strict"
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "type": "STRING",
          "default_value": "TopicNameStrategy",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "alias": "key.subject.name.strategy",
          "documentation": "How to construct the subject name for key schema registration.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Key Converter Key Subject Name Strategy"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "default_value": "TopicNameStrategy",
          "alias": "subject.name.strategy,value.subject.name.strategy",
          "documentation": "Determines how to construct the subject name under which the value schema is registered with Schema Registry.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Value Subject Name Strategy"
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Reference Subject Name Strategy"
        },
        {
          "name": "value.converter.allow.optional.map.keys",
          "type": "BOOLEAN",
          "documentation": "Allow optional string map key when converting from Connect Schema to Avro Schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Allow Optional Map Keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions",
          "type": "BOOLEAN",
          "default_value": "false",
          "documentation": "Whether to flatten singleton unions. Applicable for Avro and JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Flatten Singleton Unions"
        },
        {
          "name": "value.converter.optional.for.proto2",
          "type": "BOOLEAN",
          "documentation": "Whether proto2 optionals are supported. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Optional For Proto2"
        },
        {
          "name": "value.converter.flatten.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to flatten unions (oneofs). Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "Value Converter Flatten Unions"
        },
        {
          "name": "header.converter",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "Header Converter",
          "documentation": "The converter class for the headers. This is used to serialize and deserialize the headers of the messages.",
          "recommended_values": [
            "org.apache.kafka.connect.storage.SimpleHeaderConverter",
            "org.apache.kafka.connect.storage.StringConverter",
            "org.apache.kafka.connect.json.JsonConverter",
            "org.apache.kafka.connect.converters.BooleanConverter",
            "org.apache.kafka.connect.converters.DoubleConverter",
            "org.apache.kafka.connect.converters.FloatConverter",
            "org.apache.kafka.connect.converters.IntegerConverter",
            "org.apache.kafka.connect.converters.LongConverter",
            "org.apache.kafka.connect.converters.ShortConverter",
            "org.apache.kafka.connect.converters.ByteArrayConverter"
          ]
        },
        {
          "name": "connector.egress.whitelist",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Egress allowlist",
          "display_name": "Egress allowlist",
          "documentation": "List a comma-separated list of FQDNs, IPs, or CIDR ranges for secure, restricted network egress.",
          "docs_hidden": true,
          "conditional_metadata_provider": [
            {
              "name": "metadata.conditional.visible",
              "arguments": {
                "config": "connector.egress.whitelist.config.visible",
                "values": "true"
              }
            }
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "auto.restart.on.user.error"
        },
        {
          "name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "dynamic.mapper": {
            "name": "value.converter.auto.register.schemas.mapper"
          }
        },
        {
          "name": "value.converter.use.latest.version",
          "dynamic.mapper": {
            "name": "value.converter.use.latest.version.mapper"
          }
        },
        {
          "name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.reference.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter"
        },
        {
          "name": "key.converter.use.apache.http.client"
        },
        {
          "name": "value.converter.use.apache.http.client"
        },
        {
          "name": "connector.egress.whitelist"
        }
      ]
    },
    {
      "template_id": "super-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "producer.override.compression.type",
          "type": "STRING",
          "recommended_values": [
            "none",
            "gzip",
            "snappy",
            "lz4",
            "zstd"
          ],
          "documentation": "The compression type for all data generated by the producer. Valid values are none, gzip, snappy, lz4, and zstd.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "producer.override.compression.type"
        }
      ],
      "connector_configs": [
        {
          "name": "producer.override.compression.type"
        }
      ]
    }
  ]
}