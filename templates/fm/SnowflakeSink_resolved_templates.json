{
  "templates": [
    {
      "template_id": "SnowflakeSink",
      "connector_type": "SINK",
      "connector.class": "com.snowflake.kafka.connector.SnowflakeSinkConnector",
      "config_defs": [
        {
          "name": "regional.connectivity",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "default_value": null,
          "queryable_internal": true,
          "custom_config_provider": {
            "name": "snowflake.regional.connectivity.provider"
          }
        },
        {
          "name": "input.data.format",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "Input messages",
          "display_name": "Input Kafka record value format",
          "documentation": "Sets the input Kafka record value format. Valid entries are JSON, AVRO, JSON_SR, PROTOBUF, or STRING. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF",
          "recommended_values": [
            "JSON",
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "STRING"
          ]
        },
        {
          "name": "key.converter.reference.subject.name.strategy",
          "type": "STRING",
          "importance": "HIGH",
          "group": "Input messages",
          "order_in_group": 9,
          "display_name": "Key Converter Reference Subject Name Strategy",
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for key. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "dependents": [
            "input.key.format"
          ]
        },
        {
          "name": "input.key.format",
          "type": "STRING",
          "required": false,
          "default_value": "STRING",
          "importance": "HIGH",
          "group": "Input messages",
          "order_in_group": 1,
          "display_name": "Input Kafka record key format",
          "alias": "key.format",
          "documentation": "Sets the input Kafka record key format. Valid entries are AVRO, JSON_SR, PROTOBUF, STRING or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON",
            "STRING"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "snowflake.url.name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 1,
          "display_name": "Connection URL",
          "documentation": "The URL for accessing your Snowflake account, in the form of https://<account_name>.<region_id>.snowflakecomputing.com:443. Note that the https:// and port number are optional. The region ID is not used if your account is in the AWS US West region and you are not using AWS PrivateLink."
        },
        {
          "name": "snowflake.user.name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 2,
          "display_name": "Connection user name",
          "documentation": "User login name for the Snowflake account"
        },
        {
          "name": "snowflake.private.key",
          "type": "PASSWORD",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 3,
          "display_name": "Private key",
          "documentation": "The private key to authenticate the user. Include only the key, not the header or footer. If the key is split across multiple lines, remove the line breaks. You can provide either an unencrypted key or an encrypted key. If you use an encrypted key, provide the snowflake.private.key.passphrase parameter so Snowflake can decrypt the key. Use this parameter only if the snowflake.private.key parameter value is encrypted."
        },
        {
          "name": "snowflake.role.name",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 4,
          "display_name": "Snowflake role",
          "documentation": "Access control role to use when inserting the rows into the table. If Ingestion method is Snowpipe_Streaming Ingestion then it's required. If Ingestion method is Snowpipe then its not required and use default role"
        },
        {
          "name": "snowflake.database.name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 4,
          "display_name": "Database name",
          "documentation": "The name of the database that contains the table to insert rows into."
        },
        {
          "name": "snowflake.schema.name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "Database details",
          "order_in_group": 1,
          "display_name": "Schema name",
          "documentation": "The name of the schema that contains the table to insert rows into."
        },
        {
          "name": "snowflake.topic2table.map",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Database details",
          "order_in_group": 2,
          "display_name": "Topics to tables mapping",
          "documentation": "Map of topics to tables (optional). Format : comma-separated tuples, e.g. <topic-1>:<table-1>,<topic-2>:<table-2>,..."
        },
        {
          "name": "snowflake.private.key.passphrase",
          "type": "PASSWORD",
          "required": false,
          "default_value": "",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 1,
          "display_name": "Decryption key of private key",
          "documentation": "If snowflake.private.key is encrypted, this passphrase is used to decrypt the key. If the value of this parameter is not empty, Kafka uses this phrase to try to decrypt the private key."
        },
        {
          "name": "snowflake.ingestion.method",
          "type": "STRING",
          "required": true,
          "default_value": "SNOWPIPE",
          "importance": "HIGH",
          "group": "Snowflake connection",
          "order_in_group": 1,
          "display_name": "Ingestion method",
          "documentation": "Choose the preferred ingestion method. The connector supports the SNOWPIPE (default) and SNOWPIPE_STREAMIMG for Kafka data ingestion. Using SNOWPIPE_STREAMING may provide a cost-benefit for your Snowflake project.",
          "recommended_values": [
            "SNOWPIPE",
            "SNOWPIPE_STREAMING"
          ]
        },
        {
          "name": "snowflake.metadata.createtime",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 3,
          "display_name": "Whether or not to include \"createtime\" in metadata",
          "documentation": "If the value is set to FALSE, the CreateTime property value is omitted from the metadata in the RECORD_METADATA column. The default value is TRUE.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "snowflake.metadata.topic",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 4,
          "display_name": "Whether or not to include \"topic\" in metadata",
          "documentation": "If the value is set to FALSE, the topic property value is omitted from the metadata in the RECORD_METADATA column. The default value is TRUE.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "snowflake.metadata.offset.and.partition",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 5,
          "display_name": "Whether or not to include \"offset\" and \"partition\" in metadata",
          "documentation": "If the value is set to FALSE, the Offset and Partition property values are omitted from the metadata in the RECORD_METADATA column. The default value is TRUE.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "snowflake.streaming.metadata.connectorPushTime",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 6,
          "display_name": "Whether or not to include \"connectorPushTime\" in metadata",
          "documentation": "If the value is set to TRUE, the ConnectorPushTime property value is added to the metadata in the RECORD_METADATA column. The default value is FALSE. This works with only SNOWPIPE_STREAMING ingestion mode.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "snowflake.metadata.all",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 6,
          "display_name": "Whether or not to include metadata column",
          "documentation": "If the value is set to FALSE, the metadata in the RECORD_METADATA column is completely empty. The default value is TRUE.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "snowflake.enable.schematization",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 7,
          "display_name": "Enable Schematization",
          "documentation": "Specify to TRUE to enable schema detection and evolution for Kafka Connector with Snowpipe Streaming. The default value is FALSE",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "buffer.flush.time",
          "type": "LONG",
          "required": false,
          "default_value": 120,
          "importance": "LOW",
          "group": "Connection details",
          "order_in_group": 8,
          "display_name": "The time in seconds to flush cached data",
          "documentation": "Number of seconds between buffer flushes, where the flush is from the Kafka\u2019s memory cache to the internal stage. The default value is 120 seconds. Minimum value allowed is 10 for snowflake.ingestion.method=SNOWPIPE, and 1 for snowflake.ingestion.method=SNOWPIPE_STREAMING. The connector uses buffer.count.records and buffer.size.bytes=10,000,000 (10MB) as well. Whichever comes first, the connector will flush Kafka records to Snowflake."
        },
        {
          "name": "buffer.count.records",
          "type": "LONG",
          "required": false,
          "default_value": 10000,
          "importance": "LOW",
          "group": "Connection details",
          "order_in_group": 9,
          "display_name": "The number of records to flush cached data",
          "documentation": "Number of records between buffer flushes, where the flush is from the Kafka\u2019s memory cache to the internal stage. The default and minimum value is 10,000 records. The connector uses buffer.flush.time and buffer.size.bytes=10,000,000 (10MB) as well. Whichever comes first, the connector will flush Kafka records to Snowflake."
        },
        {
          "name": "buffer.size.bytes",
          "type": "LONG",
          "required": false,
          "default_value": 10000000,
          "importance": "LOW",
          "group": "Connection details",
          "order_in_group": 10,
          "display_name": "The size of the connector record buffer",
          "documentation": "Kafka records are cached in a buffer (per partition) before being written to Snowflake as data files. The buffer size defaults to 10000000 bytes (10 MB). The records are compressed when written to Snowflake. Because of the compression, the size of the cached records buffer may be larger that the size of the resulting data files created in Snowflake."
        },
        {
          "name": "snowflake.streaming.iceberg.enabled",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "MEDIUM",
          "group": "Connection details",
          "order_in_group": 11,
          "display_name": "Enable Iceberg Ingestion",
          "documentation": "Interested in integrating with Iceberg? Take a look at Tableflow \u2014 a solution designed to simplify and streamline your Iceberg workflows, refer https://www.confluent.io/product/tableflow/.\nThis property specifies whether the connector ingests data into an Iceberg table. The connector fails if this property doesn't match the actual table type, refer https://docs.snowflake.com/en/user-guide/kafka-connector-iceberg.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "default_value": "all",
          "importance": "LOW",
          "group": "Error handling",
          "order_in_group": 1,
          "display_name": "Error Tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior differently from the Connect framework's.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "The number of tasks for the connector. Each task is limited to a number of topic partitions based on the `buffer.size.bytes` configuration, e.g., 10 MB -> 50 Topic Partitions, 20 MB-> 25 Topic Partitions, 50 MB -> 10 Topic Partitions, and 100 MB -> 5 Topic Partitions."
        },
        {
          "name": "snowflake.useHttpsProxy",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 5,
          "display_name": "Enable HTTPS proxy for Snowflake connections",
          "documentation": "Enable HTTPS proxy for Snowflake connections",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "snowflake.https.proxyHost",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 6,
          "display_name": "HTTPS proxy host for Snowflake connections",
          "documentation": "HTTPS proxy host for Snowflake connections"
        },
        {
          "name": "snowflake.https.proxyPort",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 7,
          "display_name": "HTTPS proxy port for Snowflake connections",
          "documentation": "HTTPS proxy port for Snowflake connections"
        },
        {
          "name": "snowflake.https.nonProxyHosts",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 8,
          "display_name": "Hosts to bypass HTTPS proxy for Snowflake connections",
          "documentation": "Hosts to bypass HTTPS proxy for Snowflake connections"
        },
        {
          "name": "snowflake.https.proxyUser",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 9,
          "display_name": "HTTPS proxy username for Snowflake connections",
          "documentation": "HTTPS proxy username for Snowflake connections"
        },
        {
          "name": "snowflake.https.proxyPassword",
          "type": "PASSWORD",
          "required": false,
          "importance": "LOW",
          "group": "How should we connect to your Snowflake database?",
          "order_in_group": 10,
          "display_name": "HTTPS proxy password for Snowflake connections",
          "documentation": "HTTPS proxy password for Snowflake connections"
        },
        {
          "name": "behavior.on.null.values",
          "type": "STRING",
          "importance": "LOW",
          "documentation": "Specify how the connector should handle tombstone records. A tombstone record is defined as a record where the entire value field is null",
          "group": "Additional Configs",
          "display_name": "behavior.on.null.values",
          "default_value": "IGNORE",
          "recommended_values": [
            "DEFAULT",
            "IGNORE"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "connector.target.region",
          "value": "${regional.connectivity}"
        },
        {
          "name": "consumer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "value.converter",
          "switch": {
            "input.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "STRING": "org.apache.kafka.connect.storage.StringConverter"
            }
          }
        },
        {
          "name": "value.converter.schema.registry.url",
          "switch": {
            "input.data.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "switch": {
            "input.data.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "switch": {
            "input.data.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "topics"
        },
        {
          "name": "tasks.max"
        },
        {
          "name": "cloud.provider",
          "switch": {
            "cloud.environment": {
              "private": "aws",
              "DEFAULT": "${cloud.provider}"
            }
          }
        },
        {
          "name": "kafka.region",
          "switch": {
            "cloud.environment": {
              "private": "us-west-2",
              "DEFAULT": "${kafka.region}"
            }
          }
        },
        {
          "name": "snowflake.url.name"
        },
        {
          "name": "snowflake.user.name"
        },
        {
          "name": "snowflake.private.key",
          "value": "${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:snowflake.private.key}"
        },
        {
          "name": "snowflake.database.name"
        },
        {
          "name": "snowflake.schema.name"
        },
        {
          "name": "snowflake.role.name"
        },
        {
          "name": "snowflake.topic2table.map"
        },
        {
          "name": "snowflake.private.key.passphrase",
          "value": "${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:snowflake.private.key.passphrase}"
        },
        {
          "name": "snowflake.ingestion.method"
        },
        {
          "name": "snowflake.enable.schematization"
        },
        {
          "name": "snowflake.metadata.createtime"
        },
        {
          "name": "snowflake.metadata.topic"
        },
        {
          "name": "snowflake.metadata.offset.and.partition"
        },
        {
          "name": "snowflake.metadata.all"
        },
        {
          "name": "buffer.flush.time"
        },
        {
          "name": "buffer.count.records"
        },
        {
          "name": "enable.streaming.client.optimization",
          "value": "false"
        },
        {
          "name": "buffer.size.bytes",
          "value": "10000000"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "errors.log.enable",
          "value": "false"
        },
        {
          "name": "schema.cache.size",
          "value": "1000"
        },
        {
          "name": "key.converter",
          "switch": {
            "input.key.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "STRING": "org.apache.kafka.connect.storage.StringConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "key.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "sr.input.key.subject.reference.naming.strategy"
          }
        },
        {
          "name": "key.converter.schemas.enable",
          "switch": {
            "input.key.format": {
              "JSON": "false"
            }
          }
        },
        {
          "name": "key.converter.schema.registry.url",
          "switch": {
            "input.key.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "key.converter.basic.auth.credentials.source",
          "switch": {
            "input.key.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "key.converter.basic.auth.user.info",
          "switch": {
            "input.key.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "enhanced.avro.schema.support",
          "value": "true"
        },
        {
          "name": "locale",
          "value": "en"
        },
        {
          "name": "timezone",
          "value": "UTC"
        },
        {
          "name": "rotate.interval.ms",
          "value": "86400000"
        },
        {
          "name": "timestamp.extractor",
          "value": "Record"
        },
        {
          "name": "behavior.on.null.values"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "provider",
          "value": "CONFLUENT"
        },
        {
          "name": "connector.endpoint",
          "value": "${snowflake.url.name}"
        },
        {
          "name": "snowflake.snowpipe.v2CleanerEnabled",
          "value": "false"
        },
        {
          "name": "enable.task.fail.on.authorization.errors",
          "value": "true"
        },
        {
          "name": "snowflake.snowpipe.stageFileNameExtensionEnabled",
          "value": "true"
        },
        {
          "name": "snowflake.snowpipe.v1Cleaner.disable.reprocessFiles.cleanup",
          "value": "true"
        },
        {
          "name": "snowflake.useHttpsProxy"
        },
        {
          "name": "snowflake.https.proxyHost"
        },
        {
          "name": "snowflake.https.proxyPort"
        },
        {
          "name": "snowflake.https.nonProxyHosts"
        },
        {
          "name": "snowflake.https.proxyUser"
        },
        {
          "name": "snowflake.https.proxyPassword"
        },
        {
          "name": "snowflake.streaming.metadata.connectorPushTime"
        },
        {
          "name": "snowflake.streaming.enable.single.buffer",
          "switch": {
            "snowflake.ingestion.method": {
              "SNOWPIPE_STREAMING": "true"
            }
          }
        },
        {
          "name": "snowflake.streaming.max.client.lag",
          "switch": {
            "snowflake.ingestion.method": {
              "SNOWPIPE_STREAMING": 30
            }
          }
        },
        {
          "name": "snowflake.streaming.iceberg.enabled"
        }
      ]
    },
    {
      "template_id": "common",
      "global_validators": [
        {
          "name": "required",
          "priority": "HIGHEST"
        },
        {
          "name": "recommended.values",
          "priority": "HIGHER"
        }
      ],
      "abstract": true,
      "config_defs": [
        {
          "name": "connector.class",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 1,
          "display_name": "Connector class"
        },
        {
          "name": "name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 2,
          "display_name": "Connector name",
          "documentation": "Sets a name for your connector."
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "KAFKA_API_KEY",
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 1,
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.",
          "recommended_values": [
            "SERVICE_ACCOUNT",
            "KAFKA_API_KEY"
          ]
        },
        {
          "name": "kafka.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka API Key",
          "documentation": "Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY."
        }
      ],
      "connector_configs": [
        {
          "name": "tasks.max"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "errors.log.enable",
          "value": "true"
        },
        {
          "name": "errors.log.include.messages",
          "value": "false"
        },
        {
          "name": "errors.retry.timeout",
          "value": "300000"
        },
        {
          "name": "errors.retry.delay.max.ms",
          "value": "30000"
        },
        {
          "name": "value.converter.ignore.modern.dialects",
          "value": "true"
        }
      ]
    },
    {
      "template_id": "common-kafka-connectivity",
      "abstract": true,
      "config_defs": [],
      "connector_configs": [
        {
          "name": "consumer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "producer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "producer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "consumer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "admin.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "producer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "consumer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "admin.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "consumer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "admin.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        }
      ]
    },
    {
      "template_id": "common-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.service.account.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka Service Account",
          "documentation": "The Service Account that will be used to generate the API keys to communicate with Kafka Cluster."
        },
        {
          "name": "kafka.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 3,
          "display_name": "Kafka API Secret",
          "documentation": "Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.",
          "dependents": [
            "kafka.api.key"
          ]
        },
        {
          "name": "topics",
          "type": "LIST",
          "required": false,
          "importance": "HIGH",
          "group": "Which topics do you want to get data from?",
          "order_in_group": 1,
          "display_name": "Topic names",
          "documentation": "Identifies the topic name or a comma-separated list of topic names.",
          "dependents": [
            "kafka.api.secret"
          ],
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "max.poll.interval.ms",
          "type": "LONG",
          "required": false,
          "importance": "LOW",
          "group": "Consumer configuration",
          "order_in_group": 1,
          "display_name": "Max poll interval(ms)",
          "default_value": "300000",
          "documentation": "The maximum delay between subsequent consume requests to Kafka. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 300000 milliseconds (5 minutes)."
        },
        {
          "name": "max.poll.records",
          "type": "LONG",
          "required": false,
          "importance": "LOW",
          "group": "Consumer configuration",
          "order_in_group": 2,
          "display_name": "Max poll records",
          "default_value": "500",
          "documentation": "The maximum number of records to consume from Kafka in a single request. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 500 records."
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "all",
          "display_name": "errors.tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "errors.deadletterqueue.topic.name",
          "type": "STRING",
          "importance": "LOW",
          "group": "Which topics do you want to get data from?",
          "order_in_group": 2,
          "display_name": "Dead Letter Queue Topic Name",
          "documentation": "The name of the topic to be used as the dead letter queue (DLQ) for messages that result in an error when processed by this sink connector, or its transformations or converters. Defaults to 'dlq-${connector}' if not set. The DLQ topic will be created automatically if it does not exist. You can provide ``${connector}`` in the value to use it as a placeholder for the logical cluster ID.",
          "default_value": "dlq-${connector}"
        }
      ],
      "connector_configs": [
        {
          "name": "topics"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "errors.deadletterqueue.topic.name",
          "dynamic.mapper": {
            "name": "errors.deadletterqueue.topic.mapper"
          }
        },
        {
          "name": "errors.deadletterqueue.topic.replication.factor",
          "value": "3"
        },
        {
          "name": "errors.deadletterqueue.context.headers.enable",
          "value": "true"
        },
        {
          "name": "consumer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "consumer.override.max.poll.interval.ms",
          "value": "${max.poll.interval.ms}"
        },
        {
          "name": "consumer.override.max.poll.records",
          "value": "${max.poll.records}"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        }
      ]
    },
    {
      "template_id": "csfle-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "csfle.enabled",
          "type": "BOOLEAN",
          "default_value": "false",
          "importance": "HIGH",
          "group": "CSFLE",
          "order_in_group": 1,
          "docs_hidden": true,
          "display_name": "Enable Client-Side Field Level Encryption",
          "documentation": "Determines whether the connector honours CSFLE rules or not",
          "conditional_metadata_provider": [
            {
              "name": "metadata.conditional.visible",
              "arguments": {
                "config": "csfle.configs.visible",
                "values": "false"
              },
              "metadata": {
                "visibility": "false"
              }
            }
          ]
        },
        {
          "name": "csfle.onFailure",
          "type": "STRING",
          "required": false,
          "default_value": "ERROR",
          "importance": "MEDIUM",
          "group": "CSFLE",
          "order_in_group": 3,
          "docs_hidden": true,
          "display_name": "Connector behaviour on data decryption failure",
          "documentation": "Configures the behavior for decryption failures. If set to ERROR, the connector will behave as configured for error behaviour. If set to NONE, the connector will ignore the decryption failure and proceed to write the data in its encrypted form.",
          "recommended_values": [
            "ERROR",
            "NONE"
          ]
        },
        {
          "name": "sr.service.account.id",
          "type": "STRING",
          "importance": "HIGH",
          "group": "CSFLE",
          "order_in_group": 2,
          "docs_hidden": true,
          "display_name": "Schema Registry Service Account",
          "documentation": "Select the service account that has appropriate permissions to schemas and encryption keys in the Schema Registry."
        }
      ],
      "connector_configs": [
        {
          "name": "csfle.enabled"
        },
        {
          "name": "value.converter.rule.executors._ENCRYPT_.disabled",
          "switch": {
            "csfle.enabled": {
              "true": "false",
              "false": "true"
            }
          }
        },
        {
          "name": "value.converter.rule.executors._ENCRYPT_.onFailure",
          "switch": {
            "csfle.onFailure": {
              "ERROR": "ERROR",
              "NONE": "NONE"
            }
          }
        },
        {
          "name": "value.converter.latest.cache.ttl.sec",
          "switch": {
            "csfle.enabled": {
              "true": "300"
            }
          }
        },
        {
          "name": "key.converter.rule.executors._ENCRYPT_.disabled",
          "switch": {
            "csfle.enabled": {
              "true": "false",
              "false": "true"
            }
          }
        },
        {
          "name": "key.converter.rule.executors._ENCRYPT_.onFailure",
          "switch": {
            "csfle.onFailure": {
              "ERROR": "ERROR",
              "NONE": "NONE"
            }
          }
        },
        {
          "name": "key.converter.auto.register.schemas",
          "switch": {
            "csfle.enabled": {
              "true": "false"
            }
          }
        },
        {
          "name": "key.converter.use.latest.version",
          "switch": {
            "csfle.enabled": {
              "true": "true"
            }
          }
        },
        {
          "name": "key.converter.latest.cache.ttl.sec",
          "switch": {
            "csfle.enabled": {
              "true": "300"
            }
          }
        }
      ]
    },
    {
      "template_id": "schema-registry",
      "abstract": true,
      "config_defs": [
        {
          "name": "schema.context.name",
          "type": "STRING",
          "group": "Schema Config",
          "order_in_group": 1,
          "importance": "MEDIUM",
          "display_name": "Schema context",
          "documentation": "Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.",
          "default_value": "default",
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": []
    },
    {
      "template_id": "input-data-format",
      "abstract": true,
      "config_defs": [
        {
          "name": "input.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "JSON",
          "importance": "HIGH",
          "alias": "data.format",
          "group": "Input messages",
          "order_in_group": 1,
          "display_name": "Input Kafka record value format",
          "documentation": "Sets the input Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, JSON or BYTES. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON",
            "BYTES"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "value.converter.schemas.enable",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "alias": "schemas.enable",
          "display_name": "value.converter.schemas.enable",
          "documentation": "Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.replace.null.with.default",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "alias": "replace.null.with.default",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.replace.null.with.default",
          "documentation": "Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.ignore.default.for.nullables",
          "alias": "ignore.default.for.nullables",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.ignore.default.for.nullables",
          "documentation": "When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters."
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "type": "BOOLEAN",
          "documentation": "Whether to scrub invalid names by replacing invalid characters with valid characters. Applicable for Avro and Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.scrub.invalid.names"
        }
      ],
      "connector_configs": [
        {
          "name": "value.converter",
          "switch": {
            "input.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "BYTES": "org.apache.kafka.connect.converters.ByteArrayConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "value.converter.schemas.enable"
        },
        {
          "name": "value.converter.replace.null.with.default"
        },
        {
          "name": "value.converter.schema.registry.url",
          "switch": {
            "input.data.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "switch": {
            "input.data.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "switch": {
            "input.data.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "value.converter.ignore.default.for.nullables"
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "dynamic.mapper": {
            "name": "value.converter.scrub.invalid.names.mapper"
          }
        }
      ]
    },
    {
      "template_id": "http-network-restrictions-common",
      "abstract": true,
      "config_defs": [],
      "connector_configs": [
        {
          "name": "connection.disallow.class.e.ips",
          "value": "true"
        },
        {
          "name": "connection.disallow.local.ips",
          "value": "true"
        },
        {
          "name": "connection.disallow.private.ips"
        },
        {
          "name": "connection.disallow.cidr.ranges"
        },
        {
          "name": "connection.allow.cidr.ranges"
        }
      ]
    },
    {
      "template_id": "super",
      "abstract": true,
      "config_defs": [
        {
          "name": "auto.restart.on.user.error",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Auto-restart policy",
          "order_in_group": 1,
          "display_name": "Enable Connector Auto-restart",
          "documentation": "Enable connector to automatically restart on user-actionable errors."
        },
        {
          "name": "value.converter.enhanced.avro.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information and Enums. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data",
          "type": "BOOLEAN",
          "documentation": "Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to generate an index suffix for unions. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums",
          "type": "BOOLEAN",
          "documentation": "Whether to represent enums as integers. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should be specified with an optional label. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls",
          "type": "BOOLEAN",
          "documentation": "Whether to generate a struct variable for null values. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should use primitive wrapper messages. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives",
          "type": "BOOLEAN",
          "documentation": "Whether a wrapper message should be interpreted as a raw primitive at root level. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties",
          "type": "BOOLEAN",
          "documentation": "Whether to allow additional properties for object schemas. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired",
          "type": "BOOLEAN",
          "documentation": "Whether to set non-required properties to be optional. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format",
          "type": "STRING",
          "recommended_values": [
            "BASE64",
            "NUMERIC"
          ],
          "documentation": "Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:\nBASE64 to serialize DECIMAL logical types as base64 encoded binary data and\nNUMERIC to serialize Connect DECIMAL logical type values in JSON/JSON_SR as a number representing the decimal value.",
          "group": "Additional Configs",
          "alias": "json.output.decimal.format",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.decimal.format",
          "default_value": "BASE64"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "type": "BOOLEAN",
          "documentation": "Specify if the Serializer should attempt to register the Schema.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.auto.register.schemas"
        },
        {
          "name": "value.converter.use.latest.version",
          "type": "BOOLEAN",
          "documentation": "Use latest version of schema in subject for serialization when auto.register.schemas is false.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.latest.version"
        },
        {
          "name": "value.converter.latest.compatibility.strict",
          "type": "BOOLEAN",
          "documentation": "Verify latest subject version is backward compatible when `use.latest.version` is `true`.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "type": "STRING",
          "default_value": "TopicNameStrategy",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "alias": "key.subject.name.strategy",
          "documentation": "How to construct the subject name for key schema registration.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "key.converter.key.subject.name.strategy"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "default_value": "TopicNameStrategy",
          "alias": "subject.name.strategy,value.subject.name.strategy",
          "documentation": "Determines how to construct the subject name under which the value schema is registered with Schema Registry.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.value.subject.name.strategy"
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.reference.subject.name.strategy"
        },
        {
          "name": "value.converter.allow.optional.map.keys",
          "type": "BOOLEAN",
          "documentation": "Allow optional string map key when converting from Connect Schema to Avro Schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions",
          "type": "BOOLEAN",
          "default_value": "false",
          "documentation": "Whether to flatten singleton unions. Applicable for Avro and JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2",
          "type": "BOOLEAN",
          "documentation": "Whether proto2 optionals are supported. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to flatten unions (oneofs). Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "header.converter",
          "documentation": "The converter class for the headers. This is used to serialize and deserialize the headers of the messages.",
          "recommended_values": [
            "org.apache.kafka.connect.converters.BooleanConverter",
            "org.apache.kafka.connect.converters.ByteArrayConverter",
            "org.apache.kafka.connect.converters.DoubleConverter",
            "org.apache.kafka.connect.converters.FloatConverter",
            "org.apache.kafka.connect.converters.IntegerConverter",
            "org.apache.kafka.connect.converters.LongConverter",
            "org.apache.kafka.connect.converters.ShortConverter",
            "org.apache.kafka.connect.json.JsonConverter",
            "org.apache.kafka.connect.storage.SimpleHeaderConverter",
            "org.apache.kafka.connect.storage.StringConverter"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "auto.restart.on.user.error"
        },
        {
          "name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "dynamic.mapper": {
            "name": "value.converter.auto.register.schemas.mapper"
          }
        },
        {
          "name": "value.converter.use.latest.version",
          "dynamic.mapper": {
            "name": "value.converter.use.latest.version.mapper"
          }
        },
        {
          "name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.reference.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter"
        },
        {
          "name": "key.converter.use.apache.http.client"
        },
        {
          "name": "value.converter.use.apache.http.client"
        }
      ]
    },
    {
      "template_id": "super-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "consumer.override.auto.offset.reset",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "consumer.override.auto.offset.reset",
          "documentation": "Defines the behavior of the consumer when there is no committed position (which occurs when the group is first initialized) or when an offset is out of range. You can choose either to reset the position to the \u201cearliest\u201d offset (the default) or the \u201clatest\u201d offset. You can also select \u201cnone\u201d if you would rather set the initial offset yourself and you are willing to handle out of range errors manually. More details: https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#auto-offset-reset",
          "recommended_values": [
            "earliest",
            "latest",
            "none"
          ]
        },
        {
          "name": "consumer.override.isolation.level",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "consumer.override.isolation.level",
          "documentation": "Controls how to read messages written transactionally. If set to read_committed, consumer.poll() will only return transactional messages which have been committed. If set to read_uncommitted (the default), consumer.poll() will return all messages, even transactional messages which have been aborted. Non-transactional messages will be returned unconditionally in either mode.  More details: https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#isolation-level",
          "recommended_values": [
            "read_committed",
            "read_uncommitted"
          ]
        },
        {
          "name": "topics.regex",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Which topics do you want to get data from?",
          "display_name": "Topics Regex",
          "documentation": "A regular expression that matches the names of the topics to consume from. This is useful when you want to consume from multiple topics that match a certain pattern without having to list them all individually."
        }
      ],
      "connector_configs": [
        {
          "name": "consumer.override.auto.offset.reset"
        },
        {
          "name": "consumer.override.isolation.level"
        },
        {
          "name": "topics.regex"
        }
      ]
    }
  ]
}