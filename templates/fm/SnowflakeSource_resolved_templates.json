{
  "templates": [
    {
      "template_id": "SnowflakeSource",
      "connector_type": "SOURCE",
      "connector.class": "io.confluent.connect.snowflake.jdbc.SnowflakeSourceConnector",
      "config_defs": [
        {
          "name": "connection.url",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake Instance?",
          "display_name": "Snowflake Connection URL",
          "documentation": "Snowflake connection URL. Supported formats are `<org_name>_<account_name>.snowflakecomputing.com` or If the account is located in the AWS US West (Oregon) region, then `<locator>.snowflakecomputing.com`."
        },
        {
          "name": "connection.user",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake Instance?",
          "display_name": "Snowflake User",
          "documentation": "User to be used for authenticating to snowflake."
        },
        {
          "name": "connection.credentials.source",
          "type": "STRING",
          "required": false,
          "default_value": "PRIVATE_KEY",
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake Instance?",
          "display_name": "Credentials Source",
          "documentation": "The source of the credentials to use for authentication. Supported values are: `PRIVATE_KEY`: Use the private key to authenticate. `PRIVATE_KEY_PASSPHRASE`: Use the private key and passphrase to authenticate.",
          "recommended_values": [
            "PRIVATE_KEY",
            "PRIVATE_KEY_PASSPHRASE"
          ]
        },
        {
          "name": "connection.private.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake Instance?",
          "display_name": "Snowflake Private Key",
          "documentation": "Private key for Snowflake user."
        },
        {
          "name": "connection.private.key.passphrase",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "How should we connect to your Snowflake Instance?",
          "display_name": "Private Key Passphrase",
          "documentation": "Passphrase of the encrypted private key."
        },
        {
          "name": "output.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "AVRO",
          "importance": "HIGH",
          "group": "Output messages",
          "display_name": "Select output record value format",
          "alias": "data.format",
          "documentation": "Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "topic.prefix",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we name your topic(s)?",
          "display_name": "Topic Prefix",
          "documentation": "Prefix to prepend to table names to generate the name of the Kafka topic to publish data to."
        },
        {
          "name": "mode",
          "type": "STRING",
          "required": true,
          "group": "Connector Details",
          "importance": "MEDIUM",
          "display_name": "Mode",
          "documentation": "Mode represents the criteria on which table is polled each time. Options include -- `BULK`: perform a bulk load of all the eligible tables each time it is polled. `TIMESTAMP`: use timestamp column(s) to detect new and modified rows. On specifying multiple timestamp columns, COALESCE SQL function would be used to find out the effective timestamp for a row. This assumes that the effective timestamp is updated with each write, it's values are monotonically incrementing, but not necessarily unique. Only rows with non null value of effective timestamp would be captured. `INCREMENTING`: use a strictly incrementing column on each table to detect only new rows. Only rows with non null value of incrementing column would be captured. `TIMESTAMP AND INCREMENTING`: use two columns, a timestamp column that detects new and modified rows and a strictly incrementing column which provides a globally unique ID for updates so each row can be assigned a unique stream offset. Only rows with non null effective timestamp value and non null incrementing column value would be captured",
          "recommended_values": [
            "timestamp",
            "incrementing",
            "timestamp+incrementing",
            "bulk"
          ]
        },
        {
          "name": "table.include.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Tables Included",
          "documentation": "A comma-separated list of regular expressions that match the fully-qualified names of tables to be copied. Identifier names are case sensitive. For example, ``table.include.list: \"DB_A.PUBLIC.CUSTOMER.*,DB_B.PUBLIC.CUSTOMER.*,\"``."
        },
        {
          "name": "table.exclude.list",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Tables Excluded",
          "documentation": "A comma-separated list of regular expressions that match the fully-qualified names of tables not to be copied. This only applies on the tables filtered using include list. Identifier names are case sensitive. For example, ``table.exclude.list: \"DB_A.PUBLIC.CUSTOMER.*,DB_B.PUBLIC.CUSTOMER.*,\"``."
        },
        {
          "name": "timestamp.columns.mapping",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Table to timestamp columns mappings",
          "documentation": "A comma-separated list of table regex to timestamp columns mappings. Timestamp columns supplied should strictly be of type ``TIMESTAMP_NTZ``. On specifying multiple timestamp columns, COALESCE SQL function would be used to find out the effective timestamp for a row. Expected format is ``regex1:[col1|col2],regex2:[col3]``. Regexes would be matched against the fully-qualified table names. Identifier names are case sensitive. Every table included for capture should match exactly one of the provided mappings. An example for a valid input would be ``COMPANY.EMPLOYEES.SALARY.*:[UPDATED_AT|MODIFIED_AT], COMPANY.FINANCE.ACCOUNTS.*:[CHANGED_AT]``."
        },
        {
          "name": "incrementing.column.mapping",
          "type": "LIST",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Table to incrementing column mappings",
          "documentation": "A comma-separated list of table regex to incrementing column mappings. Expected format is ``regex1:col2,regex2:col1``. Regexes would be matched against the fully-qualified table names. Identifier names are case sensitive. Every table included for capture should match exactly one of the provided mappings. An example for a valid input would be ``COMPANY.EMPLOYEES.SALARY*:EMP_ID,COMPANY.FINANCE.ACCOUNTS.*:ID``."
        },
        {
          "name": "db.timezone",
          "type": "STRING",
          "required": true,
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Database Timezone",
          "documentation": "Timezone to be used when interpreting values for timestamp types which don't have a timezone information in them. This should be set to the timezone of the snowflake account.",
          "recommender": {
            "name": "timezone"
          }
        },
        {
          "name": "timestamp.initial",
          "type": "LONG",
          "required": false,
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Initial Timestamp",
          "documentation": "Epoch timestamp in milliseconds which provides the start timestamp from where to capture rows. The value -1 sets the start timestamp to the current time, in this case older data would not be fetched. If not specified, start timestamp is treated as epoch start time, hence all data is fetched. Once the connector has managed to successfully record a source offset, this property has no effect even if changed to a different value later on."
        },
        {
          "name": "table.types",
          "type": "LIST",
          "default_value": "TABLE",
          "importance": "MEDIUM",
          "group": "Connector Details",
          "display_name": "Table Types",
          "documentation": "By default, the connector will only detect tables with type TABLE. This config allows a command separated list of table types to extract.",
          "recommended_values": [
            "TABLE",
            "VIEW"
          ]
        },
        {
          "name": "timestamp.granularity",
          "type": "STRING",
          "default_value": "NANOS_LONG",
          "required": false,
          "importance": "LOW",
          "group": "Connector Details",
          "display_name": "Timestamp granularity for timestamp columns",
          "documentation": "Define the granularity of the Timestamp column. `CONNECT_LOGICAL`: Represents timestamp values using Kafka Connect built-in representations. This may lead to loss of precision as this only supports milliseconds precision. `NANOS_LONG`: Represents timestamp values as nanos since epoch. Avoid this if any of the eligible timestamp columns contains timestamps greater than `2262-11-04 23:47:16.854775807 GMT`, nanos since epoch value would not fit in the range for long and hence would lead to erroneous values. Use `nanos_string` in such cases. `NANOS_STRING`: represents timestamp values as nanos since epoch in string.",
          "recommended_values": [
            "CONNECT_LOGICAL",
            "NANOS_LONG",
            "NANOS_STRING"
          ]
        },
        {
          "name": "poll.interval.ms",
          "type": "INT",
          "default_value": "5000",
          "importance": "LOW",
          "group": "Connector Details",
          "display_name": "Poll Interval (ms)",
          "documentation": "Frequency in ms to poll for new data in each table."
        }
      ],
      "connector_configs": [
        {
          "name": "connection.url",
          "value": "jdbc:snowflake://${connection.url}"
        },
        {
          "name": "connection.user"
        },
        {
          "name": "connection.credentials.source"
        },
        {
          "name": "connection.private.key"
        },
        {
          "name": "connection.private.key.passphrase"
        },
        {
          "name": "topic.prefix"
        },
        {
          "name": "table.include.list"
        },
        {
          "name": "table.exclude.list"
        },
        {
          "name": "mode"
        },
        {
          "name": "timestamp.columns.mapping"
        },
        {
          "name": "incrementing.column.mapping"
        },
        {
          "name": "db.timezone"
        },
        {
          "name": "timestamp.initial"
        },
        {
          "name": "table.types"
        },
        {
          "name": "timestamp.granularity"
        },
        {
          "name": "validate.non.null",
          "value": false
        },
        {
          "name": "poll.interval.ms"
        },
        {
          "name": "value.converter",
          "switch": {
            "output.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter"
            }
          }
        },
        {
          "name": "value.converter.schema.registry.url",
          "value": "${schema.registry.url}"
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "value": "USER_INFO"
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "value": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
        }
      ]
    },
    {
      "template_id": "common",
      "global_validators": [
        {
          "name": "required",
          "priority": "HIGHEST"
        },
        {
          "name": "recommended.values",
          "priority": "HIGHER"
        }
      ],
      "abstract": true,
      "config_defs": [
        {
          "name": "connector.class",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "display_name": "Connector class"
        },
        {
          "name": "name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "display_name": "Connector name",
          "documentation": "Sets a name for your connector."
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "KAFKA_API_KEY",
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.",
          "recommended_values": [
            "SERVICE_ACCOUNT",
            "KAFKA_API_KEY"
          ]
        },
        {
          "name": "kafka.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka API Key",
          "documentation": "Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY."
        },
        {
          "name": "kafka.service.account.api.key",
          "type": "PASSWORD",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.service.account.api.secret",
          "type": "PASSWORD",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.region",
          "type": "STRING",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.endpoint",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "kafka.user.id",
          "type": "INT",
          "required": false,
          "internal": true,
          "importance": "MEDIUM"
        },
        {
          "name": "cloud.environment",
          "type": "STRING",
          "required": true,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "connector.cloud",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "kafka.dedicated",
          "type": "STRING",
          "required": true,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "valid.kafka.api.key",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "kafka.service.account.oauth.token",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "kafka.logical.cluster.id",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "connect.connector_cross_region.enable",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "connector.regional.connectivity.enabled",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "sr.internal.sa.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "sr.internal.sa.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "LOW",
          "internal": true
        },
        {
          "name": "sr.internal.sa.validity.check",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "internal": true
        }
      ],
      "connector_configs": [
        {
          "name": "tasks.max"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "errors.log.enable",
          "value": "true"
        },
        {
          "name": "errors.log.include.messages",
          "value": "false"
        },
        {
          "name": "errors.retry.timeout",
          "value": "300000"
        },
        {
          "name": "errors.retry.delay.max.ms",
          "value": "30000"
        },
        {
          "name": "value.converter.ignore.modern.dialects",
          "value": "true"
        }
      ]
    },
    {
      "template_id": "common-kafka-connectivity",
      "abstract": true,
      "config_defs": [
        {
          "name": "connect.metadata_property.kafka.itsl.embed.lkc",
          "type": "STRING",
          "required": false,
          "default_value": "SKIP",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm",
          "type": "STRING",
          "required": false,
          "default_value": "UNSET",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "connect.metadata_property.kafka.itsl.bootstrap.servers",
          "type": "STRING",
          "required": false,
          "default_value": "UNSET",
          "importance": "HIGH",
          "internal": true
        },
        {
          "name": "connect.fips.provider",
          "type": "STRING",
          "required": false,
          "default_value": "UNSET",
          "default_value_provider": {
            "name": "defaultvalue.fips.provider"
          },
          "importance": "HIGH",
          "internal": true
        }
      ],
      "connector_configs": [
        {
          "name": "consumer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "producer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "producer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "consumer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "admin.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "producer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "consumer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "admin.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "consumer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "admin.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        }
      ]
    },
    {
      "template_id": "common-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.service.account.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka Service Account",
          "documentation": "The Service Account that will be used to generate the API keys to communicate with Kafka Cluster."
        },
        {
          "name": "kafka.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "display_name": "Kafka API Secret",
          "documentation": "Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.",
          "dependents": [
            "kafka.api.key"
          ]
        },
        {
          "name": "datapreview.schemas.enable",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "default_value": "false",
          "display_name": "Show schemas in data preview request output",
          "group": "Kafka Cluster credentials",
          "documentation": "This config key only applies to data preview requests and governs whether the data preview output has record schema with it.\nThe visibility condition is set such that it can never be true.\nSo this key does not show in create connector UI."
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "none",
          "display_name": "errors.tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "producer.override.linger.ms",
          "type": "LONG",
          "required": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "producer.override.linger.ms",
          "documentation": "The producer groups together any records that arrive in between request transmissions into a single batched request. More details can be found in the documentation: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#linger-ms."
        }
      ],
      "connector_configs": [
        {
          "name": "topic.creation.default.replication.factor",
          "value": "3"
        },
        {
          "name": "topic.creation.default.partitions",
          "value": "1"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "producer.override.max.request.size",
          "switch": {
            "kafka.dedicated": {
              "true": "20971610",
              "false": "8388698"
            }
          }
        },
        {
          "name": "topic.creation.default.max.message.bytes",
          "switch": {
            "kafka.dedicated": {
              "true": "20971520",
              "false": "8388608"
            }
          }
        },
        {
          "name": "datapreview.schemas.enable"
        },
        {
          "name": "producer.override.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.sasl.jaas.config",
          "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "producer.override.linger.ms"
        }
      ]
    },
    {
      "template_id": "schema-registry",
      "abstract": true,
      "config_defs": [
        {
          "name": "schema.registry.url",
          "type": "STRING",
          "importance": "MEDIUM",
          "internal": true
        },
        {
          "name": "schema.context.name",
          "type": "STRING",
          "group": "Schema Config",
          "importance": "MEDIUM",
          "display_name": "Schema context",
          "documentation": "Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.",
          "default_value": "default",
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": []
    },
    {
      "template_id": "csfle-source",
      "abstract": true,
      "config_defs": [
        {
          "name": "csfle.enabled",
          "type": "BOOLEAN",
          "default_value": "false",
          "importance": "HIGH",
          "group": "CSFLE",
          "docs_hidden": true,
          "display_name": "Enable Client-Side Field Level Encryption",
          "documentation": "Determines whether the connector honours CSFLE rules or not",
          "conditional_metadata_provider": [
            {
              "name": "metadata.conditional.visible",
              "arguments": {
                "config": "csfle.configs.visible",
                "values": "false"
              },
              "metadata": {
                "visibility": "false"
              }
            }
          ]
        },
        {
          "name": "sr.service.account.id",
          "type": "STRING",
          "importance": "HIGH",
          "group": "CSFLE",
          "docs_hidden": true,
          "display_name": "Schema Registry Service Account",
          "documentation": "Select the service account that has appropriate permissions to schemas and encryption keys in the Schema Registry."
        },
        {
          "name": "csfle.configs.visible",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "default_value": "false",
          "internal": true
        }
      ],
      "connector_configs": [
        {
          "name": "csfle.enabled"
        },
        {
          "name": "value.converter.rule.executors._ENCRYPT_.disabled",
          "switch": {
            "csfle.enabled": {
              "true": "false",
              "false": "true"
            }
          }
        },
        {
          "name": "value.converter.rule.executors._ENCRYPT_.onFailure",
          "switch": {
            "csfle.enabled": {
              "true": "ERROR"
            }
          }
        },
        {
          "name": "value.converter.latest.cache.ttl.sec",
          "switch": {
            "csfle.enabled": {
              "true": "300"
            }
          }
        },
        {
          "name": "key.converter.rule.executors._ENCRYPT_.disabled",
          "switch": {
            "csfle.enabled": {
              "true": "false",
              "false": "true"
            }
          }
        },
        {
          "name": "key.converter.rule.executors._ENCRYPT_.onFailure",
          "switch": {
            "csfle.enabled": {
              "true": "ERROR"
            }
          }
        },
        {
          "name": "key.converter.auto.register.schemas",
          "switch": {
            "csfle.enabled": {
              "true": "false"
            }
          }
        },
        {
          "name": "key.converter.use.latest.version",
          "switch": {
            "csfle.enabled": {
              "true": "true"
            }
          }
        },
        {
          "name": "key.converter.latest.cache.ttl.sec",
          "switch": {
            "csfle.enabled": {
              "true": "300"
            }
          }
        }
      ]
    },
    {
      "template_id": "source-connector-schema-enabled-output-data-format",
      "abstract": true,
      "config_defs": [
        {
          "name": "output.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "AVRO",
          "importance": "HIGH",
          "group": "Output messages",
          "display_name": "Select output record value format",
          "alias": "data.format",
          "documentation": "Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, or PROTOBUF. Please configure Confluent Cloud Schema Registry.",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "value.converter.ignore.default.for.nullables",
          "alias": "ignore.default.for.nullables",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.ignore.default.for.nullables",
          "documentation": "When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters."
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "type": "BOOLEAN",
          "documentation": "Whether to scrub invalid names by replacing invalid characters with valid characters. Applicable for Avro and Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.scrub.invalid.names"
        }
      ],
      "connector_configs": [
        {
          "name": "value.converter",
          "switch": {
            "output.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter"
            }
          }
        },
        {
          "name": "value.converter.schema.registry.url",
          "value": "${schema.registry.url}"
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "value": "USER_INFO"
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "value": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
        },
        {
          "name": "value.converter.ignore.default.for.nullables"
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "dynamic.mapper": {
            "name": "value.converter.scrub.invalid.names.mapper"
          }
        }
      ]
    },
    {
      "template_id": "super",
      "abstract": true,
      "config_defs": [
        {
          "name": "auto.restart.on.user.error",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Auto-restart policy",
          "display_name": "Enable Connector Auto-restart",
          "documentation": "Enable connector to automatically restart on user-actionable errors."
        },
        {
          "name": "value.converter.enhanced.avro.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information and Enums. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data",
          "type": "BOOLEAN",
          "documentation": "Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to generate an index suffix for unions. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums",
          "type": "BOOLEAN",
          "documentation": "Whether to represent enums as integers. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should be specified with an optional label. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls",
          "type": "BOOLEAN",
          "documentation": "Whether to generate a struct variable for null values. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should use primitive wrapper messages. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives",
          "type": "BOOLEAN",
          "documentation": "Whether a wrapper message should be interpreted as a raw primitive at root level. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties",
          "type": "BOOLEAN",
          "documentation": "Whether to allow additional properties for object schemas. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired",
          "type": "BOOLEAN",
          "documentation": "Whether to set non-required properties to be optional. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format",
          "type": "STRING",
          "recommended_values": [
            "BASE64",
            "NUMERIC"
          ],
          "documentation": "Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:\nBASE64 to serialize DECIMAL logical types as base64 encoded binary data and\nNUMERIC to serialize Connect DECIMAL logical type values in JSON/JSON_SR as a number representing the decimal value.",
          "group": "Additional Configs",
          "alias": "json.output.decimal.format",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.decimal.format",
          "default_value": "BASE64"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "type": "BOOLEAN",
          "documentation": "Specify if the Serializer should attempt to register the Schema.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.auto.register.schemas"
        },
        {
          "name": "value.converter.use.latest.version",
          "type": "BOOLEAN",
          "documentation": "Use latest version of schema in subject for serialization when auto.register.schemas is false.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.latest.version"
        },
        {
          "name": "value.converter.latest.compatibility.strict",
          "type": "BOOLEAN",
          "documentation": "Verify latest subject version is backward compatible when `use.latest.version` is `true`.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "type": "STRING",
          "default_value": "TopicNameStrategy",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "alias": "key.subject.name.strategy",
          "documentation": "How to construct the subject name for key schema registration.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "key.converter.key.subject.name.strategy"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "default_value": "TopicNameStrategy",
          "alias": "subject.name.strategy,value.subject.name.strategy",
          "documentation": "Determines how to construct the subject name under which the value schema is registered with Schema Registry.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.value.subject.name.strategy"
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.reference.subject.name.strategy"
        },
        {
          "name": "value.converter.allow.optional.map.keys",
          "type": "BOOLEAN",
          "documentation": "Allow optional string map key when converting from Connect Schema to Avro Schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions",
          "type": "BOOLEAN",
          "default_value": "false",
          "documentation": "Whether to flatten singleton unions. Applicable for Avro and JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2",
          "type": "BOOLEAN",
          "documentation": "Whether proto2 optionals are supported. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to flatten unions (oneofs). Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "header.converter",
          "documentation": "The converter class for the headers. This is used to serialize and deserialize the headers of the messages.",
          "recommended_values": [
            "org.apache.kafka.connect.storage.SimpleHeaderConverter",
            "org.apache.kafka.connect.storage.StringConverter",
            "org.apache.kafka.connect.json.JsonConverter",
            "org.apache.kafka.connect.converters.BooleanConverter",
            "org.apache.kafka.connect.converters.DoubleConverter",
            "org.apache.kafka.connect.converters.FloatConverter",
            "org.apache.kafka.connect.converters.IntegerConverter",
            "org.apache.kafka.connect.converters.LongConverter",
            "org.apache.kafka.connect.converters.ShortConverter"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "auto.restart.on.user.error"
        },
        {
          "name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "dynamic.mapper": {
            "name": "value.converter.auto.register.schemas.mapper"
          }
        },
        {
          "name": "value.converter.use.latest.version",
          "dynamic.mapper": {
            "name": "value.converter.use.latest.version.mapper"
          }
        },
        {
          "name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.reference.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter"
        }
      ]
    }
  ],
  "all_config_def_names": [
    "connection.credentials.source",
    "connection.private.key",
    "connection.private.key.passphrase",
    "connection.url",
    "connection.user",
    "connector.class",
    "csfle.enabled",
    "datapreview.schemas.enable",
    "db.timezone",
    "incrementing.column.mapping",
    "kafka.api.key",
    "kafka.api.secret",
    "kafka.auth.mode",
    "kafka.service.account.id",
    "mode",
    "name",
    "output.data.format",
    "poll.interval.ms",
    "schema.context.name",
    "sr.service.account.id",
    "table.exclude.list",
    "table.include.list",
    "table.types",
    "tasks.max",
    "timestamp.columns.mapping",
    "timestamp.granularity",
    "timestamp.initial",
    "topic.prefix"
  ],
  "all_connector_configs": [
    {
      "name": "connection.url",
      "value": "jdbc:snowflake://${connection.url}"
    },
    {
      "name": "value.converter.schema.registry.url",
      "value": "${schema.registry.url}"
    },
    {
      "name": "value.converter.basic.auth.user.info",
      "value": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
    },
    {
      "name": "consumer.override.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "producer.override.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "admin.override.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers": {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "producer.override.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "consumer.override.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "admin.override.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc": {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "producer.override.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "admin.override.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "value.converter.schema.registry.url",
      "value": "${schema.registry.url}"
    },
    {
      "name": "value.converter.basic.auth.user.info",
      "value": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
    }
  ]
}