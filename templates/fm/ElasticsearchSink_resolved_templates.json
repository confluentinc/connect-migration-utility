{
  "templates": [
    {
      "template_id": "ElasticsearchSink",
      "connector_type": "SINK",
      "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
      "config_defs": [
        {
          "name": "input.data.format",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "display_name": "Input Kafka record value format",
          "documentation": "Sets the input Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON"
          ]
        },
        {
          "name": "connection.url",
          "type": "LIST",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your Elasticsearch Service?",
          "order_in_group": 1,
          "display_name": "Connection URI",
          "documentation": "Elasticsearch Service connection URI (e.g. https://123123.us-east-1.aws.found.io:9243)."
        },
        {
          "name": "connection.username",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "How should we connect to your Elasticsearch Service?",
          "order_in_group": 2,
          "display_name": "Connection user",
          "documentation": "The username used to authenticate with Elasticsearch Service."
        },
        {
          "name": "connection.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "How should we connect to your Elasticsearch Service?",
          "order_in_group": 3,
          "display_name": "Connection password",
          "documentation": "The password used to authenticate with Elasticsearch Service."
        },
        {
          "name": "elastic.security.protocol",
          "type": "STRING",
          "required": false,
          "default_value": "PLAINTEXT",
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 1,
          "display_name": "Enable SSL Security",
          "documentation": "This should be set to SSL if you want to enable PKI auth with SSL support. Otherwise all ssl configs are ignored. Note that the connector will still use SSL if https is used.",
          "recommended_values": [
            "PLAINTEXT",
            "SSL"
          ]
        },
        {
          "name": "elastic.https.ssl.keystore.file",
          "type": "PASSWORD",
          "required": false,
          "default_value": null,
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 2,
          "display_name": "SSL Keystore file",
          "documentation": "The key store file. This is optional for client and can be used for two-way authentication for client."
        },
        {
          "name": "elastic.https.ssl.key.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 3,
          "display_name": "Keystore Key Password",
          "documentation": "The password of the private key in the key store file. This is required for clients only if two-way authentication is configured."
        },
        {
          "name": "elastic.https.ssl.keystore.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 4,
          "display_name": "Keystore password",
          "documentation": "The store password for the key store file. This is optional for client and only needed if 'ssl.keystore.location' is configured.  Key store password is not supported for PEM format."
        },
        {
          "name": "elastic.https.ssl.keystore.type",
          "type": "STRING",
          "required": false,
          "default_value": "JKS",
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 5,
          "display_name": "Keystore file type",
          "documentation": "The file format of the key store file. This is optional for client."
        },
        {
          "name": "elastic.https.ssl.truststore.file",
          "type": "PASSWORD",
          "required": false,
          "default_value": null,
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 6,
          "display_name": "SSL Truststore file",
          "documentation": "The Truststore file with the certificates of the trusted CAs."
        },
        {
          "name": "elastic.https.ssl.truststore.password",
          "type": "PASSWORD",
          "required": false,
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 7,
          "display_name": "Truststore password",
          "documentation": "The password for the trust store file. If a password is not set, trust store file configured will still be used, but integrity checking is disabled. Trust store password is not supported for PEM format."
        },
        {
          "name": "elastic.https.ssl.truststore.type",
          "type": "STRING",
          "required": false,
          "default_value": "JKS",
          "importance": "MEDIUM",
          "group": "Security",
          "order_in_group": 8,
          "display_name": "Truststore type",
          "documentation": "The file format of the trust store file."
        },
        {
          "name": "elastic.https.ssl.keymanager.algorithm",
          "type": "STRING",
          "required": false,
          "default_value": "SunX509",
          "importance": "LOW",
          "group": "Security",
          "order_in_group": 9,
          "display_name": "Keymanager algorithm",
          "documentation": "The algorithm used by key manager factory for SSL connections."
        },
        {
          "name": "elastic.https.ssl.trustmanager.algorithm",
          "type": "STRING",
          "required": false,
          "default_value": "PKIX",
          "importance": "LOW",
          "group": "Security",
          "order_in_group": 10,
          "display_name": "Trustmanager algorithm",
          "documentation": "The algorithm used by trust manager factory for SSL connections."
        },
        {
          "name": "elastic.https.ssl.endpoint.identification.algorithm",
          "type": "STRING",
          "required": false,
          "default_value": "https",
          "importance": "LOW",
          "group": "Security",
          "order_in_group": 11,
          "display_name": "SSL Endpoint identification algorithm",
          "documentation": "The endpoint identification algorithm to validate server hostname using server certificate."
        },
        {
          "name": "external.resource.usage",
          "type": "STRING",
          "required": false,
          "default_value": "DISABLED",
          "importance": "HIGH",
          "group": "External Resource Mapping",
          "order_in_group": 1,
          "display_name": "External Resource Usage",
          "documentation": "The type of external resource the connector writes to, such as indices, datastreams or aliases. Valid options are INDEX, DATASTREAM, ALIAS_INDEX, ALIAS_DATASTREAM, and DISABLED. When set to DISABLED, the connector will auto-create indices or datastreams based on the topic name and datastream configurations.",
          "recommended_values": [
            "DISABLED",
            "INDEX",
            "DATASTREAM",
            "ALIAS_INDEX",
            "ALIAS_DATASTREAM"
          ]
        },
        {
          "name": "topic.to.external.resource.mapping",
          "type": "LIST",
          "required": false,
          "default_value": "",
          "importance": "HIGH",
          "group": "External Resource Mapping",
          "order_in_group": 2,
          "display_name": "Topic to External Resource Mapping",
          "documentation": "A list of topic-to-resource mappings in the format 'topic:resource'. If specified, the connector will use the provided resource name (index, data stream, or alias) instead of the topic name for writing to Elasticsearch. The resource must exist in Elasticsearch before configuring the connector. The type of resource (index, data stream, or alias) is determined by the 'external.resource.usage' configuration."
        },
        {
          "name": "data.stream.type",
          "type": "STRING",
          "required": false,
          "default_value": "none",
          "importance": "LOW",
          "group": "Data Streams",
          "order_in_group": 1,
          "display_name": "Data Stream Type",
          "documentation": "Describes the generic type of data to be written to a data stream. The default value is `none`, indicating that the connector will write to regular indices. If set, this configuration will be used alongside data.stream.dataset to construct the data stream name in the form of {``data.stream.type``}-{``data.stream.dataset``}-{``data.stream.namespace``}. Possible values are `logs`, `metrics`, `none`, and custom index templates defined in the destination cluster are also supported."
        },
        {
          "name": "data.stream.dataset",
          "type": "STRING",
          "required": false,
          "default_value": "",
          "importance": "LOW",
          "group": "Data Streams",
          "order_in_group": 2,
          "display_name": "Data Stream Dataset",
          "documentation": "Describes the data ingested and its structure to be written to a data stream. This can be any arbitrary string, provided it is no longer than 100 characters, in all lowercase, and does not contain spaces or any special characters ``/\\*\"<>|,#:-``. If no value is set, the connector writes to regular indices. If set, this configuration will be used alongside data.stream.type to construct the data stream name in the form of {``data.stream.type``}-{``data.stream.dataset``}-{``data.stream.namespace``}."
        },
        {
          "name": "data.stream.namespace",
          "type": "STRING",
          "required": false,
          "default_value": "${topic}",
          "importance": "LOW",
          "group": "Data Streams",
          "order_in_group": 3,
          "display_name": "Data Stream Namespace",
          "documentation": "Generic name describing a user-configurable arbitrary grouping for writing to a data stream. It can be any string up to 100 characters, in lowercase, without spaces or special characters (`/\\*\"<>|,#:-`). If unset, the connector writes to regular indices. When set, it is used with `data.stream.type` and `data.stream.dataset` to form the data stream name in the format `{data.stream.type}-{data.stream.dataset}-{data.stream.namespace}`. Default is `${topic}`, which means the topic name."
        },
        {
          "name": "data.stream.timestamp.field",
          "type": "LIST",
          "required": false,
          "default_value": "",
          "importance": "LOW",
          "group": "Data Streams",
          "order_in_group": 4,
          "display_name": "Data Stream Timestamp Field",
          "documentation": "All documents sent to a data stream need an ``@timestamp`` field with values of type ``date`` or ``date_nanos``. Otherwise, the document  will not be sent. If multiple fields are provided, the first field listed that also appears in the record will be used. If this configuration is left empty, all of the documents will use the Kafka record timestamp as the ``@timestamp`` field value. Note that ``@timestamp`` still needs to be explicitly listed if records already contain this field."
        },
        {
          "name": "key.ignore",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 1,
          "display_name": "Key ignore",
          "documentation": "Whether to ignore the record key for the purpose of forming the Elasticsearch document ID. When this is set to true, document IDs will be generated as topic+partition+offset taken from the record. When this is set to false, the record key will be used as the Elasticsearch document ID.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "topic.key.ignore",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 2,
          "display_name": "Topics for 'Ignore Key' mode",
          "documentation": "List of topics for which ``key.ignore`` should be ``true``."
        },
        {
          "name": "schema.ignore",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 3,
          "display_name": "Schema ignore",
          "documentation": "Whether to ignore schemas during indexing. When this is set to true, the record schema will be ignored for the purpose of registering an Elasticsearch mapping. Elasticsearch will infer the mapping from the data (dynamic mapping needs to be enabled by the user).",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "topic.schema.ignore",
          "type": "LIST",
          "required": false,
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 4,
          "display_name": "Topics for 'Ignore Schema' mode",
          "documentation": "List of topics for which ``schema.ignore`` should be ``true``."
        },
        {
          "name": "compact.map.entries",
          "type": "STRING",
          "required": false,
          "default_value": "true",
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 5,
          "display_name": "Compact map entries",
          "documentation": "Defines how map entries with string keys within record values should be written to JSON. When this is set to true, these entries are written compactly as \"entryKey\": \"entryValue\". Otherwise, map entries with string keys are written as a nested document {\"key\": \"entryKey\", \"value\": \"entryValue\"}.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "write.method",
          "type": "STRING",
          "required": false,
          "default_value": "INSERT",
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 6,
          "display_name": "Write Method",
          "documentation": "Method used for writing data to Elasticsearch, and one of INSERT or UPSERT. The default method is INSERT, in which the connector constructs a document from the record value and inserts that document into Elasticsearch, completely replacing any existing document with the same ID; this matches previous behavior. The UPSERT method will create a new document if one with the specified ID does not yet exist, or will update an existing document with the same ID by adding/replacing only those fields present in the record value. The UPSERT method may require additional time and resources of Elasticsearch, so consider increasing the read.timeout.ms and decreasing the batch.size configuration properties.",
          "recommended_values": [
            "INSERT",
            "UPSERT"
          ]
        },
        {
          "name": "behavior.on.null.values",
          "type": "STRING",
          "required": false,
          "default_value": "ignore",
          "importance": "LOW",
          "group": "Error Handling",
          "order_in_group": 1,
          "display_name": "Behavior on null values",
          "documentation": "How to handle records with a non-null key and a null value (i.e. Kafka tombstone records). Valid options are ignore, delete, and fail. Ignore will skip the record. Delete will delete the record. Fail will fail the connector.",
          "recommended_values": [
            "ignore",
            "delete",
            "fail"
          ]
        },
        {
          "name": "behavior.on.malformed.documents",
          "type": "STRING",
          "required": false,
          "default_value": "fail",
          "importance": "LOW",
          "group": "Error Handling",
          "order_in_group": 2,
          "display_name": "Behavior on malformed documents",
          "documentation": "How to handle records that Elasticsearch rejects due to some malformation of the document itself, such as an index mapping conflict, a field name containing illegal characters, or a record with a missing id. 'ignore' will skip the bad records and 'fail' will fail the connector.",
          "recommended_values": [
            "ignore",
            "fail"
          ]
        },
        {
          "name": "drop.invalid.message",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Error Handling",
          "order_in_group": 3,
          "display_name": "Drop invalid message",
          "documentation": "Whether to drop a record if it cannot be converted to an Elasticsearch document.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "batch.size",
          "type": "INT",
          "required": false,
          "default_value": "2000",
          "importance": "MEDIUM",
          "group": "Connection Details",
          "order_in_group": 1,
          "display_name": "Batch size",
          "documentation": "The number of records to process as a batch when writing to Elasticsearch."
        },
        {
          "name": "linger.ms",
          "type": "INT",
          "required": false,
          "default_value": "1000",
          "importance": "LOW",
          "group": "Connection Details",
          "order_in_group": 2,
          "display_name": "Linger (ms)",
          "documentation": "Linger time in milliseconds for batching. Records that arrive in between request transmissions are batched into a single bulk indexing request, based on the batch.size configuration. Normally this only occurs under load when records arrive faster than they can be sent out. However, it may be desirable to reduce the number of requests even under light load and benefit from bulk indexing. This setting helps accomplish that - when a pending batch is not full, rather than immediately sending it out the task will wait up to the given delay to allow other records to be added so that they can be batched into a single request."
        },
        {
          "name": "flush.timeout.ms",
          "type": "INT",
          "required": false,
          "default_value": "10000",
          "importance": "LOW",
          "group": "Connection Details",
          "order_in_group": 3,
          "display_name": "Flush timeout (ms)",
          "documentation": "The timeout in milliseconds to use for periodic flushing, and when waiting for buffer space to be made available by completed requests as records are added. If this timeout is exceeded the task will fail."
        },
        {
          "name": "connection.compression",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Connection Details",
          "order_in_group": 5,
          "display_name": "Connection compression",
          "documentation": "Whether to use GZip compression on HTTP connection to ElasticSearch. To make this setting to work the http.compression setting also needs to be enabled at the Elasticsearch nodes before using it.",
          "recommended_values": [
            "true",
            "false"
          ]
        },
        {
          "name": "read.timeout.ms",
          "type": "INT",
          "required": false,
          "default_value": 15000,
          "importance": "LOW",
          "group": "Connection Details",
          "order_in_group": 6,
          "display_name": "Read Timeout",
          "documentation": "How long to wait in milliseconds for the Elasticsearch server to send a response. The task fails if any read operation times out."
        },
        {
          "name": "external.version.header",
          "type": "STRING",
          "required": false,
          "default_value": "",
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 7,
          "display_name": "External Version Header Name",
          "documentation": "Header name to pull value for external versioning, defaults to using the kafka record offset. Must have a numeric value."
        },
        {
          "name": "use.autogenerated.ids",
          "type": "STRING",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Data Conversion",
          "order_in_group": 8,
          "display_name": "Elasticsearch Generated IDs",
          "documentation": "Specifies whether to use auto-generated Elasticsearch document IDs for insertion requests. Note that this setting removes exactly once guarantees, and message delivery will be at least once. This only applies if the write method is set to `INSERT`. When set to `true`, the `Ignore Key mode` option will also be ignored when sending data to Elasticsearch.",
          "recommended_values": [
            "true",
            "false"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "consumer.bootstrap.servers",
          "value": "${kafka.endpoint}"
        },
        {
          "name": "producer.bootstrap.servers",
          "value": "${kafka.endpoint}"
        },
        {
          "name": "consumer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "producer.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "consumer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "topics"
        },
        {
          "name": "tasks.max"
        },
        {
          "name": "connection.url"
        },
        {
          "name": "connection.username"
        },
        {
          "name": "connection.password"
        },
        {
          "name": "elastic.security.protocol"
        },
        {
          "name": "elastic.https.ssl.keystore.location",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.keystore.location}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.key.password",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.key.password}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.keystore.password",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.keystore.password}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.keystore.type",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.keystore.type}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.truststore.location",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.truststore.location}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.truststore.password",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.truststore.password}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.truststore.type",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.truststore.type}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.keymanager.algorithm",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.keymanager.algorithm}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.trustmanager.algorithm",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.trustmanager.algorithm}"
            }
          }
        },
        {
          "name": "elastic.https.ssl.endpoint.identification.algorithm",
          "switch": {
            "elastic.security.protocol": {
              "SSL": "${elastic.https.ssl.endpoint.identification.algorithm}"
            }
          }
        },
        {
          "name": "errors.log.enable",
          "value": "false"
        },
        {
          "name": "connection.timeout.ms",
          "value": "5000"
        },
        {
          "name": "read.timeout.ms"
        },
        {
          "name": "key.ignore"
        },
        {
          "name": "schema.ignore"
        },
        {
          "name": "behavior.on.null.values"
        },
        {
          "name": "behavior.on.malformed.documents"
        },
        {
          "name": "drop.invalid.message"
        },
        {
          "name": "compact.map.entries"
        },
        {
          "name": "batch.size"
        },
        {
          "name": "linger.ms"
        },
        {
          "name": "flush.timeout.ms"
        },
        {
          "name": "connection.compression"
        },
        {
          "name": "data.stream.type"
        },
        {
          "name": "data.stream.dataset"
        },
        {
          "name": "data.stream.namespace"
        },
        {
          "name": "data.stream.timestamp.field"
        },
        {
          "name": "external.resource.usage"
        },
        {
          "name": "topic.to.external.resource.mapping"
        },
        {
          "name": "use.autogenerated.ids"
        },
        {
          "name": "key.converter",
          "value": "org.apache.kafka.connect.storage.StringConverter"
        },
        {
          "name": "key.converter.schemas.enable",
          "value": "false"
        },
        {
          "name": "flush.synchronously",
          "dynamic.mapper": {
            "name": "topic.mutating.smt"
          }
        },
        {
          "name": "write.method"
        },
        {
          "name": "topic.key.ignore"
        },
        {
          "name": "topic.schema.ignore"
        },
        {
          "name": "log.sensitive.data",
          "value": "false"
        },
        {
          "name": "external.version.header"
        },
        {
          "name": "connector.endpoint",
          "value": "${connection.url}"
        }
      ]
    },
    {
      "template_id": "common",
      "global_validators": [
        {
          "name": "required",
          "priority": "HIGHEST"
        },
        {
          "name": "recommended.values",
          "priority": "HIGHER"
        }
      ],
      "abstract": true,
      "config_defs": [
        {
          "name": "connector.class",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 1,
          "display_name": "Connector class"
        },
        {
          "name": "name",
          "type": "STRING",
          "required": true,
          "importance": "HIGH",
          "group": "How should we connect to your data?",
          "order_in_group": 2,
          "display_name": "Connector name",
          "documentation": "Sets a name for your connector."
        },
        {
          "name": "tasks.max",
          "type": "INT",
          "required": true,
          "importance": "HIGH",
          "group": "Number of tasks for this connector",
          "order_in_group": 1,
          "display_name": "Tasks",
          "documentation": "Maximum number of tasks for the connector."
        },
        {
          "name": "kafka.auth.mode",
          "type": "STRING",
          "required": false,
          "default_value": "KAFKA_API_KEY",
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 1,
          "display_name": "Kafka Cluster Authentication mode",
          "documentation": "Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.",
          "recommended_values": [
            "SERVICE_ACCOUNT",
            "KAFKA_API_KEY"
          ]
        },
        {
          "name": "kafka.api.key",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka API Key",
          "documentation": "Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY."
        }
      ],
      "connector_configs": [
        {
          "name": "tasks.max"
        },
        {
          "name": "confluent.topic.bootstrap.servers",
          "value": "Placeholder value to pass connector validations"
        },
        {
          "name": "errors.log.enable",
          "value": "true"
        },
        {
          "name": "errors.log.include.messages",
          "value": "false"
        },
        {
          "name": "errors.retry.timeout",
          "value": "300000"
        },
        {
          "name": "errors.retry.delay.max.ms",
          "value": "30000"
        },
        {
          "name": "value.converter.ignore.modern.dialects",
          "value": "true"
        }
      ]
    },
    {
      "template_id": "common-kafka-connectivity",
      "abstract": true,
      "config_defs": [],
      "connector_configs": [
        {
          "name": "consumer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "producer.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.bootstrap.servers",
          "switch": {
            "connect.metadata_property.kafka.itsl.bootstrap.servers": {
              "UNSET": "${kafka.endpoint}",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
            }
          }
        },
        {
          "name": "admin.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "producer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "consumer.override.ssl.trustmanager.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "SECURED": "ConfluentTls",
              "DEFAULT": "PKIX"
            }
          }
        },
        {
          "name": "admin.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "producer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "consumer.override.ssl.endpoint.identification.algorithm",
          "switch": {
            "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm": {
              "UNSECURED_PREPROD_ONLY": "",
              "SECURED": "",
              "DEFAULT": "https"
            }
          }
        },
        {
          "name": "admin.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.security.providers",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "io.confluent.kafka.security.fips.provider.BcFipsProviderCreator,io.confluent.kafka.security.fips.provider.BcFipsJsseProviderCreator,io.confluent.kafka.server.plugins.ssl.ConfluentTrustProviderCreator",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.provider",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "BCJSSE",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.cipher.suites",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CCM,TLS_ECDHE_ECDSA_WITH_AES_128_CCM,TLS_ECDHE_ECDSA_WITH_AES_256_CCM_8,TLS_ECDHE_ECDSA_WITH_AES_128_CCM_8,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "admin.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "consumer.override.ssl.enabled.protocols",
          "switch": {
            "connect.fips.provider": {
              "BCJSSE": "TLSv1.2,TLSv1.3",
              "DEFAULT": null
            }
          }
        },
        {
          "name": "producer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "consumer.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "admin.override.confluent.lkc.id",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "",
              "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "producer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "consumer.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.mode",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "PROXY",
              "DEFAULT": "LOCAL"
            }
          }
        },
        {
          "name": "admin.override.confluent.proxy.protocol.client.version",
          "switch": {
            "connect.metadata_property.kafka.itsl.embed.lkc": {
              "SKIP": "NONE",
              "DEFAULT": "V2"
            }
          }
        }
      ]
    },
    {
      "template_id": "common-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "kafka.service.account.id",
          "type": "STRING",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 2,
          "display_name": "Kafka Service Account",
          "documentation": "The Service Account that will be used to generate the API keys to communicate with Kafka Cluster."
        },
        {
          "name": "kafka.api.secret",
          "type": "PASSWORD",
          "required": false,
          "importance": "HIGH",
          "group": "Kafka Cluster credentials",
          "order_in_group": 3,
          "display_name": "Kafka API Secret",
          "documentation": "Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.",
          "dependents": [
            "kafka.api.key"
          ]
        },
        {
          "name": "topics",
          "type": "LIST",
          "required": true,
          "importance": "HIGH",
          "group": "Which topics do you want to get data from?",
          "order_in_group": 1,
          "display_name": "Topic names",
          "documentation": "Identifies the topic name or a comma-separated list of topic names.",
          "dependents": [
            "kafka.api.secret"
          ],
          "sanitizers": [
            {
              "name": "trim.list"
            }
          ]
        },
        {
          "name": "max.poll.interval.ms",
          "type": "LONG",
          "required": false,
          "importance": "LOW",
          "group": "Consumer configuration",
          "order_in_group": 1,
          "display_name": "Max poll interval(ms)",
          "default_value": "300000",
          "documentation": "The maximum delay between subsequent consume requests to Kafka. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 300000 milliseconds (5 minutes)."
        },
        {
          "name": "max.poll.records",
          "type": "LONG",
          "required": false,
          "importance": "LOW",
          "group": "Consumer configuration",
          "order_in_group": 2,
          "display_name": "Max poll records",
          "default_value": "500",
          "documentation": "The maximum number of records to consume from Kafka in a single request. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 500 records."
        },
        {
          "name": "errors.tolerance",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "default_value": "all",
          "display_name": "errors.tolerance",
          "documentation": "Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.",
          "recommended_values": [
            "none",
            "all"
          ]
        },
        {
          "name": "errors.deadletterqueue.topic.name",
          "type": "STRING",
          "importance": "LOW",
          "group": "Which topics do you want to get data from?",
          "order_in_group": 2,
          "display_name": "Dead Letter Queue Topic Name",
          "documentation": "The name of the topic to be used as the dead letter queue (DLQ) for messages that result in an error when processed by this sink connector, or its transformations or converters. Defaults to 'dlq-${connector}' if not set. The DLQ topic will be created automatically if it does not exist. You can provide ``${connector}`` in the value to use it as a placeholder for the logical cluster ID.",
          "default_value": "dlq-${connector}"
        }
      ],
      "connector_configs": [
        {
          "name": "topics"
        },
        {
          "name": "errors.tolerance"
        },
        {
          "name": "errors.deadletterqueue.topic.name",
          "dynamic.mapper": {
            "name": "errors.deadletterqueue.topic.mapper"
          }
        },
        {
          "name": "errors.deadletterqueue.topic.replication.factor",
          "value": "3"
        },
        {
          "name": "errors.deadletterqueue.context.headers.enable",
          "value": "true"
        },
        {
          "name": "consumer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "consumer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "consumer.override.max.poll.interval.ms",
          "value": "${max.poll.interval.ms}"
        },
        {
          "name": "consumer.override.max.poll.records",
          "value": "${max.poll.records}"
        },
        {
          "name": "producer.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "producer.override.sasl.mechanism",
          "value": "PLAIN"
        },
        {
          "name": "admin.override.security.protocol",
          "value": "SASL_SSL"
        },
        {
          "name": "admin.override.sasl.mechanism",
          "value": "PLAIN"
        }
      ]
    },
    {
      "template_id": "schema-registry",
      "abstract": true,
      "config_defs": [
        {
          "name": "schema.context.name",
          "type": "STRING",
          "group": "Schema Config",
          "order_in_group": 1,
          "importance": "MEDIUM",
          "display_name": "Schema context",
          "documentation": "Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.",
          "default_value": "default",
          "dependents": [
            "schema.registry.url"
          ]
        }
      ],
      "connector_configs": []
    },
    {
      "template_id": "input-data-format",
      "abstract": true,
      "config_defs": [
        {
          "name": "input.data.format",
          "type": "STRING",
          "required": true,
          "default_value": "JSON",
          "importance": "HIGH",
          "alias": "data.format",
          "group": "Input messages",
          "order_in_group": 1,
          "display_name": "Input Kafka record value format",
          "documentation": "Sets the input Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, JSON or BYTES. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.",
          "recommended_values": [
            "AVRO",
            "JSON_SR",
            "PROTOBUF",
            "JSON",
            "BYTES"
          ],
          "dependents": [
            "schema.registry.url"
          ]
        },
        {
          "name": "value.converter.schemas.enable",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "alias": "schemas.enable",
          "display_name": "value.converter.schemas.enable",
          "documentation": "Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.replace.null.with.default",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "alias": "replace.null.with.default",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.replace.null.with.default",
          "documentation": "Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter."
        },
        {
          "name": "value.converter.ignore.default.for.nullables",
          "alias": "ignore.default.for.nullables",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "false",
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "value.converter.ignore.default.for.nullables",
          "documentation": "When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters."
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "type": "BOOLEAN",
          "documentation": "Whether to scrub invalid names by replacing invalid characters with valid characters. Applicable for Avro and Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.scrub.invalid.names"
        }
      ],
      "connector_configs": [
        {
          "name": "value.converter",
          "switch": {
            "input.data.format": {
              "AVRO": "io.confluent.connect.avro.AvroConverter",
              "JSON_SR": "io.confluent.connect.json.JsonSchemaConverter",
              "PROTOBUF": "io.confluent.connect.protobuf.ProtobufConverter",
              "BYTES": "org.apache.kafka.connect.converters.ByteArrayConverter",
              "JSON": "org.apache.kafka.connect.json.JsonConverter"
            }
          }
        },
        {
          "name": "value.converter.schemas.enable"
        },
        {
          "name": "value.converter.replace.null.with.default"
        },
        {
          "name": "value.converter.schema.registry.url",
          "switch": {
            "input.data.format": {
              "AVRO": "${schema.registry.url}",
              "JSON_SR": "${schema.registry.url}",
              "PROTOBUF": "${schema.registry.url}"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.credentials.source",
          "switch": {
            "input.data.format": {
              "AVRO": "USER_INFO",
              "JSON_SR": "USER_INFO",
              "PROTOBUF": "USER_INFO"
            }
          }
        },
        {
          "name": "value.converter.basic.auth.user.info",
          "switch": {
            "input.data.format": {
              "AVRO": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "JSON_SR": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}",
              "PROTOBUF": "${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:username}:${file:/mnt/secrets/connect-sr-{{.logicalClusterId}}.properties:password}"
            }
          }
        },
        {
          "name": "value.converter.ignore.default.for.nullables"
        },
        {
          "name": "value.converter.scrub.invalid.names",
          "dynamic.mapper": {
            "name": "value.converter.scrub.invalid.names.mapper"
          }
        }
      ]
    },
    {
      "template_id": "super",
      "abstract": true,
      "config_defs": [
        {
          "name": "auto.restart.on.user.error",
          "type": "BOOLEAN",
          "required": false,
          "default_value": "true",
          "importance": "MEDIUM",
          "group": "Auto-restart policy",
          "order_in_group": 1,
          "display_name": "Enable Connector Auto-restart",
          "documentation": "Enable connector to automatically restart on user-actionable errors."
        },
        {
          "name": "value.converter.enhanced.avro.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information and Enums. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data",
          "type": "BOOLEAN",
          "documentation": "Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support",
          "type": "BOOLEAN",
          "documentation": "Enable enhanced schema support to preserve package information. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to generate an index suffix for unions. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums",
          "type": "BOOLEAN",
          "documentation": "Whether to represent enums as integers. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should be specified with an optional label. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls",
          "type": "BOOLEAN",
          "documentation": "Whether to generate a struct variable for null values. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables",
          "type": "BOOLEAN",
          "documentation": "Whether nullable fields should use primitive wrapper messages. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives",
          "type": "BOOLEAN",
          "documentation": "Whether a wrapper message should be interpreted as a raw primitive at root level. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties",
          "type": "BOOLEAN",
          "documentation": "Whether to allow additional properties for object schemas. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired",
          "type": "BOOLEAN",
          "documentation": "Whether to set non-required properties to be optional. Applicable for JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format",
          "type": "STRING",
          "recommended_values": [
            "BASE64",
            "NUMERIC"
          ],
          "documentation": "Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:\nBASE64 to serialize DECIMAL logical types as base64 encoded binary data and\nNUMERIC to serialize Connect DECIMAL logical type values in JSON/JSON_SR as a number representing the decimal value.",
          "group": "Additional Configs",
          "alias": "json.output.decimal.format",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.decimal.format",
          "default_value": "BASE64"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "type": "BOOLEAN",
          "documentation": "Specify if the Serializer should attempt to register the Schema.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.auto.register.schemas"
        },
        {
          "name": "value.converter.use.latest.version",
          "type": "BOOLEAN",
          "documentation": "Use latest version of schema in subject for serialization when auto.register.schemas is false.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.use.latest.version"
        },
        {
          "name": "value.converter.latest.compatibility.strict",
          "type": "BOOLEAN",
          "documentation": "Verify latest subject version is backward compatible when `use.latest.version` is `true`.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "type": "STRING",
          "default_value": "TopicNameStrategy",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "alias": "key.subject.name.strategy",
          "documentation": "How to construct the subject name for key schema registration.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "key.converter.key.subject.name.strategy"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "TopicNameStrategy",
            "RecordNameStrategy",
            "TopicRecordNameStrategy"
          ],
          "default_value": "TopicNameStrategy",
          "alias": "subject.name.strategy,value.subject.name.strategy",
          "documentation": "Determines how to construct the subject name under which the value schema is registered with Schema Registry.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.value.subject.name.strategy"
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "type": "STRING",
          "recommended_values": [
            "DefaultReferenceSubjectNameStrategy",
            "QualifiedReferenceSubjectNameStrategy"
          ],
          "default_value": "DefaultReferenceSubjectNameStrategy",
          "documentation": "Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.reference.subject.name.strategy"
        },
        {
          "name": "value.converter.allow.optional.map.keys",
          "type": "BOOLEAN",
          "documentation": "Allow optional string map key when converting from Connect Schema to Avro Schema. Applicable for Avro Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions",
          "type": "BOOLEAN",
          "default_value": "false",
          "documentation": "Whether to flatten singleton unions. Applicable for Avro and JSON_SR Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2",
          "type": "BOOLEAN",
          "documentation": "Whether proto2 optionals are supported. Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions",
          "type": "BOOLEAN",
          "documentation": "Whether to flatten unions (oneofs). Applicable for Protobuf Converters.",
          "group": "Additional Configs",
          "required": false,
          "importance": "LOW",
          "display_name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "header.converter",
          "documentation": "The converter class for the headers. This is used to serialize and deserialize the headers of the messages.",
          "recommended_values": [
            "org.apache.kafka.connect.converters.BooleanConverter",
            "org.apache.kafka.connect.converters.ByteArrayConverter",
            "org.apache.kafka.connect.converters.DoubleConverter",
            "org.apache.kafka.connect.converters.FloatConverter",
            "org.apache.kafka.connect.converters.IntegerConverter",
            "org.apache.kafka.connect.converters.LongConverter",
            "org.apache.kafka.connect.converters.ShortConverter",
            "org.apache.kafka.connect.json.JsonConverter",
            "org.apache.kafka.connect.storage.SimpleHeaderConverter",
            "org.apache.kafka.connect.storage.StringConverter"
          ]
        }
      ],
      "connector_configs": [
        {
          "name": "auto.restart.on.user.error"
        },
        {
          "name": "value.converter.enhanced.avro.schema.support"
        },
        {
          "name": "value.converter.connect.meta.data"
        },
        {
          "name": "value.converter.enhanced.protobuf.schema.support"
        },
        {
          "name": "value.converter.generate.index.for.unions"
        },
        {
          "name": "value.converter.int.for.enums"
        },
        {
          "name": "value.converter.optional.for.nullables"
        },
        {
          "name": "value.converter.generate.struct.for.nulls"
        },
        {
          "name": "value.converter.wrapper.for.nullables"
        },
        {
          "name": "value.converter.wrapper.for.raw.primitives"
        },
        {
          "name": "value.converter.object.additional.properties"
        },
        {
          "name": "value.converter.use.optional.for.nonrequired"
        },
        {
          "name": "value.converter.decimal.format"
        },
        {
          "name": "value.converter.auto.register.schemas",
          "dynamic.mapper": {
            "name": "value.converter.auto.register.schemas.mapper"
          }
        },
        {
          "name": "value.converter.use.latest.version",
          "dynamic.mapper": {
            "name": "value.converter.use.latest.version.mapper"
          }
        },
        {
          "name": "value.converter.latest.compatibility.strict"
        },
        {
          "name": "value.converter.value.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "key.converter.key.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.value.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.reference.subject.name.strategy",
          "dynamic.mapper": {
            "name": "value.converter.reference.subject.name.strategy.mapper"
          }
        },
        {
          "name": "value.converter.allow.optional.map.keys"
        },
        {
          "name": "value.converter.flatten.singleton.unions"
        },
        {
          "name": "value.converter.optional.for.proto2"
        },
        {
          "name": "value.converter.flatten.unions"
        },
        {
          "name": "header.converter"
        },
        {
          "name": "key.converter.use.apache.http.client"
        },
        {
          "name": "value.converter.use.apache.http.client"
        }
      ]
    },
    {
      "template_id": "super-sink",
      "abstract": true,
      "config_defs": [
        {
          "name": "consumer.override.auto.offset.reset",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "consumer.override.auto.offset.reset",
          "documentation": "Defines the behavior of the consumer when there is no committed position (which occurs when the group is first initialized) or when an offset is out of range. You can choose either to reset the position to the “earliest” offset (the default) or the “latest” offset. You can also select “none” if you would rather set the initial offset yourself and you are willing to handle out of range errors manually. More details: https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#auto-offset-reset",
          "recommended_values": [
            "earliest",
            "latest",
            "none"
          ]
        },
        {
          "name": "consumer.override.isolation.level",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Additional Configs",
          "display_name": "consumer.override.isolation.level",
          "documentation": "Controls how to read messages written transactionally. If set to read_committed, consumer.poll() will only return transactional messages which have been committed. If set to read_uncommitted (the default), consumer.poll() will return all messages, even transactional messages which have been aborted. Non-transactional messages will be returned unconditionally in either mode.  More details: https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#isolation-level",
          "recommended_values": [
            "read_committed",
            "read_uncommitted"
          ]
        },
        {
          "name": "topics.regex",
          "type": "STRING",
          "required": false,
          "importance": "LOW",
          "group": "Which topics do you want to get data from?",
          "display_name": "Topics Regex",
          "documentation": "A regular expression that matches the names of the topics to consume from. This is useful when you want to consume from multiple topics that match a certain pattern without having to list them all individually."
        }
      ],
      "connector_configs": [
        {
          "name": "consumer.override.auto.offset.reset"
        },
        {
          "name": "consumer.override.isolation.level"
        },
        {
          "name": "topics.regex"
        }
      ]
    }
  ]
}